<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Liang2's Blog - Bioinfo</title><link href="https://blog.liang2.tw/" rel="alternate"></link><link href="https://blog.liang2.tw/feeds/bioinfo.atom.xml" rel="self"></link><id>https://blog.liang2.tw/</id><updated>2018-06-22T00:00:00-05:00</updated><entry><title>Access gene annotation using gffutils</title><link href="https://blog.liang2.tw/posts/2018/06/gene-annotation-using-gffutils/" rel="alternate"></link><published>2018-06-22T00:00:00-05:00</published><updated>2018-06-22T00:00:00-05:00</updated><author><name>Liang-Bo Wang</name></author><id>tag:blog.liang2.tw,2018-06-22:/posts/2018/06/gene-annotation-using-gffutils/</id><summary type="html">&lt;p&gt;Recently, I had to access gene annotations in multiple versions from multiple sources such as Ensembl, GENCODE, and UCSC. I used to rely on …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Recently, I had to access gene annotations in multiple versions from multiple sources such as Ensembl, GENCODE, and UCSC. I used to rely on the R/Bioconductor ecosystem to query the coordinates of a gene annotation. There are existing Bioconductor packages ready for Ensembl and UCSC annotations (more info in my previous posts: &lt;a href="https://blog.liang2.tw/posts/2016/05/biocondutor-ensembl-reference/"&gt;Ensembl&lt;/a&gt; and &lt;a href="https://blog.liang2.tw/2016Talk-Genomics-in-R/"&gt;UCSC&lt;/a&gt;), and one can create a new customized TxDb given a GTF/GFF file. However, the project I was working on was written in Python, so I went on searching for similar alternatives in Python.&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s how I found &lt;a href="https://daler.github.io/gffutils/"&gt;gffutils&lt;/a&gt;, a Python package to access gene annotations from GTF/GFF files. &lt;code&gt;gffutils&lt;/code&gt; first imports the annotations from the GTF/GFF file into a SQLite database. The package also provides some abstraction on top of the database schema, so user can retrieve an annotation without talking to the database directly using repetitive SQL commands. Database enables fast random access to any gene annotation. &lt;/p&gt;
&lt;p&gt;I will use GENCODE v19, an annotation used by many TCGA GRCh37/hg19 projects, as an example to demo the usage of gffutils. My project requires the coordinates of UTRs and exons of all the transcripts in use.&lt;/p&gt;
&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#usage-example"&gt;Usage example&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#single-feature-access"&gt;Single feature access&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#gene-model-coordinates-of-a-transcript"&gt;Gene model coordinates of a transcript&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#feature-selection"&gt;Feature selection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#direct-operation-on-the-database"&gt;Direct operation on the database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#discussions"&gt;Discussions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h3 id="usage-example"&gt;Usage example&lt;/h3&gt;
&lt;p&gt;To use gffutils to query GENCODE annotation, we need to create the database first. The comprehensive gene annotation GTF can be downloaded from &lt;a href="https://www.gencodegenes.org/releases/19.html"&gt;the GENCODE website&lt;/a&gt; (&lt;a href="ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_19/gencode.v19.annotation.gtf.gz"&gt;URL to the GTF&lt;/a&gt;). The database creation is handled by gffutils&amp;rsquo;s &lt;code&gt;create_db&lt;/code&gt; function. It will take a few minutes to run and the database will be at &lt;code&gt;gencode_v19.db&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;gffutils&lt;/span&gt;

&lt;span class="n"&gt;db&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gffutils&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_db&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;./gencode.v19.annotation.gtf.gz&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;dbfn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;gencode_v19.db&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;merge_strategy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;error&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;disable_infer_transcripts&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;disable_infer_genes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# INFO - Committing changes: 2619000 features&lt;/span&gt;
&lt;span class="c1"&gt;# INFO - Populating features table and first-order relations: 2619443 features&lt;/span&gt;
&lt;span class="c1"&gt;# INFO - Creating relations(parent) index&lt;/span&gt;
&lt;span class="c1"&gt;# INFO - Creating relations(child) index&lt;/span&gt;
&lt;span class="c1"&gt;# INFO - Creating features(featuretype) index&lt;/span&gt;
&lt;span class="c1"&gt;# INFO - Creating features (seqid, start, end) index&lt;/span&gt;
&lt;span class="c1"&gt;# INFO - Creating features (seqid, start, end, strand) index&lt;/span&gt;
&lt;span class="c1"&gt;# INFO - Running ANALYSE features&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once the database is created, we don&amp;rsquo;t have to repeat the same process but load the database directly as a FeatureDB object:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gffutils&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FeatureDB&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;./gencode_v19.db&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4 id="single-feature-access"&gt;Single feature access&lt;/h4&gt;
&lt;p&gt;One can then access the annotations of a gene or transcript by its ID. Using a transcript of TP53 as an example,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;gene&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ENSG00000141510.11&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt; &lt;span class="n"&gt;gene&lt;/span&gt;
&lt;span class="go"&gt;&amp;lt;Feature gene (chr17:7565097-7590856[-]) at 0x7fac828deeb8&amp;gt;&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;tx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ENST00000269305.4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt; &lt;span class="n"&gt;tx&lt;/span&gt;
&lt;span class="go"&gt;&amp;lt;Feature transcript (chr17:7571720-7590856[-]) at 0x7fac828f8080&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can then access the details of the transcript:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;featuretype&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;
&lt;span class="go"&gt;(&amp;#39;transcript&amp;#39;, &amp;#39;HAVANA&amp;#39;)&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;chrom&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strand&lt;/span&gt;
&lt;span class="go"&gt;(&amp;#39;chr17&amp;#39;, 7571720, 7590856, &amp;#39;-&amp;#39;)&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attributes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="go"&gt;[(&amp;#39;gene_id&amp;#39;, [&amp;#39;ENSG00000141510.11&amp;#39;]),&lt;/span&gt;
&lt;span class="go"&gt; (&amp;#39;transcript_id&amp;#39;, [&amp;#39;ENST00000269305.4&amp;#39;]),&lt;/span&gt;
&lt;span class="go"&gt; (&amp;#39;gene_type&amp;#39;, [&amp;#39;protein_coding&amp;#39;]),&lt;/span&gt;
&lt;span class="go"&gt; (&amp;#39;gene_status&amp;#39;, [&amp;#39;KNOWN&amp;#39;]),&lt;/span&gt;
&lt;span class="go"&gt; (&amp;#39;gene_name&amp;#39;, [&amp;#39;TP53&amp;#39;]),&lt;/span&gt;
&lt;span class="go"&gt; (&amp;#39;transcript_type&amp;#39;, [&amp;#39;protein_coding&amp;#39;]),&lt;/span&gt;
&lt;span class="go"&gt; (&amp;#39;transcript_status&amp;#39;, [&amp;#39;KNOWN&amp;#39;]),&lt;/span&gt;
&lt;span class="go"&gt; (&amp;#39;transcript_name&amp;#39;, [&amp;#39;TP53-001&amp;#39;]),&lt;/span&gt;
&lt;span class="go"&gt; (&amp;#39;level&amp;#39;, [&amp;#39;2&amp;#39;]),&lt;/span&gt;
&lt;span class="go"&gt; (&amp;#39;protein_id&amp;#39;, [&amp;#39;ENSP00000269305.4&amp;#39;]),&lt;/span&gt;
&lt;span class="go"&gt; (&amp;#39;tag&amp;#39;, [&amp;#39;basic&amp;#39;, &amp;#39;appris_principal&amp;#39;, &amp;#39;CCDS&amp;#39;]),&lt;/span&gt;
&lt;span class="go"&gt; (&amp;#39;ccdsid&amp;#39;, [&amp;#39;CCDS11118.1&amp;#39;]),&lt;/span&gt;
&lt;span class="go"&gt; (&amp;#39;havana_gene&amp;#39;, [&amp;#39;OTTHUMG00000162125.4&amp;#39;]),&lt;/span&gt;
&lt;span class="go"&gt; (&amp;#39;havana_transcript&amp;#39;, [&amp;#39;OTTHUMT00000367397.1&amp;#39;])]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4 id="gene-model-coordinates-of-a-transcript"&gt;Gene model coordinates of a transcript&lt;/h4&gt;
&lt;p&gt;To find the coordinates of its exons and UTRs, we use &lt;a href="https://daler.github.io/gffutils/autodocs/gffutils.interface.FeatureDB.children.html#gffutils.interface.FeatureDB.children"&gt;&lt;code&gt;FeatureDB.children()&lt;/code&gt;&lt;/a&gt; which takes an Feature object or its ID and retrieves all the features belong to this feature. TP53 is on the reverse strand of the chromosome, so we can further sort the features by their end position:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;children&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;order_by&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;-end&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;             
&lt;span class="go"&gt;[&amp;lt;Feature transcript (chr17:7571720-7590856[-]) at 0x7fac828922e8&amp;gt;,&lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature UTR (chr17:7590695-7590856[-]) at 0x7fac82892208&amp;gt;, &lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature exon (chr17:7590695-7590856[-]) at 0x7fac828922b0&amp;gt;,&lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature UTR (chr17:7579913-7579940[-]) at 0x7fac828925c0&amp;gt;, &lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature exon (chr17:7579839-7579940[-]) at 0x7fac828928d0&amp;gt;,&lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature CDS (chr17:7579839-7579912[-]) at 0x7fac82892c18&amp;gt;, &lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature start_codon (chr17:7579910-7579912[-]) at 0x7fac82892f28&amp;gt;,&lt;/span&gt;
&lt;span class="go"&gt; ...&lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature CDS (chr17:7572930-7573008[-]) at 0x7fac828277b8&amp;gt;, &lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature exon (chr17:7571720-7573008[-]) at 0x7fac82827b38&amp;gt;,&lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature UTR (chr17:7571720-7572929[-]) at 0x7fac82827eb8&amp;gt;,       &lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature stop_codon (chr17:7572927-7572929[-]) at 0x7fac828fca90&amp;gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We have retrieved the UTRs, CDSs and exons of the transcript. Note that UTR is considered a part of an exon in gene annotation terminology. We should use CDSs as the exons that will be translated to amino acids. &lt;code&gt;FeatureDB.children()&lt;/code&gt; provides a way to subset the feature type it returns:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;children&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;order_by&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;-end&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;featuretype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;CDS&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;UTR&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="go"&gt;[&amp;lt;Feature UTR (chr17:7590695-7590856[-]) at 0x7fac8283d7f0&amp;gt;,&lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature UTR (chr17:7579913-7579940[-]) at 0x7fac8283d710&amp;gt;,&lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature CDS (chr17:7579839-7579912[-]) at 0x7fac8283d7b8&amp;gt;,&lt;/span&gt;
&lt;span class="go"&gt; ...&lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature CDS (chr17:7572930-7573008[-]) at 0x7fac82846470&amp;gt;,&lt;/span&gt;
&lt;span class="go"&gt; &amp;lt;Feature UTR (chr17:7571720-7572929[-]) at 0x7fac828467b8&amp;gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now the gene model of TP53 becomes clearly visible.&lt;/p&gt;
&lt;h4 id="feature-selection"&gt;Feature selection&lt;/h4&gt;
&lt;p&gt;To select all the transcripts in the database, there is a &lt;code&gt;FeatureDB.all_features()&lt;/code&gt; function. Here we want to select only the basic GENOCODE transcripts and count the number of different gene types:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Counter&lt;/span&gt;
&lt;span class="c1"&gt;# All the transcripts of basic GENCODE v19&lt;/span&gt;
&lt;span class="n"&gt;all_basic_txs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tx&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;tx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;all_features&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;featuretype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;transcript&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;tag&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attributes&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;basic&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attributes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tag&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attributes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;gene_type&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;tx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;all_basic_txs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# [(&amp;#39;protein_coding&amp;#39;, 67186),&lt;/span&gt;
&lt;span class="c1"&gt;#  (&amp;#39;antisense&amp;#39;, 9160),&lt;/span&gt;
&lt;span class="c1"&gt;#  (&amp;#39;lincRNA&amp;#39;, 7121),&lt;/span&gt;
&lt;span class="c1"&gt;#  (&amp;#39;miRNA&amp;#39;, 3055),&lt;/span&gt;
&lt;span class="c1"&gt;#  (&amp;#39;misc_RNA&amp;#39;, 2034)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="direct-operation-on-the-database"&gt;Direct operation on the database&lt;/h3&gt;
&lt;p&gt;Since gffutils is just a abstraction layer on top of the database, we can always talk to the underlying SQLite database directly by writing SQL commands. The database schema is available on &lt;a href="https://daler.github.io/gffutils/database-schema.html"&gt;the gffutils&amp;rsquo;s documentation&lt;/a&gt;. Under the hood, FeatureDB object maintains a SQLite connection at &lt;code&gt;FeatureDB.conn&lt;/code&gt; and a helper function to run a single SQL command via &lt;code&gt;FeatureDB.execute()&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;For example, GENCODE stores the full version of a transcript ID but in many occasion, such information is not available. Say if we only know the TP53 transcript ID is &lt;code&gt;ENST00000269305&lt;/code&gt;, then we can write a SQL query to find the matching ID: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conn&lt;/span&gt;
&lt;span class="go"&gt;&amp;lt;sqlite3.Connection at 0x7fac89423490&amp;gt;&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;cur&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="gp"&gt;... &lt;/span&gt;   &lt;span class="s2"&gt;&amp;quot;SELECT id FROM features &amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;... &lt;/span&gt;   &lt;span class="s2"&gt;&amp;quot;WHERE featuretype=&amp;#39;transcript&amp;#39; AND id LIKE &amp;#39;ENST00000269305.%&amp;#39;;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;cur&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fetchone&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="go"&gt;&amp;#39;ENST00000269305.4&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can even tweak the SQLite behavior by setting &lt;a href="https://www.sqlite.org/pragma.html"&gt;the &lt;code&gt;PRAGMA&lt;/code&gt; statements&lt;/a&gt;. gffutils has already added default pragma to optimize database query, including less database integrity and large memory size:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pragmas&lt;/span&gt;
&lt;span class="go"&gt;{&amp;#39;synchronous&amp;#39;: &amp;#39;NORMAL&amp;#39;,&lt;/span&gt;
&lt;span class="go"&gt; &amp;#39;journal_mode&amp;#39;: &amp;#39;MEMORY&amp;#39;,&lt;/span&gt;
&lt;span class="go"&gt; &amp;#39;main.page_size&amp;#39;: 4096,&lt;/span&gt;
&lt;span class="go"&gt; &amp;#39;main.cache_size&amp;#39;: 10000}&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;PRAGMA temp_store=MEMORY&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;execute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;PRAGMA cache_size=-1000000&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Use 1GB memory&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="discussions"&gt;Discussions&lt;/h3&gt;
&lt;p&gt;gffutils provides a SQLite-based gene annotation storage in Python. Though it may not be as feature complete as what user may get in R, it is highly customizable and can be easily integrated with other Python functions. Like the Bioconductor packages GenomicFeatures and EnsDb, they all use a SQLite database under the hood. As shown in &lt;a href="https://blog.liang2.tw/posts/2017/11/use-ensdb-database-in-python/"&gt;another post&lt;/a&gt;, we can actually connect to those databases built by R packages directly, so user can access information from other sources such as UniProt isoforms and gene names.&lt;/p&gt;
&lt;p&gt;In my opinion, all the approaches mentioned above are always better than trying to bake one&amp;rsquo;s own from scratch. Those packages are backed by numerous tests and are built from reliable or the original data sources. Besides multiple existing solutions in R and Python, one can always access the databases built by those packages from different languages, so it is quite unlikely to build something from scratch anyway.&lt;/p&gt;</content><category term="en"></category><category term="python"></category><category term="sqlite"></category></entry><entry><title>Read UniProtKB in XML format</title><link href="https://blog.liang2.tw/posts/2018/01/read-uniprotkb-xml/" rel="alternate"></link><published>2018-01-28T00:00:00-06:00</published><updated>2018-01-28T00:00:00-06:00</updated><author><name>Liang-Bo Wang</name></author><id>tag:blog.liang2.tw,2018-01-28:/posts/2018/01/read-uniprotkb-xml/</id><summary type="html">&lt;p&gt;UniProt Knowledge Base (&lt;a href="http://www.uniprot.org/help/uniprotkb"&gt;UniProtKB&lt;/a&gt;) provides &lt;a href="https://www.uniprot.org/help/programmatic_access"&gt;various methods&lt;/a&gt; to access their data. I settled on their XML format since no additional parsing code is required …&lt;/p&gt;</summary><content type="html">&lt;p&gt;UniProt Knowledge Base (&lt;a href="http://www.uniprot.org/help/uniprotkb"&gt;UniProtKB&lt;/a&gt;) provides &lt;a href="https://www.uniprot.org/help/programmatic_access"&gt;various methods&lt;/a&gt; to access their data. I settled on their XML format since no additional parsing code is required and the format is well defined, which comes with a schema. Plus, it turns out that databases such as &lt;a href="http://pdbml.pdb.org/"&gt;PDB&lt;/a&gt; also provide their data export in XML format and the corresponding schema so the method can be applied elsewhere. &lt;/p&gt;
&lt;p&gt;Here I will show how to read XML with its schema in Python using &lt;a href="https://pypi.org/project/xmlschema/"&gt;xmlschema&lt;/a&gt;.&lt;/p&gt;
&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#other-ways-to-read-uniprotkb-data-in-bulk"&gt;Other ways to read UniProtKB data in bulk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#xml-and-xml-schema"&gt;XML and XML schema&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#read-uniprot-xml-by-xmlschema"&gt;Read UniProt XML by xmlschema&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h2 id="other-ways-to-read-uniprotkb-data-in-bulk"&gt;Other ways to read UniProtKB data in bulk&lt;/h2&gt;
&lt;p&gt;UniProtKB at least provides REST, SPARQL, XML, and a flat text file for its data access. &lt;/p&gt;
&lt;p&gt;RESTful APIs work very well to access a small proportion of data and usually are my way to go for data access, but it will put too much load on the server if I want a lot of information from tens of thousands of entries. Ideally, UniProtKB&amp;rsquo;s data won&amp;rsquo;t change very often so I&amp;rsquo;d like to hit the database once per entry and cache the results locally. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/SPARQL"&gt;SPARQL&lt;/a&gt; is kind of similar to REST but can directly query on UniProtKB&amp;rsquo;s &lt;a href="https://en.wikipedia.org/wiki/Resource_Description_Framework"&gt;RDF&lt;/a&gt; file, thus one can retrieve whatever information available in a complex way. I started my research on this method but I got overwhelmed by the technical details and eventually gave up. I feel like more tutorials or examples on how to access the SPARQL interface will be very helpful.&lt;/p&gt;
&lt;p&gt;UniProtKB&amp;rsquo;s flat text file has been a popular way to parse its data. I mean, it has &lt;a href="https://www.uniprot.org/docs/userman.htm"&gt;its own manual&lt;/a&gt;, and one can download a full entry&amp;rsquo;s data easily. But this requires writing a custom parser in Python. More code means more bugs, and I will worry about whether my parser works every time UniProt updates.&lt;/p&gt;
&lt;h2 id="xml-and-xml-schema"&gt;XML and XML schema&lt;/h2&gt;
&lt;p&gt;XML data are structured. For example, this is what entry &lt;a href="https://www.uniprot.org/uniprot/P51587"&gt;P51587&lt;/a&gt; looks like in XML format:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;uniprot&lt;/span&gt; &lt;span class="na"&gt;xmlns=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://uniprot.org/uniprot&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;xmlns:xsi=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;xsi:schemaLocation=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://uniprot.org/uniprot http://www.uniprot.org/support/docs/uniprot.xsd&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;entry&lt;/span&gt; &lt;span class="na"&gt;dataset=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Swiss-Prot&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;created=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;1996-10-01&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;modified=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;2017-12-20&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;version=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;201&amp;quot;&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;accession&amp;gt;&lt;/span&gt;P51587&lt;span class="nt"&gt;&amp;lt;/accession&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;accession&amp;gt;&lt;/span&gt;O00183&lt;span class="nt"&gt;&amp;lt;/accession&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;accession&amp;gt;&lt;/span&gt;O15008&lt;span class="nt"&gt;&amp;lt;/accession&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;accession&amp;gt;&lt;/span&gt;Q13879&lt;span class="nt"&gt;&amp;lt;/accession&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;accession&amp;gt;&lt;/span&gt;Q5TBJ7&lt;span class="nt"&gt;&amp;lt;/accession&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;name&amp;gt;&lt;/span&gt;BRCA2_HUMAN&lt;span class="nt"&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;protein&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;recommendedName&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;fullName&amp;gt;&lt;/span&gt;Breast cancer type 2 susceptibility protein&lt;span class="nt"&gt;&amp;lt;/fullName&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/recommendedName&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;alternativeName&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;fullName&amp;gt;&lt;/span&gt;Fanconi anemia group D1 protein&lt;span class="nt"&gt;&amp;lt;/fullName&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/alternativeName&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/protein&amp;gt;&lt;/span&gt;
&lt;span class="c"&gt;&amp;lt;!-- ...  --&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/entry&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/uniprot&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The file is available at &lt;a href="https://www.uniprot.org/uniprot/P04637.xml"&gt;https://www.uniprot.org/uniprot/P04637.xml&lt;/a&gt;. Basically, all the information about this entry should be available in this file, as long as one knows how to query the XML via &lt;a href="https://en.wikipedia.org/wiki/XPath"&gt;XPath&lt;/a&gt;. However, I find XML file harder to read alone, especially without any guide of how the file was constructed.&lt;/p&gt;
&lt;p&gt;UniProt XML is constructed based on its XML schema, available as an XSD file at &lt;a href="http://www.uniprot.org/support/docs/uniprot.xsd"&gt;http://www.uniprot.org/support/docs/uniprot.xsd&lt;/a&gt;. The schema not only helps understand the XML content, it also validates whether the XML is valid. In other words, since all UniProt XMLs are validated by its schema, one can expect to parse all their data the same as what the schema has defined. XML schema is also part of the &lt;a href="https://www.w3.org/XML/Schema"&gt;W3C standard&lt;/a&gt; and wildly used.&lt;/p&gt;
&lt;h2 id="read-uniprot-xml-by-xmlschema"&gt;Read UniProt XML by xmlschema&lt;/h2&gt;
&lt;p&gt;I use &lt;a href="https://pypi.org/project/xmlschema/"&gt;xmlschema&lt;/a&gt; to read XML with its schema in Python. Instead of using XPath, one can actually convert the XML content into a dictionary-like format, which can be easily passed to other Python functions.&lt;/p&gt;
&lt;p&gt;Using same entry &lt;a href="https://www.uniprot.org/uniprot/P51587"&gt;P51587&lt;/a&gt; as an example,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;xmlschema&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;schema&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;xmlschema&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;XMLSchema&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;https://www.uniprot.org/docs/uniprot.xsd&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;entry_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;schema&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;./P51587.xml&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;entry_dict&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="go"&gt;dict_keys([&amp;#39;@xsi:schemaLocation&amp;#39;, &amp;#39;entry&amp;#39;, &amp;#39;copyright&amp;#39;])&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;entry_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;entry&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)[:&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="go"&gt;[&amp;#39;@dataset&amp;#39;, &amp;#39;@created&amp;#39;, &amp;#39;@modified&amp;#39;, &amp;#39;@version&amp;#39;, &amp;#39;accession&amp;#39;, &amp;#39;name&amp;#39;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I don&amp;rsquo;t need any custom code to read the XML content structurally. For example, to get all the accession IDs of this entry,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;accession&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="go"&gt;[&amp;#39;P51587&amp;#39;, &amp;#39;O00183&amp;#39;, &amp;#39;O15008&amp;#39;, &amp;#39;Q13879&amp;#39;, &amp;#39;Q5TBJ7&amp;#39;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To get the protein names,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;protein&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="go"&gt;{&amp;#39;alternativeName&amp;#39;: [{&amp;#39;fullName&amp;#39;: &amp;#39;Fanconi anemia group D1 protein&amp;#39;}],&lt;/span&gt;
&lt;span class="go"&gt; &amp;#39;recommendedName&amp;#39;: {&amp;#39;fullName&amp;#39;: &amp;#39;Breast cancer type 2 susceptibility protein&amp;#39;}}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;One can compare the dictionary converted result with the original XML. I&amp;rsquo;d like to end the demo with a more complicated example that finds all the sequence variants:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="n"&gt;seq_variants&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="gp"&gt;... &lt;/span&gt;    &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;@type&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;sequence variant&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;variation&amp;#39;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="gp"&gt;... &lt;/span&gt;    &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;feature&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;location&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;position&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;@position&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
&lt;span class="gp"&gt;... &lt;/span&gt;  &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;original&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;variation&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="gp"&gt;... &lt;/span&gt;  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;seq_variants&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="go"&gt;[(25, &amp;#39;G&amp;#39;, &amp;#39;R&amp;#39;),&lt;/span&gt;
&lt;span class="go"&gt; (31, &amp;#39;W&amp;#39;, &amp;#39;C&amp;#39;),&lt;/span&gt;
&lt;span class="go"&gt; (31, &amp;#39;W&amp;#39;, &amp;#39;R&amp;#39;),&lt;/span&gt;
&lt;span class="go"&gt; (32, &amp;#39;F&amp;#39;, &amp;#39;L&amp;#39;),&lt;/span&gt;
&lt;span class="go"&gt; (42, &amp;#39;Y&amp;#39;, &amp;#39;C&amp;#39;),&lt;/span&gt;
&lt;span class="go"&gt; (53, &amp;#39;K&amp;#39;, &amp;#39;R&amp;#39;),&lt;/span&gt;
&lt;span class="go"&gt; (60, &amp;#39;N&amp;#39;, &amp;#39;S&amp;#39;),&lt;/span&gt;
&lt;span class="go"&gt; (64, &amp;#39;T&amp;#39;, &amp;#39;I&amp;#39;),&lt;/span&gt;
&lt;span class="go"&gt; (75, &amp;#39;A&amp;#39;, &amp;#39;P&amp;#39;),&lt;/span&gt;
&lt;span class="go"&gt; (81, &amp;#39;F&amp;#39;, &amp;#39;L&amp;#39;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;
&lt;p&gt;Using UniProt&amp;rsquo;s XML and its schema can read all the data in a structured fashion without a custom parser. Once downloading the XML files of interest, one could basically query everything locally, which is very helpful to retrieve substantial information from UniProt, say, extracting all the citations for certain protein feature.&lt;/p&gt;
&lt;p&gt;XML schema really helps users to understand the data structure and it also helps the database developers validate their data export. I hope someday all the databases should have this validation enforced.&lt;/p&gt;
&lt;p&gt;However, one may find XML format tedious and not human-friendly to read. JSON has been popular and used heavily by RESTful APIs. The specification of &lt;a href="http://json-schema.org/"&gt;JSON schema&lt;/a&gt; exists, but it is not a W3C standard yet. &lt;/p&gt;
&lt;p&gt;SPARQL and RDF, part of the attempt for the Semantic web can be a universal query interface solving the same problem more elegantly, though the entry level is a bit high with limited learning resources available.&lt;/p&gt;
&lt;p&gt;For now, reading bulk data in XML with its schema seems to be the mature way to go with abundant support.&lt;/p&gt;</content><category term="en"></category><category term="python"></category><category term="uniprot"></category></entry><entry><title>Ad hoc bioinformatic analysis in database</title><link href="https://blog.liang2.tw/posts/2018/01/ad-hoc-bioinfo-analysis-in-database/" rel="alternate"></link><published>2018-01-20T00:00:00-06:00</published><updated>2018-01-20T00:00:00-06:00</updated><author><name>Liang-Bo Wang</name></author><id>tag:blog.liang2.tw,2018-01-20:/posts/2018/01/ad-hoc-bioinfo-analysis-in-database/</id><summary type="html">&lt;p&gt;Recently I&amp;rsquo;ve found that bioinformatic analysis in a database is not hard at all and the database set up wasn&amp;rsquo;t as daunting …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Recently I&amp;rsquo;ve found that bioinformatic analysis in a database is not hard at all and the database set up wasn&amp;rsquo;t as daunting as it sounds, especially when the data are tabular. I used to start my analysis with loading everything into R or Python, and then figuring out all the filtering and grouping commands with my favorite R or Python packages. However, the data size would be bound by memory and the analysis might be slow unless additional optimization was applied. On the other hand, databases have already solved the problems by mapping the data to disk and indexing. Therefore I&amp;rsquo;d like to share my recent experience on using databases for bioinfo analysis.&lt;/p&gt;
&lt;p&gt;Note that if one is interested in the actual tips of using databases for analysis, feel free to skip the whole background section.&lt;/p&gt;
&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#background"&gt;Background&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#reading-tabular-data-in-bioinformatics"&gt;Reading tabular data in bioinformatics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#database"&gt;Database&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#tabular-data-io-in-database"&gt;Tabular data IO in database&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#sqlite"&gt;SQLite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#postgresql"&gt;PostgreSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#loading-compressed-data-with-named-pipe"&gt;Loading compressed data with named pipe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#benchmark"&gt;Benchmark&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#pandas-python"&gt;pandas (Python)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sqlite_1"&gt;SQLite&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#postgresql_1"&gt;PostgreSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#result"&gt;Result&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;h3 id="reading-tabular-data-in-bioinformatics"&gt;Reading tabular data in bioinformatics&lt;/h3&gt;
&lt;p&gt;Tabular data are everywhere in bioinformatics. To record gene expressions, variants or cross reference IDs between different annotation systems or databases, data are stored in various tabular-like formats, such as BED, GTF, MAF, and VCF, which can usually be normalized to the standard CSV and TSV files. Starting with the raw data, we apply different kinds of filtering and grouping to pick up the records of interest. For example, we might subset the data within a genomic region, select transcripts above an expression threshold, or group the data by the same transcript across multiple samples.&lt;/p&gt;
&lt;p&gt;Researchers have developed numerous tools to select the data of interest. In Python, numpy and pandas dominate the analysis; in R, data.frame, tibble, and data.table are all widely used. However, all the tools above only work if the data can be fit into memory. Unfortunately, bioinformatics data can go beyond 10GB easily these days. It has been difficult to analyze everything in memory. Even using a powerful server with a few hundreds GB of memory, the overhead of loading all data into memory can be time-consuming. To make things worse, when joining multiple data together, the magnitude of the issues above will be multiplied.&lt;/p&gt;
&lt;p&gt;One might argue that in Python there are packages like &lt;a href="http://xarray.pydata.org/en/stable/"&gt;xarray&lt;/a&gt; and &lt;a href="https://dask.pydata.org/en/latest/"&gt;dask&lt;/a&gt; capable of handling out-of-memory multi-dimensional array. But they are only useful for handling numerical data. In bioinformatics, metadata are frequently used and consist of many text columns, where numpy doesn&amp;rsquo;t have the same computing advantage as numerical columns. For example, gene expression only makes sense if it comes with the gene symbol, the transcript id, and the sample id.&lt;/p&gt;
&lt;h3 id="database"&gt;Database&lt;/h3&gt;
&lt;p&gt;Databases have been solving the out-of-memory data analysis for decades, and it also comes with several advantages. First, the language databases use is standardized, known as Structured Query Language (SQL). SQL is expressive, which means instead of writing how to load or query the data, one writes what the data or the query look like. Databases support concurrent reads, enabling query in parallel. Second, One can speed up the queries by setting up indexes. Different types of indexes and different combinations of columns can be added to boost the query. Lastly, databases are persistent, so one only needs to load the data once.&lt;/p&gt;
&lt;p&gt;I mainly use two databases: &lt;a href="https://sqlite.org/"&gt;SQLite&lt;/a&gt; and &lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt;. SQLite&amp;rsquo;s database is just a single file on disk and it doesn&amp;rsquo;t need any configuration to run. In fact SQLite ships with Python, available as the &lt;a href="https://docs.python.org/3/library/sqlite3.html"&gt;&lt;code&gt;sqlite&lt;/code&gt; module&lt;/a&gt;. SQLite works very well in my case.&lt;/p&gt;
&lt;p&gt;PostgreSQL is a more feature-rich database and has better concurrency support such as multiple writers at the same time. &lt;a href="https://www.postgresql.org/docs/current/static/indexes-types.html"&gt;Its advanced indexing&lt;/a&gt; and &lt;a href="https://www.postgresql.org/docs/current/static/datatype.html"&gt;data types&lt;/a&gt; might be helpful for genomic range query. The downside is that it requires some configurations and its installation is not as easy as SQLite. Though the basic PostgreSQL setup is actually just a few commands on Debian Linux, one probably needs to go through some documentation to understand what they are about and how to tweak the config.&lt;/p&gt;
&lt;p&gt;The most annoying thing I found using a database in the past was to load my data, where I had to create the table by &lt;code&gt;CREATE TABLE ...&lt;/code&gt; and insert all my data by multiple &lt;code&gt;INSERT INTO ... VALUES ...&lt;/code&gt; statements. But recently I found that many databases have some built-in utilities to make the process easy and fast. Also, it is not hard to programmatically generate the statements through packages like &lt;a href="https://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt;. Therefore, I will share some experience of using databases here.&lt;/p&gt;
&lt;h2 id="tabular-data-io-in-database"&gt;Tabular data IO in database&lt;/h2&gt;
&lt;h3 id="sqlite"&gt;SQLite&lt;/h3&gt;
&lt;p&gt;For SQLite, use &lt;code&gt;.mode csv&lt;/code&gt; with &lt;a href="https://www.sqlite.org/cli.html#csv"&gt;&lt;code&gt;.import&lt;/code&gt; statement&lt;/a&gt; to load in data. SQLite will create the table automatically by using the first row as the column names if the table doesn&amp;rsquo;t exist. One can create the table before the loading to define each column&amp;rsquo;s data type, otherwise, columns are just &lt;code&gt;TEXT&lt;/code&gt; type. &lt;code&gt;.separator&lt;/code&gt; controls the delimiter character SQLite uses between columns.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;mode&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;
&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;separator&lt;/span&gt; &lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;   &lt;span class="c1"&gt;-- For TSV files&lt;/span&gt;
&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/path/to/tsv&amp;#39;&lt;/span&gt; &lt;span class="k"&gt;table_name&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To export data, use &lt;code&gt;.once&lt;/code&gt; statement followed by the query:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;header&lt;/span&gt; &lt;span class="k"&gt;on&lt;/span&gt;  &lt;span class="c1"&gt;-- Export columns name&lt;/span&gt;
&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;once&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/path/to/output.tsv&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="k"&gt;table_name&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;  &lt;span class="c1"&gt;-- Export all data in the table&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Commands above can be scripted into SQLite like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sqlite3 mydb.sqlite &amp;amp;lt; load_data.sql
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="postgresql"&gt;PostgreSQL&lt;/h3&gt;
&lt;p&gt;For PostgreSQL, the built-in solution is to use the &lt;a href="https://www.postgresql.org/docs/current/static/sql-copy.html"&gt;&lt;code&gt;COPY&lt;/code&gt; statement&lt;/a&gt; or the &lt;a href="https://www.postgresql.org/docs/current/static/app-psql.html#APP-PSQL-META-COMMANDS-COPY"&gt;&lt;code&gt;\copy&lt;/code&gt; metacommand&lt;/a&gt; to import or export data. &lt;code&gt;COPY&lt;/code&gt; runs faster than the equivalent &lt;code&gt;INSERT&lt;/code&gt; statements. Besides built-in commands, an external tool &lt;a href="https://pgloader.io/"&gt;pgloader&lt;/a&gt; has been very helpful for the data loading, whose loading process is more flexible.&lt;/p&gt;
&lt;p&gt;In this post, I won&amp;rsquo;t dive into details of their usage. There will be an example in the benchmark section.&lt;/p&gt;
&lt;h3 id="loading-compressed-data-with-named-pipe"&gt;Loading compressed data with named pipe&lt;/h3&gt;
&lt;p&gt;Many tabular data are compressed by gzip or bgzip to save the disk space. To decompress the file and load into the database without storing the uncompressed file somewhere first, one can consider using &lt;a href="https://www.linuxjournal.com/article/2156"&gt;named pipe&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The idea is to decompress the file to a named pipe and read the data in a database from the named pipe. A named pipe can be created by &lt;code&gt;mkfifo&lt;/code&gt;.  For example,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mkfifo mypipe
gunzip -c mydata.tsv.gz &amp;gt; mypipe &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The trailing &lt;code&gt;&amp;amp;&lt;/code&gt; makes the decompress command running in the background to keep everything in one shell session. Then read the data in SQLite as if it were a file like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;mypipe&lt;/span&gt; &lt;span class="nn"&gt;mytable&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The trick here can be further expanded to any preprocessing in any language. One can simply preprocess the file and write the output to a named pipe. The database can read from the named pipe without storing the full intermediate output on disk. Plus, by piping between commands more CPU cores are utilized.&lt;/p&gt;
&lt;h2 id="benchmark"&gt;Benchmark&lt;/h2&gt;
&lt;p&gt;To give an idea of the data processing time in databases, I used all the &lt;a href="https://www.synapse.org/#!Synapse:syn7214402/wiki/405297"&gt;somatic variants from TCGA MC3&lt;/a&gt; as a demonstration. The goal here is to count the number of variants by different transcript and its mutation type. So the output result will be something like the following:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Transcript ID&lt;/th&gt;
&lt;th&gt;Mutation type&lt;/th&gt;
&lt;th&gt;Count&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ENST00000000233&lt;/td&gt;
&lt;td&gt;3&amp;rsquo;UTR&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ENST00000000233&lt;/td&gt;
&lt;td&gt;Frame_Shift_Del&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;ENST00000000233&lt;/td&gt;
&lt;td&gt;Intron&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;After filtering out all the silent mutations, there are about total 2.8 million variants making up 614MB of disk space.&lt;/p&gt;
&lt;p&gt;I used three methods to load and group the variants: pandas, SQLite, and PostgreSQL. Their code is shown below.&lt;/p&gt;
&lt;h3 id="pandas-python"&gt;pandas (Python)&lt;/h3&gt;
&lt;p&gt;Standard pandas IO code.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;


&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s1"&gt;&amp;#39;mc3_filtered.tsv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;chrom&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;start&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;end&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;strand&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;mutation_type&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;ref_allele&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;alt_allele&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;transcript_id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;hgvs_c&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;hgvs_p&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;cdna_start&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;cdna_end&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;p_start&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;p_end&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;normal_id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;tumor_id&amp;#39;&lt;/span&gt;
    &lt;span class="p"&gt;],&lt;/span&gt;
    &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;chrom&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;start&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;end&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;strand&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;cdna_start&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;cdna_end&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;p_start&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;p_end&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;c&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;grp_df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupby&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;transcript_id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;mutation_type&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;alt_allele&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_index&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;grp_df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;out.pandas.tsv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="sqlite_1"&gt;SQLite&lt;/h3&gt;
&lt;p&gt;I set some &lt;code&gt;PRAGMA ...&lt;/code&gt; statements at the beginning to control some of the SQLite settings. It tells SQLite to use more cache, create temporary tables in memory and disable all the transaction recovery settings. SQLite by default writes everything to the disk first before changing the actual database content so if the program fails or any exception occurs, it can recover all the transactions properly. In our case, we don&amp;rsquo;t care about the integrity of the database.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;PRAGMA&lt;/span&gt; &lt;span class="n"&gt;cache_size&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;4192000&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;  &lt;span class="c1"&gt;-- Use 2GB RAM as cache&lt;/span&gt;
&lt;span class="n"&gt;PRAGMA&lt;/span&gt; &lt;span class="n"&gt;temp_store&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MEMORY&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;PRAGMA&lt;/span&gt; &lt;span class="n"&gt;synchronous&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;OFF&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;PRAGMA&lt;/span&gt; &lt;span class="n"&gt;journal_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;OFF&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="n"&gt;PRAGMA&lt;/span&gt; &lt;span class="n"&gt;locking_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;EXCLUSIVE&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;mode&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;
&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;separator&lt;/span&gt; &lt;span class="err"&gt;\&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;
&lt;span class="k"&gt;CREATE&lt;/span&gt; &lt;span class="k"&gt;TABLE&lt;/span&gt; &lt;span class="n"&gt;mc3&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;chrom&lt;/span&gt;       &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="ss"&gt;&amp;quot;start&amp;quot;&lt;/span&gt;     &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="ss"&gt;&amp;quot;end&amp;quot;&lt;/span&gt;       &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;strand&lt;/span&gt;      &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;mutation_type&lt;/span&gt;   &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;ref_allele&lt;/span&gt;  &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;alt_allele&lt;/span&gt;  &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;transcript_id&lt;/span&gt;   &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;hgvs_c&lt;/span&gt;      &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;hgvs_p&lt;/span&gt;      &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;cdna_start&lt;/span&gt;  &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;cdna_end&lt;/span&gt;    &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;p_start&lt;/span&gt;     &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;p_end&lt;/span&gt;       &lt;span class="nb"&gt;INT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;normal_id&lt;/span&gt;   &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;tumor_id&lt;/span&gt;    &lt;span class="nb"&gt;TEXT&lt;/span&gt;
&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;mc3_filtered&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tsv&lt;/span&gt; &lt;span class="n"&gt;mc3&lt;/span&gt;
&lt;span class="c1"&gt;-- Create an index to speed up grouping on the same columns&lt;/span&gt;
&lt;span class="k"&gt;CREATE&lt;/span&gt; &lt;span class="k"&gt;INDEX&lt;/span&gt; &lt;span class="n"&gt;mc3_idx&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;mc3&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transcript_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mutation_type&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="c1"&gt;-- Output&lt;/span&gt;
&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;once&lt;/span&gt; &lt;span class="k"&gt;out&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqlite&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tsv&lt;/span&gt;
&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;transcript_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mutation_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alt_allele&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;mc3&lt;/span&gt;
&lt;span class="k"&gt;GROUP&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;transcript_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mutation_type&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="postgresql_1"&gt;PostgreSQL&lt;/h3&gt;
&lt;p&gt;I used &lt;a href="https://pgloader.io/"&gt;pgloader&lt;/a&gt; to load the data into a local PostgreSQL database &lt;code&gt;test_mc3&lt;/code&gt;. pgloader can take a script of its own mini-language.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;LOAD CSV
    FROM &amp;#39;mc3_filtered.tsv&amp;#39;
    INTO postgresql:///test_mc3?mc3
    WITH fields terminated by &amp;#39;\t&amp;#39;,
         fields not enclosed,
         drop indexes
    BEFORE LOAD DO
    $$ DROP TABLE IF EXISTS mc3; $$,
    $$ CREATE TABLE mc3 (
            chrom       TEXT,
            &amp;quot;start&amp;quot;     BIGINT,
            &amp;quot;end&amp;quot;       BIGINT,
            strand      SMALLINT,
            mutation_type   TEXT,
            ref_allele  TEXT,
            alt_allele  TEXT,
            transcript_id   TEXT,
            hgvs_c      TEXT,
            hgvs_p      TEXT,
            cdna_start  INT,
            cdna_end    INT,
            p_start     INT,
            p_end       INT,
            normal_id   TEXT,
            tumor_id    TEXT
        );
    $$,
    $$ CREATE INDEX mc3_idx ON mc3 (transcript_id, mutation_type); $$
;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To do the grouping analysis, I used the built-in &lt;code&gt;COPY&lt;/code&gt; command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;COPY&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;transcript_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mutation_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;alt_allele&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;
    &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;mc3&lt;/span&gt;
    &lt;span class="k"&gt;GROUP&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;transcript_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mutation_type&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;TO&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/private/tmp/mc3/MC3/out.psql.tsv&amp;#39;&lt;/span&gt; &lt;span class="k"&gt;WITH&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;FORMAT&lt;/span&gt; &lt;span class="nb"&gt;TEXT&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="result"&gt;Result&lt;/h3&gt;
&lt;p&gt;I didn&amp;rsquo;t run it systematically but a few repeats showed the similar numbers.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Method&lt;/th&gt;
&lt;th align="right"&gt;Read data (sec)&lt;/th&gt;
&lt;th align="right"&gt;Group-by analysis (sec)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;Pandas&lt;/td&gt;
&lt;td align="right"&gt;10.7&lt;/td&gt;
&lt;td align="right"&gt;0.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;SQLite&lt;/td&gt;
&lt;td align="right"&gt;27.7&lt;/td&gt;
&lt;td align="right"&gt;4.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;PostgreSQL&lt;/td&gt;
&lt;td align="right"&gt;82.6&lt;/td&gt;
&lt;td align="right"&gt;13.5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In this case, all data can be loaded into memory easily, so pandas gave the best performance here. It actually took nearly no-time to complete the grouping.&lt;/p&gt;
&lt;p&gt;All databases ran much slower on loading data than pandas. PostgreSQL seems to run a lot more slower than SQLite, which I think it has something to do with my server configuration, say, not enough cache size, or not enough working memory for the group-by operation. I feel like PostgreSQL can be faster but anyway this&amp;rsquo;s the result I have so far. Note that all the databases are stored on a PCIe SSD disk. If they were on a normal hard drive, the database creation will take a much longer time.&lt;/p&gt;
&lt;p&gt;However, after the data are loaded into the database, the speed of the query alone is comparable to pandas. Because for pandas, one cannot skip the step of reading data so if the analysis is on a frequently used dataset, database like SQLite can yield better performance. Once the data get larger than the memory capacity, special care will be needed to make the pandas&amp;rsquo; approach work, whereas database can scale up with little fuss.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;My post provides a different solution to work with tabular data by working in a database. In-memory approaches like pandas work very efficiently at a small dataset but one will have to code the &amp;ldquo;how-tos&amp;rdquo; to scale to a larger dataset that cannot feed into memory (or the overhead is too high). On the other hand, databases can easily scale to a few hundred GBs in size and the query is fast. For analysis on a frequently used dataset, loading data into the database first might be a good idea.&lt;/p&gt;
&lt;p&gt;Another good thing about databases is that SQL makes joining across tables easily. One can easily join across multiple tables, say, expand the gene annotation and doesn&amp;rsquo;t have to worry how to implement it. With indexing, the joining can be fast. In pandas, one generates many objects representing the joining results, but those objects cannot be easily shared between scripts. Relying on storing the intermediate objects on disk, the accumulated overhead might be significant. Projects like &lt;a href="https://arrow.apache.org/"&gt;Apache Arrow&lt;/a&gt; might solve the in-memory object passing ultimately, but its development is still in the early phase. As for databases, one can define reusable views for the joining logic and filtering results. The post didn&amp;rsquo;t really touch this part so I probably need another benchmark or post to back my thoughts.&lt;/p&gt;
&lt;p&gt;If one is analyzing variants, using databases or SQL in general has been backed up by many pratical projects. People at &lt;a href="http://quinlanlab.org/"&gt;Quinlab Lab&lt;/a&gt; hace been building &lt;a href="https://github.com/quinlan-lab/vcf2db"&gt;vcf2db&lt;/a&gt; to load variants into databases for downstream annotation and analysis. To scale way up to terabytes or petabytes of variant data, &lt;a href="https://cloud.google.com/genomics/v1/analyze-variants"&gt;Google Cloud Genomics&lt;/a&gt; provides an interface to store and query variants in BigQuery, where users use standard SQL to select the variants of interest.&lt;/p&gt;
&lt;p&gt;However, working in pandas gives users great room for flexibility. For example, one can iterate over rows and do some complex transformation of the value. Maybe it would be the optimal solution to use &lt;a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql.html#pandas.read_sql"&gt;&lt;code&gt;pandas.read_sql&lt;/code&gt;&lt;/a&gt; to run a query in a database.&lt;/p&gt;
&lt;p&gt;It seems to me like many people rely too much on the features of some special file formats such as bgzip and tabix and have forgotten the generic yet flexible approach using databases. Those formats often optimize the random access by a given genomic query by indexing. In databases, such index is analogous to &lt;code&gt;(chrom, start, -end)&lt;/code&gt; or even GiST index on Range type in PostgreSQL. It might be slower in databases, but aside from the performance, one can continue to query the records in the same way in databases. For special format, the functionality will be much limited.&lt;/p&gt;
&lt;p&gt;Now I will give the database approach a try before writing my own data wrangling script.&lt;/p&gt;
&lt;p&gt;EDIT 2018-01-28: Add real world examples of using databases to store variant data.&lt;/p&gt;</content><category term="en"></category><category term="python"></category><category term="pandas"></category><category term="sqlite"></category><category term="postgresql"></category></entry><entry><title>Using EnsDb's annotation database in Python</title><link href="https://blog.liang2.tw/posts/2017/11/use-ensdb-database-in-python/" rel="alternate"></link><published>2017-11-17T00:00:00-06:00</published><updated>2017-11-17T00:00:00-06:00</updated><author><name>Liang-Bo Wang</name></author><id>tag:blog.liang2.tw,2017-11-17:/posts/2017/11/use-ensdb-database-in-python/</id><summary type="html">&lt;p&gt;How to find and download the EnsDb, the Ensembl genomic annotation in SQLite database made by R package ensembldb, and use it in Python application.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I found that there isn&amp;rsquo;t a systematic way to query and convert genomic annotation IDs in Python. At least there isn&amp;rsquo;t one as good as &lt;a href="https://www.bioconductor.org/help/workflows/annotation/annotation/"&gt;what R/Bioconductor currently has&lt;/a&gt;. If you&amp;rsquo;ve never heard of R/Bioconductor annotation tool stack before, check out &lt;a href="https://www.bioconductor.org/help/workflows/annotation/annotation/"&gt;the official workflow&lt;/a&gt; or &lt;a href="https://blog.liang2.tw/posts/2016/05/biocondutor-ensembl-reference/"&gt;my post in 2016&lt;/a&gt; specific for querying Ensembl annotations.&lt;/p&gt;
&lt;p&gt;Although I enjoy using R for genomic annotation conversion, a few days ago I wanted to do the same thing inside my text processing script in Python. I might be able to re-write the script in R but I feel like R is not really the right tool for this task and on top of it, I don&amp;rsquo;t know how to write an efficent text processing in R&lt;sup id="fnref:r-text-processing"&gt;&lt;a class="footnote-ref" href="#fn:r-text-processing" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. &lt;/p&gt;
&lt;p&gt;Knowing the fact that all annotations in R are stored in single-file SQLite databases, I should be able to connect the database directly Python or any other language and wirte SQL query to retrieve the same information. So my question now becomes to how to extract or find the path to the databases. Turn out that many new Bioconductor annotation packages are hosted via &lt;a href="https://bioconductor.org/packages/release/bioc/html/AnnotationHub.html"&gt;AnnotationHub&lt;/a&gt;, and user can search for the annotation package and retrieve them locally by their ID. For example, all the recent Ensembl releases, e.g., &lt;code&gt;EnsDb.Hsapiens.vXX&lt;/code&gt;, are available on AnnotationHub. &lt;/p&gt;
&lt;p&gt;After digging around a bit, I am able to query the AnnotationHub, download the correct EnsDB SQLite database file, and make SQL queries for the annotation ID conversion without any R package. I will share the details in the rest of the post. &lt;/p&gt;
&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#manual-query-in-annotationhub"&gt;Manual query in AnnotationHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#manual-query-in-ensdb"&gt;Manual query in EnsDB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;But before we start with the details, I want to clarify that it wasn&amp;rsquo;t my intention to persuade people away from the current R ecosystem. The current R ecosystem is great and I will recommend people to stick with it as much as you can. I am pretty sure I will hit a lot of issues if I want to do more complex analysis or queries without the help of what R packages provide.&lt;/p&gt;
&lt;h2 id="manual-query-in-annotationhub"&gt;Manual query in AnnotationHub&lt;/h2&gt;
&lt;p&gt;When one wants to use the R package AnnotationHub, the common usage is &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;AnnotationHub&lt;span class="p"&gt;)&lt;/span&gt;
ah &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; AnnotationHub&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;## snapshotDate(): 2017-10-27&lt;/span&gt;

query&lt;span class="p"&gt;(&lt;/span&gt;ah&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;EnsDb&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Homo sapiens&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The function call &lt;code&gt;AnnotationHub()&lt;/code&gt; will download the latest version of the metadata of all available annotation object. The subsequent &lt;code&gt;query(...)&lt;/code&gt; function will talk to the local metadata database.&lt;/p&gt;
&lt;p&gt;Now let&amp;rsquo;s do it manually without any R function calls.&lt;/p&gt;
&lt;p&gt;The default &lt;a href="https://bioconductor.org/packages/release/bioc/html/AnnotationHub.html"&gt;AnnotationHub&lt;/a&gt; is at &lt;a href="https://annotationhub.bioconductor.org/"&gt;https://annotationhub.bioconductor.org/&lt;/a&gt;. By visiting the page we can find several relevant endpoints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/metadata/annotationhub.sqlite3&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/fetch/:id # id =&amp;gt; rdatapaths.id&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So as long as we get the &lt;code&gt;rdatapaths.id&lt;/code&gt; of the EnsDb using the metadata, we can download it via the &lt;code&gt;/fetch/:id&lt;/code&gt; endpoint.&lt;/p&gt;
&lt;p&gt;After downloading the metadata database &lt;code&gt;https://annotationhub.bioconductor.org/metadata/annotationhub.sqlite3&lt;/code&gt;, we can inspect it in SQLite3 by connecting it directly:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sqlite3 annotationhub.sqlite3
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Some useful commands to inspect a foreign database (or the ultimate help command &lt;code&gt;.help&lt;/code&gt;): &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;sqlite&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;header&lt;/span&gt; &lt;span class="k"&gt;on&lt;/span&gt; 
&lt;span class="gp"&gt;sqlite&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;mode&lt;/span&gt; &lt;span class="k"&gt;column&lt;/span&gt;
&lt;span class="gp"&gt;sqlite&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tables&lt;/span&gt;
&lt;span class="go"&gt;biocversions       rdatapaths         schema_info        test             &lt;/span&gt;
&lt;span class="go"&gt;input_sources      recipes            statuses           timestamp        &lt;/span&gt;
&lt;span class="go"&gt;location_prefixes  resources          tags&lt;/span&gt;
&lt;span class="gp"&gt;sqlite&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;schema&lt;/span&gt; &lt;span class="n"&gt;rdatapaths&lt;/span&gt;
&lt;span class="go"&gt;CREATE TABLE `rdatapaths`(`id` integer DEFAULT (NULL) NOT NULL PRIMARY KEY , `rdatapath` varchar(255) DEFAULT (NULL) NULL, `rdataclass` varchar(255) DEFAULT (NULL) NULL, `resource_id` integer DEFAULT (NULL) NULL, `dispatchclass` varchar(255) DEFAULT (NULL) NULL, CONSTRAINT `rdatapaths_ibfk_1` FOREIGN KEY (`resource_id`) REFERENCES `resources`(`id`));&lt;/span&gt;
&lt;span class="go"&gt;CREATE INDEX `rdatapaths_resource_id` ON `rdatapaths` (`resource_id`);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So let&amp;rsquo;s make a SQL query to find all Human&amp;rsquo;s EnsDb:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ah_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rdp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;rdatapaths_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rdp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rdatapath&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;resources&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;
&lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;rdatapaths&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;rdp&lt;/span&gt;
&lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rdp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;resource_id&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="k"&gt;LIKE&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;%EnsDb for Homo Sapiens%&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="c1"&gt;-- ah_id       rdatapaths_id  rdatapath                               title                            &lt;/span&gt;
&lt;span class="c1"&gt;-- ----------  -------------  --------------------------------------  -- ---------------------------------&lt;/span&gt;
&lt;span class="c1"&gt;-- AH53211     59949          AHEnsDbs/v87/EnsDb.Hsapiens.v87.sqlite  Ensembl 87 EnsDb for Homo Sapiens&lt;/span&gt;
&lt;span class="c1"&gt;-- AH53715     60453          AHEnsDbs/v88/EnsDb.Hsapiens.v88.sqlite  Ensembl 88 EnsDb for Homo Sapiens&lt;/span&gt;
&lt;span class="c1"&gt;-- AH56681     63419          AHEnsDbs/v89/EnsDb.Hsapiens.v89.sqlite  Ensembl 89 EnsDb for Homo Sapiens&lt;/span&gt;
&lt;span class="c1"&gt;-- AH57757     64495          AHEnsDbs/v90/EnsDb.Hsapiens.v90.sqlite  Ensembl 90 EnsDb for Homo Sapiens&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All the Ensembl releases 87+ are available! I will use the release 90 for example. we can download it by its rdatapaths id:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;wget -O EnsDb.Hsapiens.v90.sqlite https://annotationhub.bioconductor.org/fetch/64495
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For older Ensembl release, one may need to &lt;a href="https://bioconductor.org/packages/release/bioc/vignettes/ensembldb/inst/doc/ensembldb.html#102_building_annotation_packages"&gt;build the SQLite database based by the instructions from ensembldb&lt;/a&gt;.  For the last GRCh37 release, Ensembl release 75, one can download the source of the Bioconductor annotation package &lt;a href="https://bioconductor.org/packages/release/data/annotation/html/EnsDb.Hsapiens.v75.html"&gt;&lt;code&gt;EnsDb.Hsapiens.v75&lt;/code&gt;&lt;/a&gt; and extract it. The database will be under &lt;code&gt;inst/extdata&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="manual-query-in-ensdb"&gt;Manual query in EnsDB&lt;/h2&gt;
&lt;p&gt;EnsDb SQLite database are Ensembl annotation databases created by the R package &lt;a href="https://bioconductor.org/packages/release/bioc/html/ensembldb.html"&gt;ensembldb&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here I will show how to find a transcript&amp;rsquo;s gene name, its genomic location, and all its exon locations given its Ensembl transcript ID.&lt;/p&gt;
&lt;p&gt;First connect the database by &lt;code&gt;sqlite3 EnsDb.Hsapiens.v90.sqlite&lt;/code&gt;. Its table design is very straightforward:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;sqlite&amp;gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tables&lt;/span&gt;
&lt;span class="go"&gt;chromosome      exon            metadata        protein_domain  tx2exon&lt;/span&gt;
&lt;span class="go"&gt;entrezgene      gene            protein         tx              uniprot&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So it didn&amp;rsquo;t take me long to figure out how to join the transcript and gene information:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tx_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gene_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gene&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gene_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;seq_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;seq_strand&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;tx&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;gene&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;tx&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gene_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gene&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gene_id&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;tx_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ENST00000358731&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="c1"&gt;-- tx_id            gene_id          gene_name   seq_name    seq_strand&lt;/span&gt;
&lt;span class="c1"&gt;-- ---------------  ---------------  ----------  ----------  ----------&lt;/span&gt;
&lt;span class="c1"&gt;-- ENST00000358731  ENSG00000145734  BDP1        5           1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And for the genomic ranges of its exon:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="n"&gt;tx_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;exon_idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;exon_seq_start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;exon_seq_end&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;tx2exon&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;exon&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;tx2exon&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exon_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;exon&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exon_id&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;tx_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;ENST00000380139&amp;#39;&lt;/span&gt;
&lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;exon_idx&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="c1"&gt;-- tx_id            exon_idx    exon_seq_start  exon_seq_end&lt;/span&gt;
&lt;span class="c1"&gt;-- ---------------  ----------  --------------  ------------&lt;/span&gt;
&lt;span class="c1"&gt;-- ENST00000380139  1           32427904        32428133    &lt;/span&gt;
&lt;span class="c1"&gt;-- ENST00000380139  2           32407645        32407772    &lt;/span&gt;
&lt;span class="c1"&gt;-- ENST00000380139  3           32407250        32407338    &lt;/span&gt;
&lt;span class="c1"&gt;-- ENST00000380139  4           32404203        32404271    &lt;/span&gt;
&lt;span class="c1"&gt;-- ENST00000380139  5           32400723        32403200  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All the coordinates are 1-based and the ranges are inclusive.&lt;/p&gt;
&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;
&lt;p&gt;By downloading the underlying annotation database, one can do the same annotation query out of R language and sometimes it may be helpful. I feel like instead of trying to come up with my own layout of annotation mapping across multiple sources, it is more reliable to use a more official build. On the other hand, it is very hard to get the annotaion mapping correct and there are tons of corner cases that require careful and systematic decisions. So I don&amp;rsquo;t really recommend to build my own mapping at the first place anyway. The method here should help the situation of annotation query out of R a bit.&lt;/p&gt;
&lt;p&gt;Potentially one can try copy the full R infrastructure but using the same underlying database and replicate the same experience to other languages, but it might require substantial work to get the infrastructure done and correct.&lt;/p&gt;
&lt;p&gt;EDIT 2017-12-13: Add instructions of using older Ensembl release.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:r-text-processing"&gt;
&lt;p&gt;Based on my impression, my R expert friends would probably recommend me to write it with R-cpp, which I think would be over-kill for such a small task. But my impression can be wrong. Feel free to share your thoughts!&amp;#160;&lt;a class="footnote-backref" href="#fnref:r-text-processing" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="en"></category><category term="python"></category><category term="r"></category><category term="bioconductor"></category><category term="ensembldb"></category></entry><entry><title>Use Snakemake on Google cloud</title><link href="https://blog.liang2.tw/posts/2017/08/snakemake-google-cloud/" rel="alternate"></link><published>2017-08-10T00:00:00-05:00</published><updated>2017-08-10T00:00:00-05:00</updated><author><name>Liang-Bo Wang</name></author><id>tag:blog.liang2.tw,2017-08-10:/posts/2017/08/snakemake-google-cloud/</id><summary type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; Run a RNA-seq pipeline using Snakemake locally and later port it to Google Cloud. Snakemake can parallelize jobs of a pipeline and …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; Run a RNA-seq pipeline using Snakemake locally and later port it to Google Cloud. Snakemake can parallelize jobs of a pipeline and even across machines.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://snakemake.readthedocs.io/"&gt;Snakemake&lt;/a&gt; has been my favorite workflow management system for a while. I came across it while writing &lt;a href="https://www.dropbox.com/s/u7aa2mbsto77wwy/thesis_upload.pdf?dl=0"&gt;my master thesis&lt;/a&gt; and from the first look, it already appeared to be extremely flexible and powerful. I got some time to play with it during my lab rotation and now after joining the lab, I am using it in my many research projects.  With more and more projects in lab relying on virtualization like &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;, package management like &lt;a href="https://bioconda.github.io/"&gt;bioconda&lt;/a&gt;, and cloud computing like &lt;a href="https://cloud.google.com/"&gt;Google Cloud&lt;/a&gt;, I would like to continue using Snakemake in those scenarios as well. Hence this post to write down all the details.&lt;/p&gt;
&lt;p&gt;The post will introduce the Snakemake by writing the pipeline locally, then gradually move towards to Docker and more Google Cloud products, e.g., Google Cloud Storage, Google Compute Engine (GCE), and Google Container Engine (GKE). &lt;a href="https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html"&gt;Snakemake tutorial&lt;/a&gt; is a good place to start with to understand how Snakemake works.&lt;/p&gt;
&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#rna-seq-dataset-and-pipeline-for-demonstration"&gt;RNA-seq dataset and pipeline for demonstration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#installation-of-snakemake-and-all-related-tools"&gt;Installation of snakemake and all related tools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#snakemake-local-pipeline-execution"&gt;Snakemake local pipeline execution&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#genome-reference-index-build-how-to-write-snakemake-rules"&gt;Genome reference index build (How to write snakemake rules)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#run-snakemake"&gt;Run Snakemake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sample-alignment-how-to-write-a-general-rule"&gt;Sample alignment (How to write a general rule)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#transcript-assement"&gt;Transcript assement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#job-dependencies-and-dag"&gt;Job dependencies and DAG&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#snakemake-on-google-cloud"&gt;Snakemake on Google Cloud&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#move-input-files-to-the-cloud-from-google-cloud-storage"&gt;Move input files to the cloud (from Google Cloud Storage)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#store-output-files-on-the-cloud"&gt;Store output files on the cloud&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#dockerize-the-environment"&gt;Dockerize the environment&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#use-google-cloud-storage-in-docker-image"&gt;Use Google Cloud Storage in Docker image&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#google-container-engine-gke"&gt;Google Container Engine (GKE)&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#potential-issues-of-using-gke-with-snakemake"&gt;Potential issues of using GKE with Snakemake&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h2 id="rna-seq-dataset-and-pipeline-for-demonstration"&gt;RNA-seq dataset and pipeline for demonstration&lt;/h2&gt;
&lt;p&gt;In this example, I will use &lt;code&gt;~/snakemake_example&lt;/code&gt; to store all the files and output. Make sure you change all the paths to be relative to the actual folder in your machine.&lt;/p&gt;
&lt;p&gt;The demo pipeline will be a RNA-seq pipeline for transcript-level expression analysis, often called the &lt;a href="https://www.nature.com/nprot/journal/v11/n9/full/nprot.2016.095.html"&gt;&lt;em&gt;new Tuxedo&lt;/em&gt;&lt;/a&gt; pipeline involving &lt;a href="https://ccb.jhu.edu/software/hisat2/"&gt;HISAT2&lt;/a&gt; and &lt;a href="https://ccb.jhu.edu/software/stringtie/"&gt;StringTie&lt;/a&gt;. The RNA-seq dataset is from &lt;a href="https://github.com/griffithlab/rnaseq_tutorial/"&gt;Griffith Lab&amp;rsquo;s RNA-seq tutorial&lt;/a&gt; which,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;hellip; consists of two commercially available RNA samples: Universal Human Reference (UHR) and Human Brain Reference (HBR). The UHR is total RNA isolated from a diverse set of 10 cancer cell lines. The HBR is total RNA isolated from the brains of 23 Caucasians, male and female, of varying age but mostly 60-80 years old.&lt;/p&gt;
&lt;p&gt;(From the wiki page &lt;a href="[griffith-lab-data]"&gt;&amp;ldquo;RNA-seq Data&amp;rdquo;&lt;/a&gt; of the tutorial)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Our RNA-seq raw data are the 10% downsampled FASTQ files for these samples. For the human genome reference, only the chromosome 22 from GRCh38 is used. The gene annotation is from &lt;a href="http://dec2016.archive.ensembl.org/Homo_sapiens/Info/Index"&gt;Ensembl Version 87&lt;/a&gt;.  Let&amp;rsquo;s download all the samples and annotations.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nb"&gt;cd&lt;/span&gt; ~/snakemake_example
&lt;span class="gp"&gt;$&lt;/span&gt; wget https://storage.googleapis.com/lbwang-playground/snakemake_rnaseq/griffithlab_brain_vs_uhr.tar.gz
&lt;span class="gp"&gt;$&lt;/span&gt; tar xf griffithlab_brain_vs_uhr.tar.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now you should have the following file structure:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;~/snakemake_example
├── griffithlab_brain_vs_uhr/
│   ├── GRCh38_Ens87_chr22_ERCC/
│   │   ├── chr22_ERCC92.fa
│   │   └── genes_chr22_ERCC92.gtf
│   └── HBR_UHR_ERCC_ds_10pc/
│       ├── HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read1.fastq.gz
│       ├── HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read2.fastq.gz
│       ├── ...
│       ├── UHR_Rep3_ERCC-Mix1_Build37-ErccTranscripts-chr22.read1.fastq.gz
│       └── UHR_Rep3_ERCC-Mix1_Build37-ErccTranscripts-chr22.read2.fastq.gz
└── griffithlab_brain_vs_uhr.tar.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="installation-of-snakemake-and-all-related-tools"&gt;Installation of snakemake and all related tools&lt;/h2&gt;
&lt;p&gt;After installing &lt;a href="https://conda.io/miniconda.html"&gt;conda&lt;/a&gt; and setting up &lt;a href="https://bioconda.github.io/"&gt;bioconda&lt;/a&gt;, the installation is simple. All the dependencies are kept in a conda environment called &lt;code&gt;new_tuxedo&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; conda create -n new_tuxedo &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="nv"&gt;python&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.6 snakemake hisat2 stringtie samtools
&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nb"&gt;source&lt;/span&gt; activate new_tuxedo        &lt;span class="c1"&gt;# Use the conda env&lt;/span&gt;
&lt;span class="gp"&gt;(new_tuxedo) $&lt;/span&gt; hisat2 --version     &lt;span class="c1"&gt;# Tools are available in the env&lt;/span&gt;
&lt;span class="go"&gt;/Users/liang/miniconda3/envs/new_tuxedo/bin/hisat2-align-s version 2.1.0&lt;/span&gt;
&lt;span class="go"&gt;...&lt;/span&gt;
&lt;span class="gp"&gt;(new_tuxedo) $&lt;/span&gt; deactivate           &lt;span class="c1"&gt;# Exit the env&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; hisat2 --version                  &lt;span class="c1"&gt;# Tools are isolated in the env&lt;/span&gt;
&lt;span class="go"&gt;bash: hisat2: command not found&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All the following steps should be run inside this conda environment unless it&amp;rsquo;s specified otherwise.&lt;/p&gt;
&lt;h2 id="snakemake-local-pipeline-execution"&gt;Snakemake local pipeline execution&lt;/h2&gt;
&lt;p&gt;The RNA-seq pipeline largely consists of the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Build HISAT2 genome reference index for alignment&lt;/li&gt;
&lt;li&gt;Align sample reads to the genome by HISAT2&lt;/li&gt;
&lt;li&gt;Assemble per-sample transcripts by StringTie&lt;/li&gt;
&lt;li&gt;Merge per-sample transcripts by StringTie&lt;/li&gt;
&lt;li&gt;Quantify transcript abundance by StringTie&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To get the taste of how to write a Snakemake pipeline, I will implement it gradually by breaking it into three major parts: genome reference index build, alignment, and transcript assessment.&lt;/p&gt;
&lt;h3 id="genome-reference-index-build-how-to-write-snakemake-rules"&gt;Genome reference index build (How to write snakemake rules)&lt;/h3&gt;
&lt;p&gt;To build the genome reference, we need to extract the splice sites and exons by two of the HISAT2 scripts, &lt;code&gt;hisat2_extract_splice_sites.py&lt;/code&gt; and &lt;code&gt;hisat2_extract_exons.py&lt;/code&gt;. Then we call &lt;code&gt;hisat2-build&lt;/code&gt; to build the index. Create a new file at &lt;code&gt;~/snakemake_example/Snakefile&lt;/code&gt; with the following content:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;GENOME_FA&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;griffithlab_brain_vs_uhr/GRCh38_Ens87_chr22_ERCC/chr22_ERCC92.fa&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;GENOME_GTF&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;griffithlab_brain_vs_uhr/GRCh38_Ens87_chr22_ERCC/genes_chr22_ERCC92.gtf&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;HISAT2_INDEX_PREFIX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;hisat2_index/chr22_ERCC92&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;extract_genome_splice_sites&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;GENOME_GTF&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;hisat2_index/chr22_ERCC92.ss&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;hisat2_extract_splice_sites.py {input} &amp;gt; {output}&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;extract_genome_exons&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;GENOME_GTF&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;hisat2_index/chr22_ERCC92.exon&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;hisat2_extract_exons.py {input} &amp;gt; {output}&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;build_hisat_index&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;genome_fa&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;GENOME_FA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;splice_sites&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;hisat2_index/chr22_ERCC92.ss&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;exons&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;hisat2_index/chr22_ERCC92.exon&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;expand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;{HISAT2_INDEX_PREFIX}.{{ix}}.ht2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ix&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;hisat2_index/build.log&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;hisat2-build -p {threads} {input.genome_fa} &amp;quot;&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;--ss {input.splice_sites} --exon {input.exons} {HISAT2_INDEX_PREFIX} &amp;quot;&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;2&amp;gt;{log}&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Overall &lt;code&gt;Snakefile&lt;/code&gt; is Python-based, so one can define variables and functions, import Python libraries, and use all the string operations as one does in the Python source code.  Here I defined some constants to the genome reference files (&lt;code&gt;GENOME_FA&lt;/code&gt; and &lt;code&gt;GENOME_GTF&lt;/code&gt;) and the output index prefix (&lt;code&gt;HISAT2_INDEX_PREFIX&lt;/code&gt;) because they will get quite repetitive and specifying them at the front can make future modifications easier.&lt;/p&gt;
&lt;p&gt;In case one hasn&amp;rsquo;t read the &lt;a href="https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html"&gt;Snakemake Tutorial&lt;/a&gt;, here is an overview of the Snakemake pipeline execution.  A Snakemake rule is similar to a Makefile rule.  In a rule, one can specify the input pattern and the output pattern of a rule, as well as the command to run for this rule.  When snakemake runs, all the output user wants to generate will be translated into a sets of rules to be run.  Based on the desired output, Snakemake will find the rule that can generate them (matching the rule&amp;rsquo;s output pattern) and the required input.  The finding process can be traversed rules after rules, that is, some input of a rule depends on the output of another rule, until all the inputs are available.  Then Snakemake will start to generate the output by running the commands each rule gives.&lt;/p&gt;
&lt;p&gt;Now we can look at the three rules in our current &lt;code&gt;Snakefile&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The first rule &lt;code&gt;extract_genome_splice_sites&lt;/code&gt; extracts the genome splice sites. The input file is &lt;code&gt;GENOME_GTF&lt;/code&gt; which is the Ensembl gene annotation. The output is a file at &lt;code&gt;hisat2_index/chr22_ERCC92.ss&lt;/code&gt;. The command to generate the output from the given input is a shell command. The command contains some variables, &lt;code&gt;{input}&lt;/code&gt; and &lt;code&gt;{output}&lt;/code&gt;, where Snakemake will fill in them with the sepcified intput and output. So when the first rule is activated, Snakemake will let Bash shell to run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;hisat2_extract_splice_sites.py &lt;span class="se"&gt;\&lt;/span&gt;
    griffithlab_brain_vs_uhr/GRCh38_Ens87_chr22_ERCC/genes_chr22_ERCC92.gtf &lt;span class="se"&gt;\&lt;/span&gt;
    &amp;gt; hisat2_index/chr22_ERCC92.ss
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The second rule &lt;code&gt;extract_genome_exons&lt;/code&gt; is quite similar to the first one, but extracts the genome exons and stores it in &lt;code&gt;hisat2_index/chr22_ERCC92.exon&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The third rule &lt;code&gt;build_hisat_index&lt;/code&gt; builds the actual index. Input can be multiple files, in this case there are three entries, including the chromosome sequence, splice sites and exons. One can later refer only to input of the same entry by their entry name. For example, &lt;code&gt;{input.genome_fa}&lt;/code&gt; means the chromosome sequence FASTA file.&lt;/p&gt;
&lt;p&gt;The output of the third rule is &lt;code&gt;expand(f"{HISAT2_INDEX_PREFIX}.{{ix}}.ht2", ix=range(1, 9))&lt;/code&gt;, where &lt;code&gt;expand(...)&lt;/code&gt; is a Snakemake function which can interpolate a string pattern into an array of strings. In this case the generate index files are &lt;code&gt;&amp;lt;index_prefix&amp;gt;.1.ht2&lt;/code&gt;, &amp;hellip; ,&lt;code&gt;&amp;lt;index_prefix&amp;gt;.8.ht2&lt;/code&gt;. Instead of specifies the output eight times, we use &lt;code&gt;expand&lt;/code&gt; and pass a variable &lt;code&gt;ix&lt;/code&gt; to iterate from 1 to 8. The double curly brackets are to escape the &lt;code&gt;f"..."&lt;/code&gt; f-string interpolation (see &lt;a href="https://docs.python.org/3/whatsnew/3.6.html#whatsnew36-pep498"&gt;the Python documentation&lt;/a&gt;). So the whole process to interpret the output is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;expand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;{HISAT2_INDEX_PREFIX}.{{ix}}.ht2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ix&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;expand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;hisat2_index/chr22_ERCC92.{ix}.ht2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ix&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;hisat2_index/chr22_ERCC92.1.ht2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;hisat2_index/chr22_ERCC92.2.ht2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;hisat2_index/chr22_ERCC92.8.ht2&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For the rest of the entries such as &lt;code&gt;threads&lt;/code&gt;, and &lt;code&gt;log&lt;/code&gt;, one can find more information at &lt;a href="https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html"&gt;the Snakemake documentation about Rules&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="run-snakemake"&gt;Run Snakemake&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s build the genome reference index.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; snakemake -j &lt;span class="m"&gt;8&lt;/span&gt; -p build_hisat_index
&lt;span class="go"&gt;Provided cores: 8&lt;/span&gt;
&lt;span class="go"&gt;Rules claiming more threads will be scaled down.&lt;/span&gt;
&lt;span class="go"&gt;Job counts:&lt;/span&gt;
&lt;span class="go"&gt;    count   jobs&lt;/span&gt;
&lt;span class="go"&gt;    1   build_hisat_index&lt;/span&gt;
&lt;span class="go"&gt;    1   extract_genome_exons&lt;/span&gt;
&lt;span class="go"&gt;    1   extract_genome_splice_sites&lt;/span&gt;
&lt;span class="go"&gt;    3&lt;/span&gt;

&lt;span class="go"&gt;rule extract_genome_exons:&lt;/span&gt;
&lt;span class="go"&gt;    input: griffithlab_brain_vs_uhr/GRCh38_Ens87_chr22_ERCC/genes_chr22_ERCC92.gtf&lt;/span&gt;
&lt;span class="go"&gt;    output: hisat2_index/chr22_ERCC92.exon&lt;/span&gt;
&lt;span class="go"&gt;    jobid: 1&lt;/span&gt;

&lt;span class="go"&gt;hisat2_extract_exons.py griffithlab_brain_vs_uhr/GRCh38_Ens87_chr22_ERCC/genes_chr22_ERCC92.gtf &amp;gt; hisat2_index/chr22_ERCC92.exon&lt;/span&gt;
&lt;span class="go"&gt;...&lt;/span&gt;
&lt;span class="go"&gt;3 of 3 steps (100%) done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The command &lt;code&gt;snakemake -j 8 -p build_hisat_index&lt;/code&gt; means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-j 8&lt;/code&gt;: Use 8 cores&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-p&lt;/code&gt;: Print the actual command of each job&lt;/li&gt;
&lt;li&gt;&lt;code&gt;build_hisat_index&lt;/code&gt;: The rule or certain output to be generated&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If one runs it again, one will find that snakemake won&amp;rsquo;t do anything since all the output are present and updated.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; snakemake -j &lt;span class="m"&gt;8&lt;/span&gt; -p build_hisat_index
&lt;span class="go"&gt;Nothing to be done.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="sample-alignment-how-to-write-a-general-rule"&gt;Sample alignment (How to write a general rule)&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s write the rule to do the sample alignment. Append the &lt;code&gt;Snakefile&lt;/code&gt; with the following content:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SAMPLES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;glob_wildcards&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;griffithlab_brain_vs_uhr/HBR_UHR_ERCC_ds_10pc/{sample}.read1.fastq.gz&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;align_hisat&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;hisat2_index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;expand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;{HISAT2_INDEX_PREFIX}.{{ix}}.ht2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ix&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
        &lt;span class="n"&gt;fastq1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;griffithlab_brain_vs_uhr/HBR_UHR_ERCC_ds_10pc/{sample}.read1.fastq.gz&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;fastq2&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;griffithlab_brain_vs_uhr/HBR_UHR_ERCC_ds_10pc/{sample}.read2.fastq.gz&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;align_hisat2/{sample}.bam&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;align_hisat2/{sample}.log&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;hisat2 -p {threads} --dta -x {HISAT2_INDEX_PREFIX} &amp;quot;&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;-1 {input.fastq1} -2 {input.fastq2} 2&amp;gt;{log} | &amp;quot;&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;samtools sort -@ {threads} -o {output}&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;align_all_samples&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;expand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;align_hisat2/{sample}.bam&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;SAMPLES&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There are two rules here but only &lt;code&gt;align_hisat&lt;/code&gt; does the real work. The rule looks familar but there are something new. There is a unresolved variable &lt;code&gt;{sample}&lt;/code&gt; in input, output and log entries, such as &lt;code&gt;fastq1=".../{sample}.read1.fastq.gz"&lt;/code&gt;. So this rule will apply to all outputs that match the pattern &lt;code&gt;align_hisat2/{sample}.bam&lt;/code&gt;. For example, given an output &lt;code&gt;align_hisat2/mysample.bam&lt;/code&gt;, Snakemake will look for the inputs &lt;code&gt;griffithlab_brain_vs_uhr/HBR_UHR_ERCC_ds_10pc/mysample.read1.fastq.gz&lt;/code&gt;, where &lt;code&gt;sample = "mysample"&lt;/code&gt; in this case.&lt;/p&gt;
&lt;p&gt;To get the names of all the samples, we use &lt;code&gt;glob_wildcards(...)&lt;/code&gt; which finds all the files that match the given string pattern, and collects the possible values of the variables in the string pattern as a list. Hence all the sample names are stored in &lt;code&gt;SAMPLES&lt;/code&gt;, and the other rule takes input of all samples&amp;rsquo; BAM files to generate alignment of all samples.&lt;/p&gt;
&lt;p&gt;Now run Snakemake again with a different rule target:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;snakemake -j 8 -p align_all_samples
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This time pay attention to the CPU usage (say, using &lt;a href="http://hisham.hm/htop/"&gt;&lt;code&gt;htop&lt;/code&gt;&lt;/a&gt;), one should find out that snakemake runs jobs in parallel, and tries to use as many cores as possible.&lt;/p&gt;
&lt;h3 id="transcript-assement"&gt;Transcript assement&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s complete the whole pipeline by adding all StringTie steps to &lt;code&gt;Snakefile&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;

&lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;stringtie_assemble&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;genome_gtf&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;GENOME_GTF&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;bam&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;align_hisat2/{sample}.bam&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;stringtie/assembled/{sample}.gtf&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;stringtie -p {threads} -G {input.genome_gtf} &amp;quot;&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;-o {output} -l {wildcards.sample} {input.bam}&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;stringtie_merge_list&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;expand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;stringtie/assembled/{sample}.gtf&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;SAMPLES&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;stringtie/merged_list.txt&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;gtf&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gtf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;resolve&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;stringtie_merge&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;genome_gtf&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;GENOME_GTF&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;merged_list&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;stringtie/merged_list.txt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;sample_gtfs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;expand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;stringtie/assembled/{sample}.gtf&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;SAMPLES&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;stringtie/merged.gtf&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;stringtie --merge -p {threads} -G {input.genome_gtf} &amp;quot;&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;-o {output} {input.merged_list}&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;stringtie_quant&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;merged_gtf&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;stringtie/merged.gtf&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;sample_bam&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;align_hisat2/{sample}.bam&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;gtf&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;stringtie/quant/{sample}/{sample}.gtf&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;ctabs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;expand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;stringtie/quant/{{sample}}/{name}.ctab&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;i2t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;e2t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;i_data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;e_data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;t_data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;stringtie -e -B -p {threads} -G {input.merged_gtf} &amp;quot;&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;-o {output.gtf} {input.sample_bam}&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;quant_all_samples&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;expand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;stringtie/quant/{sample}/{sample}.gtf&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;SAMPLES&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Most rules are similar to the previous ones except for &lt;code&gt;stringtie_merge_list&lt;/code&gt;. This step a file is generated to contain list of paths to all the samples&amp;rsquo; GTF file. Instead of running some command (no &lt;code&gt;shell&lt;/code&gt; entry), a &lt;code&gt;run&lt;/code&gt; entry is used to write a Python code snippet to generate the file.&lt;/p&gt;
&lt;p&gt;Another thing to be noted is the output entry &lt;code&gt;ctabs=...&lt;/code&gt; of &lt;code&gt;stringtie_quant&lt;/code&gt;. The following lines are equivalent:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Before expansion&lt;/span&gt;
&lt;span class="n"&gt;ctabs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;expand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;stringtie/quant/{{sample}}/{name}.ctab&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;i2t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;e2t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;i_data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;e_data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;t_data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# After expansion&lt;/span&gt;
&lt;span class="n"&gt;ctabs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;stringtie/quant/{sample}/i2t.ctab&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;stringtie/quant/{sample}/e2t.ctab&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s2"&gt;&amp;quot;stringtie/quant/{sample}/t_data.ctab&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The full &lt;code&gt;Snakefile&lt;/code&gt; can be found &lt;a href="https://gist.github.com/ccwang002/2659b19439b6205284c0ae68ca06345d"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="job-dependencies-and-dag"&gt;Job dependencies and DAG&lt;/h3&gt;
&lt;p&gt;Now with the pipeline complete, we can further look at the how all the rules are chained with each other. Snakemake has a command to generate the job depedency graph (a DAG):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;snakemake --dag quant_all_samples | dot -Tsvg &amp;amp;gt; dag.svg
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure full-img"&gt;
  &lt;img src="https://blog.liang2.tw/posts/2017/08/snakemake-google-cloud/pics/snakemake_rnaseq_dag.svg"/&gt;
  &lt;p class="caption"&gt;Snakemake job dependency graph.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Snakemake generates such DAG first before execution, where each node represents a job. As long as two nodes have no connected edges and their input exist, they can be executed parallely. This is a powerful feature to pipeline management, which can use the resources in a fin grain.&lt;/p&gt;
&lt;p&gt;A simpler graph that shows rules instead of jobs can be generated by:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;snakemake --rulegraph quant_all_samples | dot -Tsvg &amp;amp;gt; ruledag.svg
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
  &lt;img src="https://blog.liang2.tw/posts/2017/08/snakemake-google-cloud/pics/snakemake_rnaseq_ruledag.svg"/&gt;
  &lt;p class="caption"&gt;Snakemake rule dependency graph.&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id="snakemake-on-google-cloud"&gt;Snakemake on Google Cloud&lt;/h2&gt;
&lt;p&gt;Now we start to move our Snakemake pipeline to the Google Cloud. To complete all the following steps, one needs a Google account and has a bucket on the Google Cloud with write access. That is, be able to upload the output back to Google Cloud Storage. Snakemake is able to download/upload files from the cloud, one needs to &lt;a href="https://cloud.google.com/sdk/downloads"&gt;set up the Google Cloud SDK on the local machine&lt;/a&gt; and create the default application credentials:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gcloud auth application-default login
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Also, install the neccessary Python packages to give Snakemake the access to storage API:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;conda install google-cloud-storage
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Actually snakemake support remote files from many more providers. More detail can be found at &lt;a href="https://snakemake.readthedocs.io/en/stable/snakefiles/remote_files.html"&gt;the Snakemake documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note that although one can run this section on a local machine, this step will be significantly faster if one runs it on a Google Computer Engine (GCE) instance. It also saves extra bandwidth and fees.&lt;/p&gt;
&lt;h3 id="move-input-files-to-the-cloud-from-google-cloud-storage"&gt;Move input files to the cloud (from Google Cloud Storage)&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s modify the &lt;code&gt;Snakefile&lt;/code&gt; to use the reference and FASTQ files from Google Cloud Storage. Replace those file paths with the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;snakemake.remote.GS&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RemoteProvider&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;GSRemoteProvider&lt;/span&gt;
&lt;span class="n"&gt;GS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GSRemoteProvider&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;GS_PREFIX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;lbwang-playground/snakemake_rnaseq&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;GENOME_FA&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;GS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;{GS_PREFIX}/griffithlab_brain_vs_uhr/GRCh38_Ens87_chr22_ERCC/chr22_ERCC92.fa&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;GENOME_GTF&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;{GS_PREFIX}/griffithlab_brain_vs_uhr/GRCh38_Ens87_chr22_ERCC/genes_chr22_ERCC92.gtf&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;HISAT2_INDEX_PREFIX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;hisat2_index/chr22_ERCC92&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;SAMPLES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;GS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glob_wildcards&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;GS_PREFIX&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/griffithlab_brain_vs_uhr/HBR_UHR_ERCC_ds_10pc/{sample}.read1.fastq.gz&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# rule extract_genome_splice_sites:&lt;/span&gt;
&lt;span class="c1"&gt;# ...&lt;/span&gt;

&lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;align_hisat&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;hisat2_index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;expand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;{HISAT2_INDEX_PREFIX}.{{ix}}.ht2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ix&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
        &lt;span class="n"&gt;fastq1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;GS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;GS_PREFIX&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;/griffithlab_brain_vs_uhr/HBR_UHR_ERCC_ds_10pc/{sample}.read1.fastq.gz&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;fastq2&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;GS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;GS_PREFIX&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;/griffithlab_brain_vs_uhr/HBR_UHR_ERCC_ds_10pc/{sample}.read2.fastq.gz&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="c1"&gt;# ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now all the file paths are on Google Cloud Storage under the bucket &lt;code&gt;lbwang-playground&lt;/code&gt;. For example, &lt;code&gt;GENOME_FA&lt;/code&gt; points to &lt;code&gt;gs://lbwang-playground/snakemake_rnaseq/griffithlab_brain_vs_uhr/GRCh38_Ens87_chr22_ERCC/chr22_ERCC92.fa&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;One could launch Snakemake again:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;snakemake --timestamp -p --verbose --keep-remote -j 8 quant_all_samples
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="store-output-files-on-the-cloud"&gt;Store output files on the cloud&lt;/h3&gt;
&lt;p&gt;Although we could replace all the file paths to &lt;code&gt;GS.remote(...)&lt;/code&gt;, there is a simpler way to replace every path through the command line option. On top of that, we need to add a &lt;code&gt;FULL_HISAT2_INDEX_PREFIX&lt;/code&gt; variable to reflect the path change that prepends the path under the writable bucket. Replace all &lt;code&gt;{WRITABLE_BUCKET_PATH}&lt;/code&gt; with a writable Google Cloud Storage bucket.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;HISAT2_INDEX_PREFIX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;hisat2_index/chr22_ERCC92&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;FULL_HISAT2_INDEX_PREFIX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;{WRITABLE_BUCKET_PATH}/hisat2_index/chr22_ERCC92&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;build_hisat_index&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# ...&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;hisat2-build -p {threads} {input.genome_fa} &amp;quot;&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;--ss {input.splice_sites} --exon {input.exons} {FULL_HISAT2_INDEX_PREFIX} &amp;quot;&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;2&amp;gt;{log}&amp;quot;&lt;/span&gt;

&lt;span class="n"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;align_hisat&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# ...&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;hisat2 -p {threads} --dta -x {FULL_HISAT2_INDEX_PREFIX} &amp;quot;&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;-1 {input.fastq1} -2 {input.fastq2} 2&amp;gt;{log} | &amp;quot;&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;samtools sort -@ {threads} -o {output}&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The full &lt;code&gt;Snakefile&lt;/code&gt; can be found &lt;a href="https://gist.github.com/ccwang002/2686840e90574a67a673ec4b48e9f036"&gt;here&lt;/a&gt;. Now run the Snakemake with the following options:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;snakemake --timestamp -p --verbose --keep-remote -j &lt;span class="m"&gt;8&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
        --default-remote-provider GS &lt;span class="se"&gt;\&lt;/span&gt;
        --default-remote-prefix &lt;span class="o"&gt;{&lt;/span&gt;WRITABLE_BUCKET_PATH&lt;span class="o"&gt;}&lt;/span&gt; &amp;gt; &lt;span class="se"&gt;\&lt;/span&gt;
        quant_all_samples
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To understand how the whole remote files work, here is the the folder structure after the exection:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;~/snakemake_example
├── lbwang-playground/
│   └── snakemake_rnaseq/
│       └── griffithlab_brain_vs_uhr/
│           ├── GRCh38_Ens87_chr22_ERCC/
│           └── HBR_UHR_ERCC_ds_10pc/
├── {WRITABLE_BUCKET_PATH}/
│   ├── align_hisat2/
│   ├── hisat2_index/
│   └── stringtie/
└── Snakefile
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So Snakemake simply downloads/generates the files with the full path on remote storage.&lt;/p&gt;
&lt;h2 id="dockerize-the-environment"&gt;Dockerize the environment&lt;/h2&gt;
&lt;p&gt;Although bioconda has made the package installation very easy, it would be easier to just isolate the whole environment at the operating system level. One common approach is to use &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A minimal working Dockerfile would be:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="s"&gt; continuumio/miniconda3&lt;/span&gt;
&lt;span class="k"&gt;RUN&lt;/span&gt; conda install -y &lt;span class="nv"&gt;python&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.6 nomkl &lt;span class="se"&gt;\&lt;/span&gt;
        stringtie samtools hisat2 snakemake google-cloud-storage &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; conda clean -y --all
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;However there are some details required extra care at the time of writing, so I&amp;rsquo;ve created a Docker image for this pipeline on Docker Hub, &lt;a href="https://hub.docker.com/r/lbwang/snakemake-conda-rnaseq/"&gt;&lt;code&gt;lbwang/snakemake-conda-rnaseq&lt;/code&gt;&lt;/a&gt;. One could be able to run the snakemake by:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; ~/snakemake_example
docker run -t                       &lt;span class="se"&gt;\&lt;/span&gt;
    -v &lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;:/analysis             &lt;span class="se"&gt;\&lt;/span&gt;
    lbwang/snakemake-conda-rnaseq   &lt;span class="se"&gt;\&lt;/span&gt;
    snakemake -j &lt;span class="m"&gt;2&lt;/span&gt; --timestamp      &lt;span class="se"&gt;\&lt;/span&gt;
        -s /analysis/Snakefile --directory /analysis &lt;span class="se"&gt;\&lt;/span&gt;
        quant_all_samples
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="use-google-cloud-storage-in-docker-image"&gt;Use Google Cloud Storage in Docker image&lt;/h3&gt;
&lt;p&gt;To use Google&amp;rsquo;s Cloud products in a Docker image, one needs to install &lt;a href="https://cloud.google.com/sdk/downloads"&gt;Google Cloud SDK&lt;/a&gt; inside the Docker image. Refer to &lt;a href="https://github.com/GoogleCloudPlatform/cloud-sdk-docker/blob/master/debian_slim/Dockerfile"&gt;Google&amp;rsquo;s Dockerfile with Cloud SDK&lt;/a&gt; for detail. &lt;a href="https://hub.docker.com/r/lbwang/snakemake-conda-rnaseq/"&gt;&lt;code&gt;lbwang/snakemake-conda-rnaseq&lt;/code&gt;&lt;/a&gt; has installed the Cloud SDK.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo docker run -t -i                           &lt;span class="se"&gt;\&lt;/span&gt;
    -v &lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;:/analysis                         &lt;span class="se"&gt;\&lt;/span&gt;
    -v ~/.config/gcloud:/root/.config/gcloud    &lt;span class="se"&gt;\&lt;/span&gt;
    lbwang/snakemake-conda-rnaseq               &lt;span class="se"&gt;\&lt;/span&gt;
    snakemake -j &lt;span class="m"&gt;4&lt;/span&gt; --timestamp --verbose -p --keep-remote   &lt;span class="se"&gt;\&lt;/span&gt;
        -s /analysis/Snakefile --directory /analysis        &lt;span class="se"&gt;\&lt;/span&gt;
        --default-remote-provider GS --default-remote-prefix &lt;span class="s2"&gt;&amp;quot;{WRITABLE_BUCKET_PATH}&amp;quot;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
        quant_all_samples
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To run Docker on a GCE VM instance, it requires the host machine (the VM instance) to have Docker installed. One may refer to Docker&amp;rsquo;s &lt;a href="https://docs.docker.com/engine/installation/linux/docker-ce/debian/#install-using-the-repository"&gt;official installation guide&lt;/a&gt; to install it. VM instance by default inherit the user&amp;rsquo;s permission (via the automatically created service account), thus the command above should apply to the GCE instance as well.&lt;/p&gt;
&lt;h2 id="google-container-engine-gke"&gt;Google Container Engine (GKE)&lt;/h2&gt;
&lt;p&gt;To scale up the pipeline execution across multiple machines, Snakemake could use &lt;a href="https://cloud.google.com/container-engine/"&gt;Google Container Engine&lt;/a&gt; (GKE, implemented on top of Kubernetes). This method is built on Docker which each node will pull down the given Docker image to load the environment. After &lt;a href="https://bitbucket.org/snakemake/snakemake/issues/602"&gt;some discussions&lt;/a&gt; about how to specify user input image &lt;sup id="fnref:kubernetes-docker"&gt;&lt;a class="footnote-ref" href="#fn:kubernetes-docker" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, on Snakemake 4.1+ one is able to specify the Docker image Kubernete&amp;rsquo;s node uses by &lt;code&gt;--container-image &amp;lt;image&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To install the master branch of Snakemake, run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install git+https://bitbucket.org/snakemake/snakemake.git@master
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Following Snakemake&amp;rsquo;s &lt;a href="https://snakemake.readthedocs.io/en/stable/executable.html#executing-a-snakemake-workflow-via-kubernetes"&gt;GKE guide&lt;/a&gt;, extra packages need to be installed to talk to GKE (Kubernetes) cluster:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install kubernetes
gcloud components install kubectl
&lt;span class="c1"&gt;# or Debian on GCE:&lt;/span&gt;
&lt;span class="c1"&gt;# sudo apt-get install kubectl&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;First we create the GKE cluster by:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;CLUSTER_NAME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;snakemake-cluster&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;ZONE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;us-central1-a&amp;quot;&lt;/span&gt;
gcloud container clusters create &lt;span class="nv"&gt;$CLUSTER_NAME&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --zone&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$ZONE&lt;/span&gt; --num-nodes&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --machine-type&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;n1-standard-4&amp;quot;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --scopes storage-rw
gcloud container clusters get-credentials --zone&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$ZONE&lt;/span&gt; &lt;span class="nv"&gt;$CLUSTER_NAME&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will launch 3 GCE VM instances using &lt;code&gt;n1-standard-4&lt;/code&gt; machine type (4 CPUs). Therefore in the cluster there are total 12 CPUs available for computation. Modify the variables to fit one&amp;rsquo;s setting.&lt;/p&gt;
&lt;p&gt;Note that some rule may specify a number of CPUs that no node in the clusters has, say the rule &lt;code&gt;build_hisat_index&lt;/code&gt; specifies 8 threads. In this case, the cluster cannot find a node with enough free CPUs to forward the job to a &lt;a href="https://kubernetes.io/docs/concepts/workloads/pods/pod/"&gt;pod&lt;/a&gt; and the cluster will halt. Therefore, make sure to lower the &lt;code&gt;threads&lt;/code&gt; to a reasonable number (or use &lt;a href="https://snakemake.readthedocs.io/en/stable/snakefiles/configuration.html"&gt;configfile&lt;/a&gt; to apply to mulitple samples). We will continue to use the same Docker image &lt;a href="https://hub.docker.com/r/lbwang/snakemake-conda-rnaseq/"&gt;&lt;code&gt;lbwang/snakemake-conda-rnaseq&lt;/code&gt;&lt;/a&gt; as the Kubernetes&amp;rsquo; container image.&lt;/p&gt;
&lt;p&gt;By default, Snakemake will always check if the output files are outdated, that is, older than the rule that generated them. To ensure it re-runs the pipeline, one might need to remove the generated output before calling Snakemake again:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gsutil -m rm -r gs://&lt;span class="o"&gt;{&lt;/span&gt;WRITABLE_BUCKET_PATH&lt;span class="o"&gt;}&lt;/span&gt;/&lt;span class="o"&gt;{&lt;/span&gt;align_hisat2,hisat2_index,stringtie&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then we are able to run the pipeline again.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;snakemake                                            &lt;span class="se"&gt;\&lt;/span&gt;
    --timestamp -p --verbose --keep-remote           &lt;span class="se"&gt;\&lt;/span&gt;
    -j &lt;span class="m"&gt;12&lt;/span&gt; --kubernetes                               &lt;span class="se"&gt;\&lt;/span&gt;
    --container-image lbwang/snakemake-conda-rnaseq &lt;span class="se"&gt;\&lt;/span&gt;
    --default-remote-provider GS                     &lt;span class="se"&gt;\&lt;/span&gt;
    --default-remote-prefix &lt;span class="o"&gt;{&lt;/span&gt;WRITABLE_BUCKET_PATH&lt;span class="o"&gt;}&lt;/span&gt;   &lt;span class="se"&gt;\&lt;/span&gt;
    quant_all_samples
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that since we change the container image, we have to make sure the version of Snakemake in the Docker image and the machine starting the pipeline matches. An easy way to ensure that the versions are matched is to start the workflow inside the same Docker image.&lt;/p&gt;
&lt;p&gt;To connect the Kubernete cluster inside Docker, we need to pass kubectl&amp;rsquo;s config file as well, which is at &lt;code&gt;~/.kube/config&lt;/code&gt;. So the full command becomes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo docker run -t -i                           &lt;span class="se"&gt;\&lt;/span&gt;
    -v &lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;:/analysis                         &lt;span class="se"&gt;\&lt;/span&gt;
    -v ~/.config/gcloud:/root/.config/gcloud    &lt;span class="se"&gt;\&lt;/span&gt;
    -v ~/.kube/config:/root/.kube/config        &lt;span class="se"&gt;\&lt;/span&gt;
    lbwang/snakemake-conda-rnaseq               &lt;span class="se"&gt;\&lt;/span&gt;
    snakemake                                           &lt;span class="se"&gt;\&lt;/span&gt;
        -s /analysis/Snakefile --directory /analysis    &lt;span class="se"&gt;\&lt;/span&gt;
        --timestamp -p --verbose --keep-remote          &lt;span class="se"&gt;\&lt;/span&gt;
        -j &lt;span class="m"&gt;12&lt;/span&gt; --kubernetes                              &lt;span class="se"&gt;\&lt;/span&gt;
        --container-image lbwang/snakemake-conda-rnaseq &lt;span class="se"&gt;\&lt;/span&gt;
        --default-remote-provider GS                    &lt;span class="se"&gt;\&lt;/span&gt;
        --default-remote-prefix &lt;span class="o"&gt;{&lt;/span&gt;WRITABLE_BUCKET_PATH&lt;span class="o"&gt;}&lt;/span&gt;  &lt;span class="se"&gt;\&lt;/span&gt;
        quant_all_samples
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After running our pipeline, make sure to delete the GKE cluster by:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gcloud container clusters delete --zone&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$ZONE&lt;/span&gt; &lt;span class="nv"&gt;$CLUSTER_NAME&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="potential-issues-of-using-gke-with-snakemake"&gt;Potential issues of using GKE with Snakemake&lt;/h3&gt;
&lt;p&gt;I still encountered the following issues while running the whole pipeline on the Kubernetes. It is likely that they are not Snakemake&amp;rsquo;s fault but I couldn&amp;rsquo;t find enough time to dig into the details at the time of writing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HISAT2 cannot build its index on Kubenetes. So the step &lt;code&gt;build_hisat_index&lt;/code&gt; failed for unknown reason. The error message from HISAT2 looks like this:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;...
Wrote 8912688 bytes to secondary GFM file: {WRITABLE_BUCKET_PATH}/snakemake_demo/hisat2_index/chr22_ERCC92.6.ht2
Index is corrupt: File size for {WRITABLE_BUCKET_PATH}/snakemake_demo/hisat2_index/chr22_ERCC92.6.ht2 should have been 8912688 but is actually 0.
Please check if there is a problem with the disk or if disk is full.
Total time for call to driver() for forward index: 00:01:18
Error: Encountered internal HISAT2 exception (#1)
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;
&lt;p&gt;Snakemake is a flexible pipeline management tool that can be run locally and on the cloud. Although it is able to run on Kubernetes such as Google Container Engine, it is a relatively new feature and will take some time to stablize. Currently if one wants to run everything (both the computing and the data) on the cloud, using Google Compute Engine and Google Cloud Storage will be the way to go.&lt;/p&gt;
&lt;p&gt;Using a 4-core (n1-standard-4) GCE instance, the total time to finish the pipeline locally and via Google Cloud Storage were 3.2 mins and 5.8 mins resepctively. So there are some overhead to transfer files from/to the storage.&lt;/p&gt;
&lt;p&gt;Docker and bioconda have made the deployment a lot easier. Bioconda truly saves a lot of duplicated efforts to figure out the tool compilation. Docker provides an OS-level isolation and an ecosystem of deployment. With more tools such as &lt;a href="http://singularity.lbl.gov/"&gt;Singularity&lt;/a&gt; continuing to come out, virtualization seems to be a inevitable trend.&lt;/p&gt;
&lt;p&gt;Other than Google cloud products, Snakemake also supports AWS, S3, LSF, SLURM and many other cluster settings. It seems to me that the day when one &lt;code&gt;Snakefile&lt;/code&gt; works for all platforms might be around the corner.&lt;/p&gt;
&lt;p&gt;EDIT 2017-08-15: Add a section about using Google Cloud in Docker. Update summary with some time measurements. Add links to the full Snakefiles.&lt;br&gt;
EDIT 2017-09-07: Snakemake has added the support of custom Kubernetes container image. Thus update the GKE section to use the official parameter to pass image.&lt;br&gt;
EDIT 2017-11-17: Add instructions to run the Snakemake on Kubernete inside Docker. And also list out the issues of using GKE.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:kubernetes-docker"&gt;
&lt;p&gt;In the discussion, Snakemake&amp;rsquo;s author, Johannes, mentioned the possiblity of using &lt;a href="http://singularity.lbl.gov/"&gt;Singularity&lt;/a&gt; so each rule can run in a different virutal environment. Singularity support comes at Snakemake 4.2+.&amp;#160;&lt;a class="footnote-backref" href="#fnref:kubernetes-docker" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="en"></category><category term="bio"></category><category term="python"></category><category term="snakemake"></category><category term="cloud"></category></entry><entry><title>Variants、eQTL、MPRA</title><link href="https://blog.liang2.tw/posts/2017/06/variants-eqtl-mpra/" rel="alternate"></link><published>2017-06-20T00:00:00-05:00</published><updated>2017-06-20T00:00:00-05:00</updated><author><name>Liang-Bo Wang</name></author><id>tag:blog.liang2.tw,2017-06-20:/posts/2017/06/variants-eqtl-mpra/</id><summary type="html">&lt;p&gt;本文內容主要來自 Barak Cohen 教授給的數堂課的筆記，以 Systems Biology 的角度來看 coding/noncoding variant modeling 和相關實驗 MPRA。&lt;/p&gt;</summary><content type="html">&lt;p&gt;Computational Biology 和 Bioinformatics 在現在可能區分不大，本文也不打算深究兩定義，但他們大致能代表兩大類將電腦科學、程式運用在生物上的研究。&lt;/p&gt;
&lt;p&gt;在碩班，我的實驗室一直鼓勵我們去想新的演算法，把某種預測做得更好或者快，或者運用更多來源的數據；做新的工具；整合出新的資料庫。這些應用都有他們的研究價值，也需要大量的技術投入，即便在發表上並不會放入這些細節。這類研究比較偏向 Bioinformatics。&lt;/p&gt;
&lt;p&gt;來 WashU 前，我期許自己繼續往 Bioinformatics 深入。然而，在過去的數月裡，即便我仍投入在這些數據分析與工具開發上，另一大部份的時間，我經歷了許多關於模型，或者，關於「如何回答重要的生物問題」上的討論，有了較碩班訓練不同的啟發。這另一類研究比較偏向 Computational Biology。&lt;/p&gt;
&lt;p&gt;本文想用另一個角度來看所謂的「modeling」。內容主要來自 &lt;a href="http://genetics.wustl.edu/bclab/"&gt;Barak Cohen&lt;/a&gt; 教授給的數堂課的筆記，主題為 &lt;em&gt;Coding and Noncoding Variant&lt;/em&gt;。我生物背景不足，如果筆記有任何錯誤，煩請告知。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conflict of Interest&lt;/strong&gt;: Cohen Lab 開發了 &lt;a href="http://www.pnas.org/content/109/47/19498.short"&gt;CRE-seq&lt;/a&gt; (&lt;em&gt;cis&lt;/em&gt;-regulatory element by sequencing)，其中一種 MPRA (Massively Parallel Reporter Assay) 技術。&lt;/p&gt;
&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#coding-vs-noncoding-variants"&gt;Coding vs noncoding variants&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#noncoding-elements"&gt;Noncoding elements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#noncoding-variants"&gt;Noncoding variants&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#endophenotypes"&gt;Endophenotypes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#eqtl"&gt;eQTL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mpra"&gt;MPRA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h2 id="coding-vs-noncoding-variants"&gt;Coding vs noncoding variants&lt;/h2&gt;
&lt;p&gt;首先來談談 coding 和 noncoding variant。課堂上老師讓我們自由辯論研究兩者的「優缺點」，亦或，如果你是 PI 比較想研究哪個，面臨的優勢與困境。&lt;/p&gt;
&lt;p&gt;Coding variant 很好理解，就是在某個 gene coding region 產生的序列改變，一般會先看所謂的 nonsynonymous，即這個 variant 造成 amino acid 改變，影響到蛋白質的結構，進而影響到其功能。synonymous variant 雖然不會改變 amino acid，但在模式物種中，可能會討論不同 amino acid 對於不同 tRNA 的偏好，也許會影響到 gene expression。另一方面，它也可能會影響 transcription factor (TF) binding，某些 TF 在 biding 有偏好的 DNA sequence（motif），即使蛋白質序列不變，TF binding 變化也會影響到其他基因的調控。&lt;/p&gt;
&lt;p&gt;不過一般而言，coding variant 主要都是考慮 nonsynonymous change，這造成的變化十分具大，無法解釋像 complex traits、gene expression 高低這種細微的變化。&lt;/p&gt;
&lt;h3 id="noncoding-elements"&gt;Noncoding elements&lt;/h3&gt;
&lt;p&gt;Noncoding vairant 相對而言複雜的多。在討論它之前，不如來說說看我們知道哪些 noncoding elements：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Introns&lt;/li&gt;
&lt;li&gt;Promoters&lt;/li&gt;
&lt;li&gt;Regulatory elements (REs)&lt;ul&gt;
&lt;li&gt;&lt;em&gt;cis&lt;/em&gt;-regulatory elements (CREs): promoters, enhancers&lt;/li&gt;
&lt;li&gt;&lt;em&gt;trans&lt;/em&gt;-regulatory elements&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;miRNAs&lt;/li&gt;
&lt;li&gt;Retrovirus, satellites, centromeres, telemeres&lt;/li&gt;
&lt;li&gt;Structual elements &lt;ul&gt;
&lt;li&gt;Matrix Attachment Regions (MARs)&lt;/li&gt;
&lt;li&gt;Lamina Associated Domains (LADs)&lt;/li&gt;
&lt;li&gt;CTCF/Cohesin&lt;/li&gt;
&lt;li&gt;Topologically associating domains (TADs)&lt;/li&gt;
&lt;li&gt;3D genome&lt;sup id="fnref:3D genome"&gt;&lt;a class="footnote-ref" href="#fn:3D genome" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Methylation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;咦，忘記提到 histone modification 嗎？關於這些 epigenetics markers，Barak 對於他們有深刻的懷疑，他認為這些只是 markers 而非最終 regulatory element：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Something you can measure does not mean it is interesting.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;然後建議我們去讀一篇批評 ENCODE 的論文&lt;sup id="fnref:ENCODE paper"&gt;&lt;a class="footnote-ref" href="#fn:ENCODE paper" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;，被他評之為近十年最辛辣，標題也非常有趣。&lt;/p&gt;
&lt;h3 id="noncoding-variants"&gt;Noncoding variants&lt;/h3&gt;
&lt;p&gt;從 non-coding elements 我們能知道控制 gene expression 可以從很多面向切入，於是討論 non-coding variant 時就會有很多不同的機制影響 gene expression。底下針對所謂的 enhancers (RE) 和 promoters 來畫個簡單的示意圖：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;     TF1  TF2  TF3         TF4  [RNA PolII]
----[  enhancer  ]-------[promoter]--[gene body]-------------------------
  &amp;lt;-- Topologically Associating Domain, TAD -----&amp;gt;   &amp;lt;-- Another TAD --&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;RNA Polymerase II (RNA PolII) 負責 gene transcription，而 promoter 是一段在 gene body 前不特定的序列可以吸引 RNA PolII 來提高 gene transcription rate，很有可能就會提高 gene expression。TF 可能會辨別 promoter 上特定的序列，它對 PolII 有更強的吸引力。除了 promoter 之外，enhancer 相較於 gene body 的距離就更不確定，可能是 10kb 或 100kb 之外，但它在立體的距離可能非常近，本身也可以 recruit TF 然後增加 Pol affinity。這一切可以用抑制、競爭的角度來想產生負向的調控。&lt;/p&gt;
&lt;p&gt;Enhancer 的影響力沒有方向性，即上下游的 gene 都會受同個 enhancer 調控。於是有所謂 TAD 的概念，它會讓 chromosome 形成一個 loop 侷限這樣立體空間上下游的互動，使得只在同個 TAD 的 REs 和 gene 能互相作用。
這樣的觀念可以進一步推廣到 3D genome 上，考慮不同 chromosome 間的互動。TAD 的邊界由某些 motif（例如 CTCF）決定，但究竟 TAD 是如果建立與調控，機制尚未明朗。&lt;/p&gt;
&lt;p&gt;在 non-coding 複雜的交互作用的另一面，代表了每個交互作用很可能僅改變了基因表達的程度，而不是大幅度的開關。但這也代表他們對生物體不一定有很強的影響，所以有變化並一定代表它有功能。不過，不同的 cell type 倒可以用透過 TF 有無來調控一系列的 gene，而不是一味增加 gene 數量。因此，在很多情況下，了解 non-coding variants 造成的影響是很有趣的。&lt;/p&gt;
&lt;h3 id="endophenotypes"&gt;Endophenotypes&lt;/h3&gt;
&lt;p&gt;我們要如何看 non-coding variants 呢？首先要了解從 genotype 到 phenotype 其實中間包含了很多層級：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;DNA (genotype) →  RNA →  Proteins →  Metabolites →  Phenotype
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;中間的每個步驟都可能影響，或不會傳遞影響至下個階段。但我們在 DNA 和 RNA level 有非常好的工具─定序─可以同時看 genome wide 非常多基因或區域。於是在大多數的情況我們都只有看到 endophenotypes，要務必僅記在心這和真正的 phenotype 是有所差異的。&lt;/p&gt;
&lt;h2 id="eqtl"&gt;eQTL&lt;/h2&gt;
&lt;p&gt;eQTL 即是一種 endophenotype。QTL (quantitative trait loci) 意即某個 chromosome region 可以關連至一些量化數值的變動（即 locations that map to some quantitative measures），而 eQTL 即為 expresion QTL，關心某段區域的 variants 影響 gene expression。&lt;/p&gt;
&lt;p&gt;過往常見的 eQTL study 有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linkage study&lt;/li&gt;
&lt;li&gt;Family tree&lt;/li&gt;
&lt;li&gt;GWAS on two groups&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這都是使用數個不同人不同 sample 來看 eQTL。但這些對於 non-coding variant 來說變因太多，為何不從個人、單一 sample 著手，即 allele imballance？然而單一 sample 就會牽扯到 eQTL 本身的問題，即它很難進一步從某個區域縮小到是哪個 variant 或哪幾個 variants 為決定性因子 (causal vairants)。&lt;/p&gt;
&lt;h2 id="mpra"&gt;MPRA&lt;/h2&gt;
&lt;p&gt;於是我們可以想辦法設計實驗來進一步解釋 eQTL。實驗可以從兩個方向來設計：necessary 和 sufficient。Necessity 可以透過 CRISPR 設計一系列的 tiled gRNAs 把某個 eQTL 逐步刪掉。平行化這個實驗，可以透過 growth selection 和 single cell sequencing 讀出是哪些 gRNAs 最有影響力。&lt;/p&gt;
&lt;p&gt;在 sufficiency 方面，我們可以設計 reporter assay 來回答這問題：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-----------------------------[weak promoter]--[GFP]--
---[cis RE, CRE]-------------[weak promoter]--[GFP]--
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;reporter assay 可以用個 plasmid 放到 target cell，但要怎麼平行化，同時看很多 genes 呢？這時候就是 MPRA (Massively Parallel Reporter Assay) 表現的時候了。我們可以用 DNA synthesis 把該 &lt;em&gt;cis&lt;/em&gt;-regulatory element (CRE) 和 barcode 做出來，可以建立一個 CRE library，用 RNA-seq 就可以同時看到不同 CRE 所造成的 gene expression change。當然細節有像 normalization DNA amount 和 barcode efficiency，但我們可以用 MPRA 來分析 CRE。&lt;/p&gt;
&lt;p&gt;這裡提到的 CRE-seq 有什麼缺陷呢？它是 Plasmid based，沒有 histone modification，有 copy number 問題；再來他的 genome context 也只有區域性（像 TAD 就沒有考慮）。於是接下來如何改善他，就是目前 Barak Lab 研究最新動態。&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;我覺得從這個角度，把很多觀念用系統的角度整合，並且提出新的實驗與模型，非常有趣。像要怎麼 model enhancer 和 TFs 的交互作用，都是很有趣的題目。他的課非常有啟發性，很有意思。&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:3D genome"&gt;
&lt;p&gt;關於 3D genome 就要提一下這篇論文：&lt;br&gt;
Adrian and Suhas &lt;em&gt;el al.&lt;/em&gt;, &lt;a href="http://www.pnas.org/content/112/47/E6456.abstract"&gt;&lt;em&gt;Chromatin extrusion explains key features of loop and domain formation in wild-type and engineered genomes&lt;/em&gt;&lt;/a&gt;, PNAS, 2015.&lt;br&gt;
裡面用碎形 (fractal globule) 去解釋 CTCF 形成 TADs 造成怎麼樣的染色體摺疊，並如何透過這樣的摺疊產生 long distance interaction，因為可能在立體空間他們是接近的。模型用來解釋 Hi-C 數據。這篇論文使用數學之抽象和複雜，甚至請丘成桐來當 reviewer。&amp;#160;&lt;a class="footnote-backref" href="#fnref:3D genome" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ENCODE paper"&gt;
&lt;p&gt;針對 ENCODE 所謂 80% genome are functional 非常有名的戰文：&lt;br&gt;Dan &lt;em&gt;et al.&lt;/em&gt;, &lt;a href="https://academic.oup.com/gbe/article-lookup/doi/10.1093/gbe/evt028"&gt;&lt;em&gt;On the Immortality of Television Sets: “Function” in the Human Genome According to the Evolution-Free Gospel of ENCODE&lt;/em&gt;&lt;/a&gt;, Genome Biol Evol, 2013.&amp;#160;&lt;a class="footnote-backref" href="#fnref:ENCODE paper" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="zh"></category><category term="bio"></category></entry><entry><title>Ensembl Genomic Reference in Bioconductor</title><link href="https://blog.liang2.tw/posts/2016/05/biocondutor-ensembl-reference/" rel="alternate"></link><published>2016-05-21T18:00:00-05:00</published><updated>2016-05-21T18:00:00-05:00</updated><author><name>Liang-Bo Wang</name></author><id>tag:blog.liang2.tw,2016-05-21:/posts/2016/05/biocondutor-ensembl-reference/</id><summary type="html">&lt;p&gt;Using fundamental R/Biocondcutor packages (e.g. AnnotationHub, ensembldb and biomaRt) to query Ensembl genomic references or annotations.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; I gave a talk &lt;a href="https://blog.liang2.tw/2016Talk-Genomics-in-R/"&gt;Genomics in R&lt;/a&gt; about querying genomic annotations and references in R/Bioconductor. In this post, we re-visit all the operations in my talk using Ensembl references instead of UCSC/NCBI ones.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This post is part of the &amp;ldquo;&lt;a href="https://blog.liang2.tw/posts/2015/12/biocondutor-genomic-data/"&gt;Genomic Data Processing in Bioconductor&lt;/a&gt;&amp;rdquo; series. In that post, I mentioned several topics critical for genomic data analysis in Bioconductor:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Annotation and genome reference (OrgDb, TxDb, OrganismDb, BSgenome)&lt;/li&gt;
&lt;li&gt;Experiment data storage (ExpressionSets)&lt;/li&gt;
&lt;li&gt;Operations on genome (GenomicRanges)&lt;/li&gt;
&lt;li&gt;Genomic data visualization (Gviz, ggbio)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Few days ago in a local R community meetup, I gave a talk &lt;a href="https://blog.liang2.tw/2016Talk-Genomics-in-R/"&gt;&lt;em&gt;Genomics in R&lt;/em&gt;&lt;/a&gt; covering the &amp;ldquo;Annotation and genome reference&amp;rdquo; part and a quick glance through &amp;ldquo;Operations on genome&amp;rdquo;, which should be sufficient for daily usage such as searching annotations in the subset of some genomic ranges. You can find the &lt;a href="https://blog.liang2.tw/2016Talk-Genomics-in-R/"&gt;slides&lt;/a&gt;, the &lt;a href="https://www.youtube.com/watch?v=ZR4GYQ487j8"&gt;meetup screencast&lt;/a&gt; (in Chinese) and the &lt;a href="https://github.com/ccwang002/2016Talk-Genomics-in-R"&gt;accompanied source code&lt;/a&gt; online. I don&amp;rsquo;t think a write-up is needed for the talk. But if anyone is interested, feel free to drop your reply below. :)&lt;/p&gt;
&lt;h3 id="fundamental-bioconductor-packages"&gt;Fundamental Bioconductor packages&lt;/h3&gt;
&lt;p&gt;Some Bioconductor packages are the building blocks for genomic data analysis. I put a table here containing all the classes covered in rest of the post. If you are not familiar with these classes and their methods, go through the &lt;a href="https://blog.liang2.tw/2016Talk-Genomics-in-R/"&gt;talk slides&lt;/a&gt; first, or at least follow the &lt;a href="https://bioconductor.org/help/workflows/annotation/annotation/"&gt;annotation workflow&lt;/a&gt; on Bioconductor.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;R Class&lt;/th&gt;
&lt;th align="left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;code&gt;OrgDb&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;Gene-based information for Homo sapiens; useful for mapping between gene IDs, Names, Symbols, GO and KEGG identifiers, etc.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;code&gt;TxDb&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;Transcriptome ranges for the known gene track of Homo sapiens, e.g., introns, exons, UTR regions.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;code&gt;OrganismDb&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;Collection of multiple annotations for a common organism and genome build.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;code&gt;BSgenome&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;Full genome sequence for Homo sapiens.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;code&gt;AnnotationHub&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;Provides a convenient interface to annotations from many different sources; objects are returned as fully parsed Bioconductor data objects or as the name of a file on disk.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="ensembl-genome-browser-and-its-ecosystem"&gt;Ensembl genome browser and its ecosystem&lt;/h3&gt;
&lt;p&gt;In Bioconductor, most annotations are built against NCBI and UCSC naming systems, which are also used in my talk. However, there is another naming system maintained by &lt;a href="http://www.ensembl.org/index.html"&gt;Ensembl&lt;/a&gt;, whose IDs are very recognizable with suffix &amp;ldquo;ENSG&amp;rdquo; and &amp;ldquo;ENST&amp;rdquo; for gene and transcript respectively.&lt;/p&gt;
&lt;p&gt;I particularly enjoy the Ensembl genome browser. The information is well organized and structured. For example, take a look at the description page of &lt;a href="http://www.ensembl.org/Homo_sapiens/Gene/Summary?db=core;g=ENSG00000100030"&gt;gene MAPK1&lt;/a&gt;,&lt;/p&gt;
&lt;div class="figure"&gt;
  &lt;img src="https://blog.liang2.tw/posts/2016/05/biocondutor-ensembl-reference/pics/gene_MAPK1_ensembl_browser.png"&gt;
  &lt;p class="caption center"&gt;Gene information page of MAP1 on Ensembl Genome Browser release 84 (&lt;a href="http://www.ensembl.org/Homo_sapiens/Gene/Summary?db=core;g=ENSG00000100030"&gt;link&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;a href="http://www.ensembl.org/Homo_sapiens/Gene/Compara_Tree?db=core;g=ENSG00000100030"&gt;gene tree&lt;/a&gt; tab shows its homologs and paralogs. The &lt;a href="http://www.ensembl.org/Homo_sapiens/Gene/Variation_Gene/Table?db=core;g=ENSG00000100030"&gt;variant table&lt;/a&gt; tab shows various kinds of SNPs within MAPK1&amp;rsquo;s transcript region. SNPs are annotated with their sources, different levels of supporting evidence, and SIFT/PolyPhen prediction on protein function change. Finally, there is a &lt;a href="http://www.ensembl.org/Homo_sapiens/Gene/Matches?db=core;g=ENSG00000100030"&gt;external references&lt;/a&gt; tab which links the Ensembl IDs with &lt;a href="https://www.ncbi.nlm.nih.gov/CCDS/CcdsBrowse.cgi"&gt;NCBI CCDS&lt;/a&gt; and &lt;a href="http://www.ncbi.nlm.nih.gov/refseq/"&gt;NCBI RefSeq&lt;/a&gt; IDs. There are many ways to explore different aspects of this gene, and it seems everything at multiple biological levels is simply connected. &lt;/p&gt;
&lt;p&gt;I always think of the Ensembl ecosystem as a decent learning portal, so it is a pity if one cannot easily use its information in R/Bioconductor. After a quick research, I found using Ensembl annotations are quite straightforward even though the required files does not ship with Bioconductor. Also, there were some topics I failed to mention in the talk, such as AnnotationHub and genomic coordinate system conversion (e.g., from hg19 to hg38). I am going to cover these topics in the talk.&lt;/p&gt;
&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#fundamental-bioconductor-packages"&gt;Fundamental Bioconductor packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ensembl-genome-browser-and-its-ecosystem"&gt;Ensembl genome browser and its ecosystem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#orgdb"&gt;OrgDb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#txdb"&gt;TxDb&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#bsgenome-and-annotationhub"&gt;BSgenome and AnnotationHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#biomart"&gt;biomaRt&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#compatibility-with-annotationdbs-interface"&gt;Compatibility with AnnotationDb&amp;rsquo;s interface&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#biomarts-original-interface"&gt;biomaRt&amp;rsquo;s original interface&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conversion-between-genomic-coordinate-systems"&gt;Conversion between genomic coordinate systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h2 id="orgdb"&gt;OrgDb&lt;/h2&gt;
&lt;p&gt;The same OrgDb object for human (&lt;code&gt;org.Hs.eg.db&lt;/code&gt;) can be used. It relates different gene IDs, including Entrez and Ensembl gene ID. From its metadata, human&amp;rsquo;s OrgDb gets updated frequently. Most of its data source were fetched during this March. So one should be able to use it for both hg19 and hg38 human reference.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;org.Hs.eg.db&lt;span class="p"&gt;)&lt;/span&gt;
human &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; org.Hs.eg.db

mapk_gene_family_info &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; select&lt;span class="p"&gt;(&lt;/span&gt;
    human&lt;span class="p"&gt;,&lt;/span&gt;
    keys &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;MAPK1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;MAPK3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;MAPK6&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    keytype &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;SYMBOL&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    columns &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ENTREZID&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;ENSEMBL&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;GENENAME&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
mapk_gene_family_info
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;SYMBOL&lt;/th&gt;
&lt;th align="left"&gt;ENTREZID&lt;/th&gt;
&lt;th align="left"&gt;ENSEMBL&lt;/th&gt;
&lt;th align="left"&gt;GENENAME&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;MAPK1&lt;/td&gt;
&lt;td align="left"&gt;5594&lt;/td&gt;
&lt;td align="left"&gt;ENSG00000100030&lt;/td&gt;
&lt;td align="left"&gt;mitogen-activated protein kinase 1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;MAPK3&lt;/td&gt;
&lt;td align="left"&gt;5595&lt;/td&gt;
&lt;td align="left"&gt;ENSG00000102882&lt;/td&gt;
&lt;td align="left"&gt;mitogen-activated protein kinase 3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;MAPK6&lt;/td&gt;
&lt;td align="left"&gt;5597&lt;/td&gt;
&lt;td align="left"&gt;ENSG00000069956&lt;/td&gt;
&lt;td align="left"&gt;mitogen-activated protein kinase 6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here comes a small pitfall for Ensembl annotation. We cannot sufficiently map Ensembl&amp;rsquo;s gene ID to its transcript ID,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;select&lt;span class="p"&gt;(&lt;/span&gt;
    human&lt;span class="p"&gt;,&lt;/span&gt;
    keys &lt;span class="o"&gt;=&lt;/span&gt; mapk_gene_family_info&lt;span class="o"&gt;$&lt;/span&gt;ENSEMBL&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;
    keytype &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;ENSEMBL&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    columns &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ENSEMBLTRANS&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# &amp;#39;select()&amp;#39; returned 1:1 mapping between keys and columns&lt;/span&gt;
&lt;span class="c1"&gt;#           ENSEMBL ENSEMBLTRANS&lt;/span&gt;
&lt;span class="c1"&gt;# 1 ENSG00000100030         &amp;lt;NA&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We got &lt;em&gt;no&lt;/em&gt; Ensembl transcript ID for MAPK1, which is impossible. Therefore, to find the real Ensembl transcript IDs, we need to find other references.&lt;/p&gt;
&lt;h2 id="txdb"&gt;TxDb&lt;/h2&gt;
&lt;p&gt;There is no pre-built Ensembl TxDb object available on Bioconductor. But with the help of &lt;a href="http://bioconductor.org/packages/release/bioc/html/ensembldb.html"&gt;ensembldb&lt;/a&gt;, we can easily build the TxDb ourselves.&lt;/p&gt;
&lt;p&gt;Following the instructions in ensembldb&amp;rsquo;s &lt;a href="http://bioconductor.org/packages/release/bioc/vignettes/ensembldb/inst/doc/ensembldb.html"&gt;vignette file&lt;/a&gt;, we can build the TxDb object from the Ensembl latest release, which is release 84 (Mar, 2016) at the time of writing. Ensembl releases all human transcript records as GTF file, which can be found here &lt;a href="ftp://ftp.ensembl.org/pub/release-84/gtf/homo_sapiens/Homo_sapiens.GRCh38.84.gtf.gz"&gt;ftp://ftp.ensembl.org/pub/release-84/gtf/homo_sapiens/Homo_sapiens.GRCh38.84.gtf.gz&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After processing GTF file via &lt;code&gt;ensDbFromGtf()&lt;/code&gt;, the generated data for creating the TxDb object will be stored in a SQLite3 database file &lt;code&gt;Homo_sapiens.GRCh38.84.sqlite&lt;/code&gt; at the R working directory. Building TxDB is just one command away, &lt;code&gt;EnsDb()&lt;/code&gt;. Putting two commands together, the script for building Ensembl TxDb is listed below. To prevent from rebuilding the TxDb every time the script is executed, we first check if the sqlite file exists,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# xxx_DB in the vignette is just a string to the SQLite db file path&lt;/span&gt;
ens84_txdb_pth &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;./Homo_sapiens.GRCh38.84.sqlite&amp;#39;&lt;/span&gt;
&lt;span class="kr"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="kp"&gt;file.exists&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;ens84_human_txdb_pth&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    ens84_txdb_pth &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ensDbFromGtf&lt;span class="p"&gt;(&lt;/span&gt;gtf&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Homo_sapiens.GRCh38.84.gtf.gz&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
txdb_ens84 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; EnsDb&lt;span class="p"&gt;(&lt;/span&gt;ens84txdb_pth&lt;span class="p"&gt;)&lt;/span&gt;
txdb_ens84  &lt;span class="c1"&gt;# Preview the metadata&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The filtering syntax for finding desired genes or transcripts is different to the built-in TxDb object,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;transcripts&lt;span class="p"&gt;(&lt;/span&gt;
    txdb_ens84&lt;span class="p"&gt;,&lt;/span&gt;
    filter&lt;span class="o"&gt;=&lt;/span&gt;GeneidFilter&lt;span class="p"&gt;(&lt;/span&gt;mapk_gene_family_info&lt;span class="o"&gt;$&lt;/span&gt;ENSEMBL&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# GRanges object with 4 ranges and 5 metadata columns:&lt;/span&gt;
&lt;span class="c1"&gt;#                   seqnames               ranges strand |           tx_id           tx_biotype&lt;/span&gt;
&lt;span class="c1"&gt;#                      &amp;lt;Rle&amp;gt;            &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; |     &amp;lt;character&amp;gt;          &amp;lt;character&amp;gt;&lt;/span&gt;
&lt;span class="c1"&gt;#   ENST00000215832       22 [21754500, 21867629]      - | ENST00000215832       protein_coding&lt;/span&gt;
&lt;span class="c1"&gt;#   ENST00000491588       22 [21763984, 21769428]      - | ENST00000491588 processed_transcript&lt;/span&gt;
&lt;span class="c1"&gt;#   ENST00000398822       22 [21769040, 21867680]      - | ENST00000398822       protein_coding&lt;/span&gt;
&lt;span class="c1"&gt;#   ENST00000544786       22 [21769204, 21867440]      - | ENST00000544786       protein_coding&lt;/span&gt;
&lt;span class="c1"&gt;#                   tx_cds_seq_start tx_cds_seq_end         gene_id&lt;/span&gt;
&lt;span class="c1"&gt;#                          &amp;lt;numeric&amp;gt;      &amp;lt;numeric&amp;gt;     &amp;lt;character&amp;gt;&lt;/span&gt;
&lt;span class="c1"&gt;#   ENST00000215832         21769204       21867440 ENSG00000100030&lt;/span&gt;
&lt;span class="c1"&gt;#   ENST00000491588             &amp;lt;NA&amp;gt;           &amp;lt;NA&amp;gt; ENSG00000100030&lt;/span&gt;
&lt;span class="c1"&gt;#   ENST00000398822         21769204       21867440 ENSG00000100030&lt;/span&gt;
&lt;span class="c1"&gt;#   ENST00000544786         21769204       21867440 ENSG00000100030&lt;/span&gt;
&lt;span class="c1"&gt;#   -------&lt;/span&gt;
&lt;span class="c1"&gt;#   seqinfo: 1 sequence from GRCh38 genome&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So filtering is done by passing special filter functions to &lt;code&gt;filter=&lt;/code&gt;. Likewise, there are &lt;code&gt;TxidFilter&lt;/code&gt;, &lt;code&gt;TxbiotypeFilter&lt;/code&gt;, and &lt;code&gt;GRangesFilter&lt;/code&gt; for filtering on the respective columns.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tx_gr &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; transcripts&lt;span class="p"&gt;(&lt;/span&gt;
    txdb_ens84&lt;span class="p"&gt;,&lt;/span&gt;
    filter&lt;span class="o"&gt;=&lt;/span&gt;TxidFilter&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ENST00000215832&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
tr_gr
&lt;span class="c1"&gt;# GRanges object with 1 range and 5 metadata columns:&lt;/span&gt;
&lt;span class="c1"&gt;#                   seqnames               ranges strand |           tx_id     tx_biotype tx_cds_seq_start tx_cds_seq_end         gene_id&lt;/span&gt;
&lt;span class="c1"&gt;#                      &amp;lt;Rle&amp;gt;            &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; |     &amp;lt;character&amp;gt;    &amp;lt;character&amp;gt;        &amp;lt;numeric&amp;gt;      &amp;lt;numeric&amp;gt;     &amp;lt;character&amp;gt;&lt;/span&gt;
&lt;span class="c1"&gt;#   ENST00000215832       22 [21754500, 21867629]      - | ENST00000215832 protein_coding         21769204       21867440 ENSG00000100030&lt;/span&gt;
&lt;span class="c1"&gt;#   -------&lt;/span&gt;
&lt;span class="c1"&gt;#   seqinfo: 1 sequence from GRCh38 genome&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Check the result with the online Ensembl genome browser. Note that Ensembl release 84 use hg38.&lt;/p&gt;
&lt;h2 id="bsgenome-and-annotationhub"&gt;BSgenome and AnnotationHub&lt;/h2&gt;
&lt;p&gt;We can load the sequence from &lt;code&gt;BSgenome.Hsapiens.UCSC.hg38&lt;/code&gt;, however, we can obtain the genome (chromosome) sequence of Ensembl using &lt;a href="https://bioconductor.org/packages/release/bioc/html/AnnotationHub.html"&gt;AnnotationHub&lt;/a&gt;. References of non-model organisms can be found on AnnotationHub, many of which are extracted from Ensembl. But they can be downloaded as Bioconductor objects directly so it should be easier to use.&lt;/p&gt;
&lt;p&gt;First we create a AnnotationHub instance, it cached the metadata all available annotations locally for us to query.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ah &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; AnnotationHub&lt;span class="p"&gt;()&lt;/span&gt;
query&lt;span class="p"&gt;(&lt;/span&gt;ah&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Homo sapiens&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;release-84&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;# AnnotationHub with 5 records&lt;/span&gt;
&lt;span class="c1"&gt;# # snapshotDate(): 2016-05-12&lt;/span&gt;
&lt;span class="c1"&gt;# # $dataprovider: Ensembl&lt;/span&gt;
&lt;span class="c1"&gt;# # $species: Homo sapiens&lt;/span&gt;
&lt;span class="c1"&gt;# # $rdataclass: TwoBitFile&lt;/span&gt;
&lt;span class="c1"&gt;# # additional mcols(): taxonomyid, genome, description, tags, sourceurl, sourcetype&lt;/span&gt;
&lt;span class="c1"&gt;# # retrieve records with, e.g., &amp;#39;object[[&amp;quot;AH50558&amp;quot;]]&amp;#39;&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;#             title&lt;/span&gt;
&lt;span class="c1"&gt;#   AH50558 | Homo_sapiens.GRCh38.cdna.all.2bit&lt;/span&gt;
&lt;span class="c1"&gt;#   AH50559 | Homo_sapiens.GRCh38.dna.primary_assembly.2bit&lt;/span&gt;
&lt;span class="c1"&gt;#   AH50560 | Homo_sapiens.GRCh38.dna_rm.primary_assembly.2bit&lt;/span&gt;
&lt;span class="c1"&gt;#   AH50561 | Homo_sapiens.GRCh38.dna_sm.primary_assembly.2bit&lt;/span&gt;
&lt;span class="c1"&gt;#   AH50562 | Homo_sapiens.GRCh38.ncrna.2bit&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;From the search results, human hg38 genome sequences are available as &lt;a href="https://genome.ucsc.edu/goldenpath/help/twoBit.html"&gt;TwoBit&lt;/a&gt; format. But having multiple results is confusing at first. After checking the Ensembl&amp;rsquo;s &lt;a href="ftp://ftp.ensembl.org/pub/release-84/fasta/homo_sapiens/dna/README"&gt;gnome DNA assembly readme&lt;/a&gt;, what we should use here is the full DNA assembly without any masking (or you can decide it based on your application).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# There are a plenty of query hits. Description of different file suffix:&lt;/span&gt;
&lt;span class="c1"&gt;# GRCh38.dna.*.2bit     genome sequence&lt;/span&gt;
&lt;span class="c1"&gt;# GRCh38.dna_rm.*.2bit  hard-masked genome sequence (masked regions are replaced with N&amp;#39;s)&lt;/span&gt;
&lt;span class="c1"&gt;# GRCh38.dna_sm.*.2bit  soft-masked genome sequence (.............. are lower cased)&lt;/span&gt;
ens84_human_dna &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ah&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;AH50559&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then we can use it to obtain the DNA sequence of desired genomic range (in &lt;code&gt;GRagnes&lt;/code&gt;).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;getSeq&lt;span class="p"&gt;(&lt;/span&gt;ens84_human_dna&lt;span class="p"&gt;,&lt;/span&gt; tx_gr&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;#   A DNAStringSet instance of length 1&lt;/span&gt;
&lt;span class="c1"&gt;#      width seq                              names&lt;/span&gt;
&lt;span class="c1"&gt;# [1] 113130 TTTATAGAGAAAA...CTCGGACCGATTGCCT ENST00000215832&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="biomart"&gt;biomaRt&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.ensembl.org/biomart/martview"&gt;BioMart&lt;/a&gt; are a collections of database that can be accessed by the same API, including Ensembl, Uniprot and HapMap. &lt;a href="https://bioconductor.org/packages/release/bioc/html/biomaRt.html"&gt;biomaRt&lt;/a&gt; provides an R interface to these database resources. We will use BioMart for ID conversion between Ensembl and RefSeq. Its &lt;a href="https://bioconductor.org/packages/release/bioc/vignettes/biomaRt/inst/doc/biomaRt.pdf"&gt;vignette&lt;/a&gt; contains solutions to common scenarios so should be a good starting point to get familiar with it.&lt;/p&gt;
&lt;p&gt;You could first explore which Marts are currently available by &lt;code&gt;listMarts()&lt;/code&gt;,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;biomaRt&lt;span class="p"&gt;)&lt;/span&gt;
listMarts&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;#                biomart               version&lt;/span&gt;
&lt;span class="c1"&gt;# 1 ENSEMBL_MART_ENSEMBL      Ensembl Genes 84&lt;/span&gt;
&lt;span class="c1"&gt;# 2     ENSEMBL_MART_SNP  Ensembl Variation 84&lt;/span&gt;
&lt;span class="c1"&gt;# 3 ENSEMBL_MART_FUNCGEN Ensembl Regulation 84&lt;/span&gt;
&lt;span class="c1"&gt;# 4    ENSEMBL_MART_VEGA               Vega 64&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here we will use Ensembl&amp;rsquo;s biomart. Each mart contains multiple datasets, usually separated by different organisms. In our case, human&amp;rsquo;s dataset is &lt;code&gt;hsapiens_gene_ensembl&lt;/code&gt;. For other organisms, you can find their dataset by &lt;code&gt;listDatasets(ensembl)&lt;/code&gt;. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ensembl &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; useMart&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ensembl&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
ensembl &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; useDataset&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;hsapiens_gene_ensembl&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; mart&lt;span class="o"&gt;=&lt;/span&gt;ensembl&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# or equivalently&lt;/span&gt;
ensembl &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; useMart&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ensembl&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; dataset&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;hsapiens_gene_ensembl&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="compatibility-with-annotationdbs-interface"&gt;Compatibility with AnnotationDb&amp;rsquo;s interface&lt;/h3&gt;
&lt;p&gt;The way to query the &lt;code&gt;ensembl&lt;/code&gt; Mart object is slightly different to how we query a AnnotationDb object. The major difference is the terminology. Luckily, Mart object provides a compatibility layer so we can still call functions such as &lt;code&gt;select(db, ...)&lt;/code&gt;, &lt;code&gt;keytypes(db)&lt;/code&gt;, &lt;code&gt;keys(db)&lt;/code&gt; and &lt;code&gt;columns(db)&lt;/code&gt;, which we frequently do&lt;sup id="fnref:select-compat"&gt;&lt;a class="footnote-ref" href="#fn:select-compat" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; when using NCBI/UCSC references.&lt;/p&gt;
&lt;p&gt;A Mart can have hundreds of keys and columns. So we select a part of them out by &lt;code&gt;grep()&lt;/code&gt;,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kp"&gt;grep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;^refseq&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; keytypes&lt;span class="p"&gt;(&lt;/span&gt;ensembl&lt;span class="p"&gt;),&lt;/span&gt; value &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# [1] &amp;quot;refseq_mrna&amp;quot; &amp;quot;refseq_mrna_predicted&amp;quot; ...&lt;/span&gt;
&lt;span class="kp"&gt;grep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;^ensembl&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; keytypes&lt;span class="p"&gt;(&lt;/span&gt;ensembl&lt;span class="p"&gt;),&lt;/span&gt; value &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# [1] &amp;quot;ensembl_exon_id&amp;quot; &amp;quot;ensembl_gene_id&amp;quot; ...&lt;/span&gt;
&lt;span class="kp"&gt;grep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;hsapiens_paralog_&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; columns&lt;span class="p"&gt;(&lt;/span&gt;ensembl&lt;span class="p"&gt;),&lt;/span&gt; value&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# [1] &amp;quot;hsapiens_paralog_associated_gene_name&amp;quot;&lt;/span&gt;
&lt;span class="c1"&gt;# [2] &amp;quot;hsapiens_paralog_canonical_transcript_protein&amp;quot;&lt;/span&gt;
&lt;span class="c1"&gt;# [3] &amp;quot;hsapiens_paralog_chrom_end&amp;quot;&lt;/span&gt;
&lt;span class="c1"&gt;# ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We start by finding the MAPK1&amp;rsquo;s RefSeq transcript IDs and their corresponding Ensembl transcript IDs, which is something we cannot do by our locally built Ensembl TxDb nor the human OrgDb.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;select&lt;span class="p"&gt;(&lt;/span&gt;
    ensembl&lt;span class="p"&gt;,&lt;/span&gt;
    keys &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;MAPK1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    keytype &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;hgnc_symbol&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    columns &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;refseq_mrna&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;ensembl_transcript_id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;hgnc_symbol&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;entrezgene&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;chromosome_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;transcript_start&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;transcript_end&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;strand&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;#   refseq_mrna ensembl_transcript_id hgnc_symbol entrezgene&lt;/span&gt;
&lt;span class="c1"&gt;# 1   NM_002745       ENST00000215832       MAPK1       5594&lt;/span&gt;
&lt;span class="c1"&gt;# 2                   ENST00000491588       MAPK1       5594&lt;/span&gt;
&lt;span class="c1"&gt;# 3   NM_138957       ENST00000398822       MAPK1       5594&lt;/span&gt;
&lt;span class="c1"&gt;# 4                   ENST00000544786       MAPK1       5594&lt;/span&gt;
&lt;span class="c1"&gt;#   chromosome_name transcript_start transcript_end strand&lt;/span&gt;
&lt;span class="c1"&gt;# 1              22         21754500       21867629     -1&lt;/span&gt;
&lt;span class="c1"&gt;# 2              22         21763984       21769428     -1&lt;/span&gt;
&lt;span class="c1"&gt;# 3              22         21769040       21867680     -1&lt;/span&gt;
&lt;span class="c1"&gt;# 4              22         21769204       21867440     -1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So some of the MAPK1 Ensembl transcripts does not have RefSeq identifiers. This is common to see since RefSeq is more conservative about including new transcripts. Anyway, we can now translate our analysis result between a wider range of naming systems.&lt;/p&gt;
&lt;p&gt;Moreover, what&amp;rsquo;s awesome about BioMart is that almost all the information on the Ensembl genome browser can be retreived by BioMart. For example, getting the paralog and the mouse homolog of MAPK1,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Get paralog of MAPK1&lt;/span&gt;
select&lt;span class="p"&gt;(&lt;/span&gt;
    ensembl&lt;span class="p"&gt;,&lt;/span&gt;
    keys &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ENSG00000100030&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    keytype &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;ensembl_gene_id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    columns &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;hsapiens_paralog_associated_gene_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;hsapiens_paralog_orthology_type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;hsapiens_paralog_ensembl_peptide&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;#   hsapiens_paralog_associated_gene_name hsapiens_paralog_orthology_type hsapiens_paralog_ensembl_peptide&lt;/span&gt;
&lt;span class="c1"&gt;# 1                                 MAPK3          within_species_paralog                  ENSP00000263025&lt;/span&gt;
&lt;span class="c1"&gt;# 2                                 MAPK6          within_species_paralog                  ENSP00000261845&lt;/span&gt;
&lt;span class="c1"&gt;# 3                                 MAPK4          within_species_paralog                  ENSP00000383234&lt;/span&gt;
&lt;span class="c1"&gt;# 4                                   NLK          within_species_paralog                  ENSP00000384625&lt;/span&gt;
&lt;span class="c1"&gt;# 5                                 MAPK7          within_species_paralog                  ENSP00000311005&lt;/span&gt;

&lt;span class="c1"&gt;# Get homolog of MAPK1 in mouse&lt;/span&gt;
select&lt;span class="p"&gt;(&lt;/span&gt;
    ensembl&lt;span class="p"&gt;,&lt;/span&gt;
    keys &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ENSG00000100030&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    keytype &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;ensembl_gene_id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    columns &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;mmusculus_homolog_associated_gene_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;mmusculus_homolog_orthology_type&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;mmusculus_homolog_ensembl_peptide&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;#   mmusculus_homolog_associated_gene_name mmusculus_homolog_orthology_type mmusculus_homolog_ensembl_peptide&lt;/span&gt;
&lt;span class="c1"&gt;# 1                                  Mapk1                 ortholog_one2one                ENSMUSP00000065983&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="biomarts-original-interface"&gt;biomaRt&amp;rsquo;s original interface&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;select()&lt;/code&gt; function we use is not the original biomaRt&amp;rsquo;s interface. In fact, keys and columns are interpreted as BioMart&amp;rsquo;s &lt;strong&gt;filters&lt;/strong&gt; and &lt;strong&gt;attributes&lt;/strong&gt; respectively. To find all available filters and attributes,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;filters &lt;span class="o"&gt;=&lt;/span&gt; listFilters&lt;span class="p"&gt;(&lt;/span&gt;ensembl&lt;span class="p"&gt;)&lt;/span&gt;
attributes &lt;span class="o"&gt;=&lt;/span&gt; listAttributes&lt;span class="p"&gt;(&lt;/span&gt;ensembl&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;each of the command return a data.frame that contains each filter&amp;rsquo;s or attribute&amp;rsquo;s name and description.&lt;/p&gt;
&lt;p&gt;Behind the scene, arguments of &lt;code&gt;select(db, ...)&lt;/code&gt; is converted to &lt;code&gt;getBM(mart, ...)&lt;/code&gt;. For the same example of finding RefSeq and Ensembl transcript IDs, it can be re-written as&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;getBM&lt;span class="p"&gt;(&lt;/span&gt;
    attributes &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;refseq_mrna&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;ensembl_transcript_id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;chromosome_name&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;transcript_start&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;transcript_end&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;strand&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;hgnc_symbol&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;entrezgene&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;ensembl_gene_id&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;),&lt;/span&gt;
    filters &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;hgnc_symbol&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    values &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;MAPK1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    mart &lt;span class="o"&gt;=&lt;/span&gt; ensembl
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="conversion-between-genomic-coordinate-systems"&gt;Conversion between genomic coordinate systems&lt;/h2&gt;
&lt;p&gt;Somethings we need to convert between different verions of the reference. For example, today we&amp;rsquo;d like to convert a batch of genomic locations of reference hg38 to that of hg19, so we can compare our new research with previous studies. It is a non-trivial task that can be currently handled by the following tools:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://crossmap.sourceforge.net/"&gt;CrossMap&lt;/a&gt; (used by Ensembl)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://genome.ucsc.edu/cgi-bin/hgLiftOver"&gt;liftOver&lt;/a&gt; (used by UCSC)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Frankly I don&amp;rsquo;t have experience for such conversion in real study (the converted result still gives the sense of unease), but anyway here I follow &lt;a href="http://genomicsclass.github.io/book/pages/bioc1_liftOver.html"&gt;the guide on PH525x series&lt;/a&gt;. In Bioconductor, we can use UCSC&amp;rsquo;s Chain file to apply the &lt;code&gt;liftOver()&lt;/code&gt; method provided by package &lt;code&gt;rtracklayer&lt;/code&gt;. To convert regions from hg38 to hg19, we need the &lt;code&gt;hg38ToHg19.over.chain&lt;/code&gt; file, which can be found at &lt;a href="ftp://hgdownload.cse.ucsc.edu/goldenPath/hg38/liftOver/"&gt;ftp://hgdownload.cse.ucsc.edu/goldenPath/hg38/liftOver/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We still use MAPK1 as an example of conversion. First extract MAPK1&amp;rsquo;s genomic ranges in hg38 and hg19 respectively,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;TxDb.Hsapiens.UCSC.hg38.knownGene&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;TxDb.Hsapiens.UCSC.hg19.knownGene
tx38 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; TxDb.Hsapiens.UCSC.hg38.knownGene
tx19 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; TxDb.Hsapiens.UCSC.hg19.knownGene
MAPK1_hg38 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; genes&lt;span class="p"&gt;(&lt;/span&gt;tx38&lt;span class="p"&gt;,&lt;/span&gt; filter&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kt"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;gene_id&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;5594&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
MAPK1_hg19 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; genes&lt;span class="p"&gt;(&lt;/span&gt;tx19&lt;span class="p"&gt;,&lt;/span&gt; filter&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kt"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;gene_id&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;5594&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then we convert &lt;code&gt;MAPK1_hg38&lt;/code&gt; to use the hg19 coordinate system.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;rtracklayer&lt;span class="p"&gt;)&lt;/span&gt;
ch &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; import.chain&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;./hg38ToHg19.over.chain&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
MAPK1_hg19_lifted &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; liftOver&lt;span class="p"&gt;(&lt;/span&gt;MAPK1_hg38&lt;span class="p"&gt;,&lt;/span&gt; ch&lt;span class="p"&gt;)&lt;/span&gt;

MAPK1_hg19
&lt;span class="c1"&gt;# GRanges object with 1 range and 1 metadata column:&lt;/span&gt;
&lt;span class="c1"&gt;#        seqnames               ranges strand |     gene_id&lt;/span&gt;
&lt;span class="c1"&gt;#           &amp;lt;Rle&amp;gt;            &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; | &amp;lt;character&amp;gt;&lt;/span&gt;
&lt;span class="c1"&gt;#   5594    chr22 [22113947, 22221970]      - |        5594&lt;/span&gt;
&lt;span class="c1"&gt;#   -------&lt;/span&gt;
&lt;span class="c1"&gt;#   seqinfo: 93 sequences (1 circular) from hg19 genome&lt;/span&gt;

MAPK1_hg19_lifted
&lt;span class="c1"&gt;# GRangesList object of length 1:&lt;/span&gt;
&lt;span class="c1"&gt;# $5594&lt;/span&gt;
&lt;span class="c1"&gt;# GRanges object with 2 ranges and 1 metadata column:&lt;/span&gt;
&lt;span class="c1"&gt;#       seqnames               ranges strand |     gene_id&lt;/span&gt;
&lt;span class="c1"&gt;#          &amp;lt;Rle&amp;gt;            &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt; | &amp;lt;character&amp;gt;&lt;/span&gt;
&lt;span class="c1"&gt;#   [1]    chr22 [22113947, 22216652]      - |        5594&lt;/span&gt;
&lt;span class="c1"&gt;#   [2]    chr22 [22216654, 22221970]      - |        5594&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# -------&lt;/span&gt;
&lt;span class="c1"&gt;# seqinfo: 1 sequence from an unspecified genome; no seqlengths&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So the conversion worked as expected, though it created a gap in the range (missing a base at 22216653). I haven&amp;rsquo;t looked into the results. To ensure the correctness of the conversion, maybe a comparison with CrossMap is needed.&lt;/p&gt;
&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;
&lt;p&gt;We skimmed through OrgDb and TxDb again using the Ensembl references, including how to build the TxDb for Ensembl locally and obtain external annotations from AnnotationHub.&lt;/p&gt;
&lt;p&gt;BioMart is an abundant resource to query across various types of databases and references, which can be used in conversion between different naming systems.&lt;/p&gt;
&lt;p&gt;Finally, we know how to convert between different version of the reference. Though the correctness of the conversion requires further examination (not meaning it is wrong), at least the conversion by liftOver works as expected.&lt;/p&gt;
&lt;p&gt;Starting here, you should have no trouble dealing with annotations in R anymore. For the next post, I plan to further explore the way to read sequencing analysis results in R.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:select-compat"&gt;
&lt;p&gt;Note that the &lt;code&gt;select(mart, ...)&lt;/code&gt; compatibility does not apply to all existed filters (keys) and attributes (columns) of the given Mart.&amp;#160;&lt;a class="footnote-backref" href="#fnref:select-compat" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="en"></category><category term="r"></category><category term="bioconductor"></category></entry><entry><title>Plot Sequencing Depth with Gviz</title><link href="https://blog.liang2.tw/posts/2016/01/plot-seq-depth-gviz/" rel="alternate"></link><published>2016-01-15T23:50:00-06:00</published><updated>2016-01-15T23:50:00-06:00</updated><author><name>Liang-Bo Wang</name></author><id>tag:blog.liang2.tw,2016-01-15:/posts/2016/01/plot-seq-depth-gviz/</id><summary type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; Plot exome sequencing depth and coverage with genome annotation using Gviz in R. Then apply detail control on Gviz annotation track displaying …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; Plot exome sequencing depth and coverage with genome annotation using Gviz in R. Then apply detail control on Gviz annotation track displaying.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is an extending post from &lt;a href="https://blog.liang2.tw/posts/2015/12/biocondutor-genomic-data/"&gt;Genomic Data Processing in Bioconductor&lt;/a&gt;, though I haven&amp;rsquo;t finished reading all the reference in that post. The background knowledge of this post is basic understanding of how to deal with annotation and genome reference in Bioconductor/R. If you don&amp;rsquo;t deal with genome annotations in R before, you should find some time learning it anyway, a truly life saver.&lt;/p&gt;
&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#convert-sequencing-depth-to-bedgraph-format"&gt;Convert sequencing depth to BedGraph format&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#plot-depth-in-gviz"&gt;Plot depth in Gviz&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#first-gviz-track"&gt;First Gviz track&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#add-genome-axis"&gt;Add genome axis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#add-annotation"&gt;Add annotation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#plot-fine-tune"&gt;Plot fine tune&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#genome-annotation-query-in-bioconductorr"&gt;Genome annotation query in Bioconductor/R&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#via-transcripts"&gt;via transcripts()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#via-exonsby"&gt;via exonsBy()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#show-only-the-annotations-of-certain-genes"&gt;Show only the annotations of certain genes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#display-gene-symbols-at-annotation-track"&gt;Display gene symbols at annotation track&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#supplementary-plot-bam-files-directly"&gt;Supplementary - Plot BAM files directly&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#fancier-alignment-display"&gt;Fancier alignment display&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;I got the chance trying new tricks today when I and other lab members were analyzing our human cancer exome sequencing data. The results were a bunch of BAM files aligned by &lt;a href="https://github.com/lh3/bwa"&gt;BWA-MEM&lt;/a&gt; using reference hg19.&lt;/p&gt;
&lt;p&gt;We want to see how was the sequencing depth and the coverage of all exons designed to be sequenced. Roughly, this can be done in the genome viewer such as &lt;a href="https://www.broadinstitute.org/igv/"&gt;IGV&lt;/a&gt;.&lt;/p&gt;
&lt;div class="figure"&gt;
  &lt;img src="https://blog.liang2.tw/posts/2016/01/plot-seq-depth-gviz/pics/seqdepth_IGV.png"/&gt;
  &lt;p class="caption center"&gt;Visualize sequencing depth in IGV&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;IGV is good for daily research, but when it comes to customization, there aren&amp;rsquo;t many options. And if the visualization is aimed for publishing, one might want the figure to be vectorized and, more importantly, &lt;em&gt;reproducible&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Therefore, combining with what I learnt in &lt;a href="https://blog.liang2.tw/posts/2015/12/biocondutor-genomic-data/"&gt;Genomic Data Processing in Bioconductor&lt;/a&gt;, I tried to plot the sequencing depth in R with &lt;a href="https://bioconductor.org/packages/release/bioc/html/Gviz.html"&gt;Gviz&lt;/a&gt;. I thought learning Gviz will be demanding, since its vignette has 80 pages and the function documentation are &lt;a href="http://rpackages.ianhowson.com/bioc/Gviz/man/GeneRegionTrack-class.html"&gt;scarily long spells&lt;/a&gt;. But both of them turned out to be &lt;em&gt;really&lt;/em&gt; helpful and informative, especially when trying to tune its behavior. Figures produced by Gviz are aesthetically pleasing, and Gviz has many features as well (still trying). I&amp;rsquo;m glad that I gave it a shot.&lt;/p&gt;
&lt;p&gt;If you want to follow the code yourself, any human BAM alignment files will do. For example, the GEO dataset &lt;a href="http://dev.3dvcell.org/geo/query/acc.cgi?acc=GSE48215"&gt;GSE48215&lt;/a&gt; contains exome sequencing of breast cancer cell lines.&lt;/p&gt;
&lt;h2 id="convert-sequencing-depth-to-bedgraph-format"&gt;Convert sequencing depth to BedGraph format&lt;/h2&gt;
&lt;p&gt;After a quick search, Gviz&amp;rsquo;s &lt;a href="http://rpackages.ianhowson.com/bioc/Gviz/man/DataTrack-class.html"&gt;DataTrack&lt;/a&gt; accepts BedGraph format. This format can display any numerical value of chromosome ranges, shown as follows,&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;chromosome&lt;/th&gt;
&lt;th&gt;start&lt;/th&gt;
&lt;th&gt;end&lt;/th&gt;
&lt;th align="right"&gt;value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;chr1&lt;/td&gt;
&lt;td&gt;10,051&lt;/td&gt;
&lt;td&gt;10,093&lt;/td&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;chr1&lt;/td&gt;
&lt;td&gt;10,093&lt;/td&gt;
&lt;td&gt;10,104&lt;/td&gt;
&lt;td align="right"&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;/td&gt;
&lt;td align="right"&gt;&amp;hellip;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So we need to convert the alignment result as BedGraph format, which can be done by &lt;a href="http://bedtools.readthedocs.org/en/latest/content/tools/genomecov.html"&gt;BEDTools&amp;rsquo; genomecov&lt;/a&gt; command. On BEDTools&amp;rsquo; documentation, it notes that the BAM file should be sorted. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bedtools genomecov -bg -ibam myseq.bam &amp;gt; myseq.bedGraph
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The plain text BedGraph can be huge, pipe&amp;rsquo;d with gzip will reduce file size to around 30% of the original.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bedtools genomecov -bg -ibam myseq.bam &lt;span class="p"&gt;|&lt;/span&gt; gzip &amp;gt; myseq.bedGraph.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="plot-depth-in-gviz"&gt;Plot depth in Gviz&lt;/h2&gt;
&lt;p&gt;R packages of human genome annotations (&lt;a href="http://bioconductor.org/packages/release/data/annotation/html/Homo.sapiens.html"&gt;Homo.sapiens&lt;/a&gt;) and &lt;a href="https://bioconductor.org/packages/release/bioc/html/Gviz.html"&gt;Gviz&lt;/a&gt; itself are required. Also, &lt;a href="https://cran.r-project.org/web/packages/data.table/index.html"&gt;data.table&lt;/a&gt; gives an impressed speed at reading text tables so is recommended to use. During the analysis, I happened to know that data.table supports &lt;a href="https://github.com/Rdatatable/data.table/issues/717"&gt;reading gzip&amp;rsquo;d file through pipe&lt;/a&gt;, which makes it more awesome.&lt;/p&gt;
&lt;h3 id="first-gviz-track"&gt;First Gviz track&lt;/h3&gt;
&lt;p&gt;We should first start at reading our sequencing depth as BedGraph format and plot it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;data.table&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;Gviz&lt;span class="p"&gt;)&lt;/span&gt;

bedgraph_dt &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; fread&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s"&gt;&amp;#39;./coverage.bedGraph&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    col.names &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;chromosome&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;start&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;end&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Specifiy the range to plot&lt;/span&gt;
thechr &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;chr17&amp;quot;&lt;/span&gt;
st &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;41176e3&lt;/span&gt;
en &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;41324e3&lt;/span&gt;

bedgraph_dt_one_chr &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; bedgraph_dt&lt;span class="p"&gt;[&lt;/span&gt;chromosome &lt;span class="o"&gt;==&lt;/span&gt; thechr&lt;span class="p"&gt;]&lt;/span&gt;
dtrack &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; DataTrack&lt;span class="p"&gt;(&lt;/span&gt;
    range &lt;span class="o"&gt;=&lt;/span&gt; bedgraph_dt_one_chr&lt;span class="p"&gt;,&lt;/span&gt;
    type &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;a&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    genome &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;hg19&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    name &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Seq. Depth&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
plotTracks&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="kt"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;dtrack&lt;span class="p"&gt;),&lt;/span&gt;
    from &lt;span class="o"&gt;=&lt;/span&gt; st&lt;span class="p"&gt;,&lt;/span&gt; to &lt;span class="o"&gt;=&lt;/span&gt; en
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So we read the sequencing depth data, create a Gviz &lt;code&gt;DataTrack&lt;/code&gt; holding the subset of our data on chr17, then plot Gviz tracks by &lt;code&gt;plotTracks&lt;/code&gt; (though we only made one here) within a given chromosome region. Here is what we got.&lt;/p&gt;
&lt;div class="figure"&gt;
  &lt;img src="https://blog.liang2.tw/posts/2016/01/plot-seq-depth-gviz/pics/seqdepth_one_track.png"/&gt;
&lt;/div&gt;

&lt;h3 id="add-genome-axis"&gt;Add genome axis&lt;/h3&gt;
&lt;p&gt;The figure is a bit weird and lack of information without the genomic location. &lt;/p&gt;
&lt;p&gt;Adding genomic location can be done automatically by Gviz through a new track &lt;code&gt;GenomeAxisTrack&lt;/code&gt;. Also, we&amp;rsquo;d like to show which region of chromosome we are at. This can be done by adding another track, &lt;code&gt;IdeogramTrack&lt;/code&gt;, to show the chromosome ideogram. Note that the latter track will download cytoband data from UCSC so the given genome must have a valid name.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;itrack &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; IdeogramTrack&lt;span class="p"&gt;(&lt;/span&gt;
    genome &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;hg19&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; chromosome &lt;span class="o"&gt;=&lt;/span&gt; thechr
&lt;span class="p"&gt;)&lt;/span&gt;
gtrack &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; GenomeAxisTrack&lt;span class="p"&gt;()&lt;/span&gt;

plotTracks&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="kt"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;itrack&lt;span class="p"&gt;,&lt;/span&gt; gtrack&lt;span class="p"&gt;,&lt;/span&gt; dtrack&lt;span class="p"&gt;),&lt;/span&gt;
    from &lt;span class="o"&gt;=&lt;/span&gt; st&lt;span class="p"&gt;,&lt;/span&gt; to &lt;span class="o"&gt;=&lt;/span&gt; en
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
  &lt;img src="https://blog.liang2.tw/posts/2016/01/plot-seq-depth-gviz/pics/seqdepth_with_loc.png"/&gt;
&lt;/div&gt;

&lt;p&gt;Better now :)&lt;/p&gt;
&lt;h3 id="add-annotation"&gt;Add annotation&lt;/h3&gt;
&lt;p&gt;Since we are using exome sequencing, the curve of sequencing depth only makes senses when combined with the transcript annotations. &lt;/p&gt;
&lt;p&gt;Gviz has &lt;code&gt;GeneRegionTrack&lt;/code&gt; to extract annotation from the R annotation packages. Package Homo.sapiens includes the gene annotation package using UCSC knownGene database. Adding this new track and we will have annotation on our plot.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;TxDb.Hsapiens.UCSC.hg19.knownGene&lt;span class="p"&gt;)&lt;/span&gt;
txdb &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; TxDb.Hsapiens.UCSC.hg19.knownGene

grtrack &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; GeneRegionTrack&lt;span class="p"&gt;(&lt;/span&gt;
    txdb&lt;span class="p"&gt;,&lt;/span&gt;
    chromosome &lt;span class="o"&gt;=&lt;/span&gt; thechr&lt;span class="p"&gt;,&lt;/span&gt; start &lt;span class="o"&gt;=&lt;/span&gt; st&lt;span class="p"&gt;,&lt;/span&gt; end &lt;span class="o"&gt;=&lt;/span&gt; en&lt;span class="p"&gt;,&lt;/span&gt;
    showId &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    name &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Gene Annotation&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

plotTracks&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="kt"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;itrack&lt;span class="p"&gt;,&lt;/span&gt; gtrack&lt;span class="p"&gt;,&lt;/span&gt; dtrack&lt;span class="p"&gt;,&lt;/span&gt; grtrack&lt;span class="p"&gt;),&lt;/span&gt;
    from &lt;span class="o"&gt;=&lt;/span&gt; st&lt;span class="p"&gt;,&lt;/span&gt; to &lt;span class="o"&gt;=&lt;/span&gt; en
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
  &lt;img src="https://blog.liang2.tw/posts/2016/01/plot-seq-depth-gviz/pics/seqdepth_with_annotation.png"/&gt;
&lt;/div&gt;

&lt;p&gt;The plot should now be as informative as what we can get from the IGV. In fact, Gviz can plot the alignment result too. It can read the BAM file directly and show a more detailed coverage that matches what IGV can do. I&amp;rsquo;ll leave that part at the end of this post. &lt;/p&gt;
&lt;p&gt;So far we&amp;rsquo;ve shown the sequencing depth of some chromosome region with annotation. However, there still leave something to be desired, mostly about the annotation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can we show only the annotation of certain genes?&lt;/li&gt;
&lt;li&gt;knownGene&amp;rsquo;s identifier is barely meaningless, can we show the gene symbol instead?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So here comes the second part, annotation fine tuning.&lt;/p&gt;
&lt;h2 id="plot-fine-tune"&gt;Plot fine tune&lt;/h2&gt;
&lt;p&gt;Say, we only care about gene &lt;em&gt;BRCA1&lt;/em&gt;. So we need to get its location, or specifically, the genomic range that cover all &lt;em&gt;BRCA1&lt;/em&gt; isoforms. In the following example, I will demonstrate the Gviz&amp;rsquo;s annotation fine tuning.&lt;/p&gt;
&lt;h3 id="genome-annotation-query-in-bioconductorr"&gt;Genome annotation query in Bioconductor/R&lt;/h3&gt;
&lt;p&gt;If you are not familiar with how to query annotations in Bioconductor, it&amp;rsquo;s easier to think by breaking our goal of finding &lt;em&gt;BRCA1&lt;/em&gt;&amp;lsquo;s ranges into two steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Get the transcript IDs&lt;/li&gt;
&lt;li&gt;Query the transcript locations by their IDs&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Getting transcript IDs given their gene symbol is a &lt;code&gt;select()&lt;/code&gt; on OrganismDb object,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Get all transcript IDs of gene BRCA1&lt;/span&gt;
BRCA1_txnames &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; select&lt;span class="p"&gt;(&lt;/span&gt;
    Homo.sapiens&lt;span class="p"&gt;,&lt;/span&gt;
    keys &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;BRCA1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; keytype &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;SYMBOL&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    columns &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ENTREZID&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;TXNAME&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;TXNAME
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt; &lt;/span&gt;BRCA1_txnames
&lt;span class="go"&gt; [1] &amp;quot;uc010whl.2&amp;quot; &amp;quot;uc002icp.4&amp;quot; &amp;quot;uc010whm.2&amp;quot; &amp;quot;uc002icu.3&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt; [5] &amp;quot;uc010cyx.3&amp;quot; &amp;quot;uc002icq.3&amp;quot; &amp;quot;uc002ict.3&amp;quot; &amp;quot;uc010whn.2&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt; [9] &amp;quot;uc010who.3&amp;quot; &amp;quot;uc010whp.2&amp;quot; &amp;quot;uc010whq.1&amp;quot; &amp;quot;uc002idc.1&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;[13] &amp;quot;uc010whr.1&amp;quot; &amp;quot;uc002idd.3&amp;quot; &amp;quot;uc002ide.1&amp;quot; &amp;quot;uc010cyy.1&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;[17] &amp;quot;uc010whs.1&amp;quot; &amp;quot;uc010cyz.2&amp;quot; &amp;quot;uc010cza.2&amp;quot; &amp;quot;uc010wht.1&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Look like it has plenty of isoforms!&lt;/p&gt;
&lt;h4 id="via-transcripts"&gt;via &lt;code&gt;transcripts()&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;For the transcript location, the easiest way will be querying the txDb via &lt;code&gt;transcript()&lt;/code&gt;,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;BRCA1_txs &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; transcripts&lt;span class="p"&gt;(&lt;/span&gt;
    Homo.sapiens&lt;span class="p"&gt;,&lt;/span&gt;
    vals&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kt"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;tx_name &lt;span class="o"&gt;=&lt;/span&gt; BRCA1_txnames&lt;span class="p"&gt;),&lt;/span&gt;
    columns&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;TXNAME&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;SYMBOL&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;EXONID&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt; &lt;/span&gt;BRCA1_txs
&lt;span class="go"&gt;GRanges object with 20 ranges and 3 metadata columns:&lt;/span&gt;
&lt;span class="go"&gt;       seqnames               ranges strand   |                   EXONID          TXNAME          SYMBOL&lt;/span&gt;
&lt;span class="go"&gt;          &amp;lt;Rle&amp;gt;            &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;   |            &amp;lt;IntegerList&amp;gt; &amp;lt;CharacterList&amp;gt; &amp;lt;CharacterList&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;   [1]    chr17 [41196312, 41276132]      -   | 227486,227485,227482,...      uc010whl.2           BRCA1&lt;/span&gt;
&lt;span class="go"&gt;   [2]    chr17 [41196312, 41277340]      -   | 227487,227486,227485,...      uc002icp.4           BRCA1&lt;/span&gt;
&lt;span class="go"&gt;   [3]    chr17 [41196312, 41277340]      -   | 227487,227464,227463,...      uc010whm.2           BRCA1&lt;/span&gt;
&lt;span class="go"&gt;   [4]    chr17 [41196312, 41277468]      -   | 227489,227486,227485,...      uc002icu.3           BRCA1&lt;/span&gt;
&lt;span class="go"&gt;   [5]    chr17 [41196312, 41277468]      -   | 227489,227486,227482,...      uc010cyx.3           BRCA1&lt;/span&gt;
&lt;span class="go"&gt;   ...      ...                  ...    ... ...                      ...             ...             ...&lt;/span&gt;
&lt;span class="go"&gt;  [16]    chr17 [41243452, 41277340]      -   | 227487,227486,227485,...      uc010cyy.1           BRCA1&lt;/span&gt;
&lt;span class="go"&gt;  [17]    chr17 [41243452, 41277468]      -   | 227489,227486,227485,...      uc010whs.1           BRCA1&lt;/span&gt;
&lt;span class="go"&gt;  [18]    chr17 [41243452, 41277500]      -   | 227488,227486,227485,...      uc010cyz.2           BRCA1&lt;/span&gt;
&lt;span class="go"&gt;  [19]    chr17 [41243452, 41277500]      -   | 227488,227486,227485,...      uc010cza.2           BRCA1&lt;/span&gt;
&lt;span class="go"&gt;  [20]    chr17 [41243452, 41277500]      -   |            227488,227474      uc010wht.1           BRCA1&lt;/span&gt;
&lt;span class="go"&gt;  -------&lt;/span&gt;
&lt;span class="go"&gt;  seqinfo: 93 sequences (1 circular) from hg19 genome&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then get the genomic range of these transcripts by &lt;code&gt;seqnames()&lt;/code&gt;, &lt;code&gt;start()&lt;/code&gt; and &lt;code&gt;end()&lt;/code&gt; functions on the &lt;code&gt;GRanages&lt;/code&gt; object,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;thechr &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;as.character&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    seqnames&lt;span class="p"&gt;(&lt;/span&gt;BRCA1_txs&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;))&lt;/span&gt;
st &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;start&lt;span class="p"&gt;(&lt;/span&gt;BRCA1_txs&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="m"&gt;2e4&lt;/span&gt;
en &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="p"&gt;(&lt;/span&gt;BRCA1_txs&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="m"&gt;1e3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Some space are added at both ends so the plot won&amp;rsquo;t tightly fit all transcripts and leave some room for the transcript names. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt; &lt;/span&gt;&lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;thechr&lt;span class="p"&gt;,&lt;/span&gt; st&lt;span class="p"&gt;,&lt;/span&gt; en&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="go"&gt;[1] &amp;quot;chr17&amp;quot;    &amp;quot;41176312&amp;quot; &amp;quot;41323420&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4 id="via-exonsby"&gt;via &lt;code&gt;exonsBy()&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Another way to obtain the genomic range is getting the exact range of CDS (e.g. exons and UTRs) for each transcript via &lt;code&gt;exonsBy()&lt;/code&gt;. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;BRCA1_cds_by_tx &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; exonsBy&lt;span class="p"&gt;(&lt;/span&gt;
    Homo.sapiens&lt;span class="p"&gt;,&lt;/span&gt; by&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;tx&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; use.names&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;TRUE&lt;/span&gt;
&lt;span class="p"&gt;)[&lt;/span&gt;BRCA1_txnames&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The function returns a &lt;code&gt;GRangesList&lt;/code&gt; object, a list of &lt;code&gt;GRanges&lt;/code&gt; that each &lt;code&gt;GRanges&lt;/code&gt; object corresponds to a transcript respectively.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt; &lt;/span&gt;BRCA1_cds_by_tx
&lt;span class="go"&gt;GRangesList object of length 20:&lt;/span&gt;
&lt;span class="go"&gt;$uc010whl.2 &lt;/span&gt;
&lt;span class="go"&gt;GRanges object with 22 ranges and 3 metadata columns:&lt;/span&gt;
&lt;span class="go"&gt;       seqnames               ranges strand   |   exon_id   exon_name exon_rank&lt;/span&gt;
&lt;span class="go"&gt;          &amp;lt;Rle&amp;gt;            &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;   | &amp;lt;integer&amp;gt; &amp;lt;character&amp;gt; &amp;lt;integer&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;   [1]    chr17 [41276034, 41276132]      -   |    227486        &amp;lt;NA&amp;gt;         1&lt;/span&gt;
&lt;span class="go"&gt;   [2]    chr17 [41267743, 41267796]      -   |    227485        &amp;lt;NA&amp;gt;         2&lt;/span&gt;
&lt;span class="go"&gt;   [3]    chr17 [41258473, 41258550]      -   |    227482        &amp;lt;NA&amp;gt;         3&lt;/span&gt;
&lt;span class="go"&gt;   [4]    chr17 [41256885, 41256973]      -   |    227481        &amp;lt;NA&amp;gt;         4&lt;/span&gt;
&lt;span class="go"&gt;   [5]    chr17 [41256139, 41256278]      -   |    227480        &amp;lt;NA&amp;gt;         5&lt;/span&gt;
&lt;span class="go"&gt;   ...      ...                  ...    ... ...       ...         ...       ...&lt;/span&gt;
&lt;span class="go"&gt;  [18]    chr17 [41209069, 41209152]      -   |    227462        &amp;lt;NA&amp;gt;        18&lt;/span&gt;
&lt;span class="go"&gt;  [19]    chr17 [41203080, 41203134]      -   |    227461        &amp;lt;NA&amp;gt;        19&lt;/span&gt;
&lt;span class="go"&gt;  [20]    chr17 [41201138, 41201211]      -   |    227459        &amp;lt;NA&amp;gt;        20&lt;/span&gt;
&lt;span class="go"&gt;  [21]    chr17 [41199660, 41199720]      -   |    227458        &amp;lt;NA&amp;gt;        21&lt;/span&gt;
&lt;span class="go"&gt;  [22]    chr17 [41196312, 41197819]      -   |    227457        &amp;lt;NA&amp;gt;        22&lt;/span&gt;

&lt;span class="go"&gt;...&lt;/span&gt;
&lt;span class="go"&gt;&amp;lt;19 more elements&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;-------&lt;/span&gt;
&lt;span class="go"&gt;seqinfo: 93 sequences (1 circular) from hg19 genome&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;GRangesList&lt;/code&gt; is not merely a R list structure, which can correctly propagate the GRanges-related functions to all the GRanges it contain.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt; &lt;/span&gt;start&lt;span class="p"&gt;(&lt;/span&gt;BRCA1_cds_by_tx&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="go"&gt;IntegerList of length 20&lt;/span&gt;
&lt;span class="go"&gt;[[&amp;quot;uc010whl.2&amp;quot;]] 41276034 41267743 41258473 ... 41201138 41199660 41196312&lt;/span&gt;
&lt;span class="go"&gt;[[&amp;quot;uc002icp.4&amp;quot;]] 41277199 41276034 41267743 ... 41201138 41199660 41196312&lt;/span&gt;
&lt;span class="go"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here we only cares about the widest range, so the hierarchical structure is not useful. It would be better to flatten the &lt;code&gt;GRangesList&lt;/code&gt; first,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt; &lt;/span&gt;BRCA1_cds_flatten &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;unlist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;BRCA1_cds_by_tx&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt; &lt;/span&gt;BRCA1_cds_flatten
&lt;span class="go"&gt;GRanges object with 284 ranges and 3 metadata columns:&lt;/span&gt;
&lt;span class="go"&gt;             seqnames               ranges strand   |   exon_id   exon_name exon_rank&lt;/span&gt;
&lt;span class="go"&gt;                &amp;lt;Rle&amp;gt;            &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;   | &amp;lt;integer&amp;gt; &amp;lt;character&amp;gt; &amp;lt;integer&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;  uc010whl.2    chr17 [41276034, 41276132]      -   |    227486        &amp;lt;NA&amp;gt;         1&lt;/span&gt;
&lt;span class="go"&gt;  uc010whl.2    chr17 [41267743, 41267796]      -   |    227485        &amp;lt;NA&amp;gt;         2&lt;/span&gt;
&lt;span class="go"&gt;  uc010whl.2    chr17 [41258473, 41258550]      -   |    227482        &amp;lt;NA&amp;gt;         3&lt;/span&gt;
&lt;span class="go"&gt;  uc010whl.2    chr17 [41256885, 41256973]      -   |    227481        &amp;lt;NA&amp;gt;         4&lt;/span&gt;
&lt;span class="go"&gt;  uc010whl.2    chr17 [41256139, 41256278]      -   |    227480        &amp;lt;NA&amp;gt;         5&lt;/span&gt;
&lt;span class="go"&gt;         ...      ...                  ...    ... ...       ...         ...       ...&lt;/span&gt;
&lt;span class="go"&gt;  uc010cza.2    chr17 [41249261, 41249306]      -   |    227477        &amp;lt;NA&amp;gt;         7&lt;/span&gt;
&lt;span class="go"&gt;  uc010cza.2    chr17 [41247863, 41247939]      -   |    227476        &amp;lt;NA&amp;gt;         8&lt;/span&gt;
&lt;span class="go"&gt;  uc010cza.2    chr17 [41243452, 41246877]      -   |    227474        &amp;lt;NA&amp;gt;         9&lt;/span&gt;
&lt;span class="go"&gt;  uc010wht.1    chr17 [41277288, 41277500]      -   |    227488        &amp;lt;NA&amp;gt;         1&lt;/span&gt;
&lt;span class="go"&gt;  uc010wht.1    chr17 [41243452, 41246877]      -   |    227474        &amp;lt;NA&amp;gt;         2&lt;/span&gt;
&lt;span class="go"&gt;  -------&lt;/span&gt;
&lt;span class="go"&gt;  seqinfo: 93 sequences (1 circular) from hg19 genome&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We have the BRCA1 genomic region, rest of the plotting is the same.&lt;/p&gt;
&lt;h3 id="show-only-the-annotations-of-certain-genes"&gt;Show only the annotations of certain genes&lt;/h3&gt;
&lt;p&gt;Before we start to create our own annotation subset, we first take a look at what Gviz generated. The &lt;code&gt;GeneRegionTrack&lt;/code&gt; track store its annotation data at slot &lt;code&gt;range&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt; &lt;/span&gt;grtrack&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="kp"&gt;range&lt;/span&gt;
&lt;span class="go"&gt;GRanges object with 459 ranges and 7 metadata columns:&lt;/span&gt;
&lt;span class="go"&gt;        seqnames               ranges strand   |     feature          id         exon  transcript        gene      symbol   density&lt;/span&gt;
&lt;span class="go"&gt;           &amp;lt;Rle&amp;gt;            &amp;lt;IRanges&amp;gt;  &amp;lt;Rle&amp;gt;   | &amp;lt;character&amp;gt; &amp;lt;character&amp;gt;  &amp;lt;character&amp;gt; &amp;lt;character&amp;gt; &amp;lt;character&amp;gt; &amp;lt;character&amp;gt; &amp;lt;numeric&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;    [1]    chr17 [41177258, 41177364]      +   |        utr5     unknown uc002icn.3_1  uc002icn.3        8153  uc002icn.3         1&lt;/span&gt;
&lt;span class="go"&gt;    [2]    chr17 [41177365, 41177466]      +   |         CDS     unknown uc002icn.3_1  uc002icn.3        8153  uc002icn.3         1&lt;/span&gt;
&lt;span class="go"&gt;    [3]    chr17 [41177977, 41178064]      +   |         CDS     unknown uc002icn.3_2  uc002icn.3        8153  uc002icn.3         1&lt;/span&gt;
&lt;span class="go"&gt;    [4]    chr17 [41179200, 41179309]      +   |         CDS     unknown uc002icn.3_3  uc002icn.3        8153  uc002icn.3         1&lt;/span&gt;
&lt;span class="go"&gt;    [5]    chr17 [41180078, 41180212]      +   |         CDS     unknown uc002icn.3_4  uc002icn.3        8153  uc002icn.3         1&lt;/span&gt;
&lt;span class="go"&gt;    ...      ...                  ...    ... ...         ...         ...          ...         ...         ...         ...       ...&lt;/span&gt;
&lt;span class="go"&gt;  [455]    chr17 [41277294, 41277468]      -   |        utr5     unknown uc010cyx.3_1  uc010cyx.3         672  uc010cyx.3         1&lt;/span&gt;
&lt;span class="go"&gt;  [456]    chr17 [41277294, 41277468]      -   |        utr5     unknown uc002idc.1_1  uc002idc.1         672  uc002idc.1         1&lt;/span&gt;
&lt;span class="go"&gt;  [457]    chr17 [41277294, 41277468]      -   |        utr5     unknown uc010whr.1_1  uc010whr.1         672  uc010whr.1         1&lt;/span&gt;
&lt;span class="go"&gt;  [458]    chr17 [41277294, 41277468]      -   |        utr5     unknown uc010whs.1_1  uc010whs.1         672  uc010whs.1         1&lt;/span&gt;
&lt;span class="go"&gt;  [459]    chr17 [41322143, 41322420]      -   |        utr5     unknown uc010whp.2_1  uc010whp.2         672  uc010whp.2         1&lt;/span&gt;
&lt;span class="go"&gt;  -------&lt;/span&gt;
&lt;span class="go"&gt;  seqinfo: 1 sequence from hg19 genome; no seqlengths&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So we filter out unrelated ranges by checking if the value of metadata column &lt;code&gt;transcript&lt;/code&gt; is one of &lt;em&gt;BRCA1&lt;/em&gt;&amp;lsquo;s transcript IDs,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;BRCA_only_range &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; grtrack&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="kp"&gt;range&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
    mcols&lt;span class="p"&gt;(&lt;/span&gt;grtrack&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="kp"&gt;range&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;transcript &lt;span class="o"&gt;%in%&lt;/span&gt; BRCA1_txnames
&lt;span class="p"&gt;]&lt;/span&gt;
grtrack&lt;span class="o"&gt;@&lt;/span&gt;range &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; BRCA_only_range
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;or by less hacky way that use the new range to construct another &lt;code&gt;GeneRegionTrack&lt;/code&gt;,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grtrack_BRCA_only &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; GeneRegionTrack&lt;span class="p"&gt;(&lt;/span&gt;
    BRCA_only_range&lt;span class="p"&gt;,&lt;/span&gt;
    chromosome &lt;span class="o"&gt;=&lt;/span&gt; thechr&lt;span class="p"&gt;,&lt;/span&gt; start &lt;span class="o"&gt;=&lt;/span&gt; st&lt;span class="p"&gt;,&lt;/span&gt; end &lt;span class="o"&gt;=&lt;/span&gt; en&lt;span class="p"&gt;,&lt;/span&gt;
    showId &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    name &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Gene Annotation (BRCA1 only)&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
plotTracks&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="kt"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;itrack&lt;span class="p"&gt;,&lt;/span&gt; gtrack&lt;span class="p"&gt;,&lt;/span&gt; dtrack&lt;span class="p"&gt;,&lt;/span&gt; grtrack_BRCA_only&lt;span class="p"&gt;),&lt;/span&gt;
    from &lt;span class="o"&gt;=&lt;/span&gt; st&lt;span class="p"&gt;,&lt;/span&gt; to &lt;span class="o"&gt;=&lt;/span&gt; en
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
  &lt;img src="https://blog.liang2.tw/posts/2016/01/plot-seq-depth-gviz/pics/seqdepth_BRCA1_only.png"/&gt;
&lt;/div&gt;

&lt;h3 id="display-gene-symbols-at-annotation-track"&gt;Display gene symbols at annotation track&lt;/h3&gt;
&lt;p&gt;It&amp;rsquo;s more obvious now about how Gviz stores the annotation. All we need is to replace the symbol name with whatever we desire.&lt;/p&gt;
&lt;p&gt;First, we extract the metadata of the &lt;code&gt;GeneRegionTrack&lt;/code&gt;, and query for their gene symbols. Using either the transcript ID or Entrez ID will do. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grtrack_range &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; grtrack&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="kp"&gt;range&lt;/span&gt;
range_mapping &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; select&lt;span class="p"&gt;(&lt;/span&gt;
    Homo.sapiens&lt;span class="p"&gt;,&lt;/span&gt;
    keys &lt;span class="o"&gt;=&lt;/span&gt; mcols&lt;span class="p"&gt;(&lt;/span&gt;grtrack_range&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;symbol&lt;span class="p"&gt;,&lt;/span&gt;
    keytype &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;TXNAME&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    columns &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;ENTREZID&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;SYMBOL&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt; &lt;/span&gt;&lt;span class="kp"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;range_mapping&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="go"&gt;      TXNAME SYMBOL ENTREZID&lt;/span&gt;
&lt;span class="go"&gt;1 uc002icn.3   RND2     8153&lt;/span&gt;
&lt;span class="go"&gt;2 uc002icn.3   RND2     8153&lt;/span&gt;
&lt;span class="go"&gt;3 uc002icn.3   RND2     8153&lt;/span&gt;
&lt;span class="go"&gt;4 uc002icn.3   RND2     8153&lt;/span&gt;
&lt;span class="go"&gt;5 uc002icn.3   RND2     8153&lt;/span&gt;
&lt;span class="go"&gt;6 uc002icn.3   RND2     8153&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then we concatenate the information of transcript ID and gene symbol using &lt;a href="https://cran.r-project.org/web/packages/stringr/index.html"&gt;stringr&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;stringr&lt;span class="p"&gt;)&lt;/span&gt;
new_symbols &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;with&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    range_mapping&lt;span class="p"&gt;,&lt;/span&gt;
    str_c&lt;span class="p"&gt;(&lt;/span&gt;SYMBOL&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; (&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; TXNAME&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; sep &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;&amp;gt; &lt;/span&gt;&lt;span class="kp"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;new_symbols&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="go"&gt;[1] &amp;quot;RND2 (uc002icn.3)&amp;quot; &amp;quot;NBR2 (uc002idf.3)&amp;quot; &amp;quot;NBR2 (uc010czb.2)&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;[4] &amp;quot;NBR2 (uc002idg.3)&amp;quot; &amp;quot;NBR2 (uc002idh.3)&amp;quot; &amp;quot;NBR1 (uc010czd.3)&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Like how we extract &lt;em&gt;BRCA1&lt;/em&gt;-only annotations, we construct a new &lt;code&gt;GeneRegionTrack&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grtrack_symbol &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; GeneRegionTrack&lt;span class="p"&gt;(&lt;/span&gt;
    grtrack&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="kp"&gt;range&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    chromosome &lt;span class="o"&gt;=&lt;/span&gt; thechr&lt;span class="p"&gt;,&lt;/span&gt; start &lt;span class="o"&gt;=&lt;/span&gt; st&lt;span class="p"&gt;,&lt;/span&gt; end &lt;span class="o"&gt;=&lt;/span&gt; en&lt;span class="p"&gt;,&lt;/span&gt;
    showId &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    name &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Gene Annotation w. Symbol&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
symbol&lt;span class="p"&gt;(&lt;/span&gt;grtrack_symbol&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; new_symbols
plotTracks&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="kt"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;itrack&lt;span class="p"&gt;,&lt;/span&gt; gtrack&lt;span class="p"&gt;,&lt;/span&gt; dtrack&lt;span class="p"&gt;,&lt;/span&gt; grtrack_symbol&lt;span class="p"&gt;),&lt;/span&gt;
    from &lt;span class="o"&gt;=&lt;/span&gt; st&lt;span class="p"&gt;,&lt;/span&gt; to &lt;span class="o"&gt;=&lt;/span&gt; en
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
  &lt;img src="https://blog.liang2.tw/posts/2016/01/plot-seq-depth-gviz/pics/seqdepth_gene_symbol.png"/&gt;
&lt;/div&gt;

&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;
&lt;p&gt;So we&amp;rsquo;ve learnt how to plot using Gviz. You should go explore other data tracks or try to combine sequencing depth of multiple samples. I found the design of Gviz is clean and easy to modify. I think I&amp;rsquo;ll use Gviz whenever genome-related plots are needed. &lt;/p&gt;
&lt;p&gt;Really glad I&amp;rsquo;ve tried it :)&lt;/p&gt;
&lt;h2 id="supplementary-plot-bam-files-directly"&gt;Supplementary - Plot BAM files directly&lt;/h2&gt;
&lt;p&gt;We will start by replacing &lt;code&gt;DataTrack&lt;/code&gt; with &lt;code&gt;AlignmentsTrack&lt;/code&gt;. Also we select a smaller region this time so the read mapping can be clearly seen.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;st &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;41.196e6L&lt;/span&gt;
en &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;41.202e6L&lt;/span&gt;
gtrack &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; GenomeAxisTrack&lt;span class="p"&gt;(&lt;/span&gt;cex &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# set the font size larger&lt;/span&gt;
altrack &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; AlignmentsTrack&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s"&gt;&amp;quot;myseq.bam&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; isPaired &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col.mates &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;deeppink&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
plotTracks&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="kt"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;gtrack&lt;span class="p"&gt;,&lt;/span&gt; altrack&lt;span class="p"&gt;,&lt;/span&gt; grtrack&lt;span class="p"&gt;),&lt;/span&gt;
    from &lt;span class="o"&gt;=&lt;/span&gt; st&lt;span class="p"&gt;,&lt;/span&gt; to &lt;span class="o"&gt;=&lt;/span&gt; en
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
  &lt;img src="https://blog.liang2.tw/posts/2016/01/plot-seq-depth-gviz/pics/seqdepth_BAM_default.png"/&gt;
&lt;/div&gt;

&lt;p&gt;To plot only the coverage, set the type as &lt;code&gt;coverage&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;altrack &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; AlignmentsTrack&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s"&gt;&amp;quot;myseq.bam&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; type &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;coverage&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
  &lt;img src="https://blog.liang2.tw/posts/2016/01/plot-seq-depth-gviz/pics/seqdepth_BAM_coverage_only.png"/&gt;
&lt;/div&gt;

&lt;h3 id="fancier-alignment-display"&gt;Fancier alignment display&lt;/h3&gt;
&lt;p&gt;Spend some time reading the documentation, the alignment can be much more fancier. &lt;/p&gt;
&lt;p&gt;For example, when looking at a much smaller genome region, we many want to see the sequence and read mismatches. It could be done by adding a new track &lt;code&gt;SequenceTrack&lt;/code&gt; to include the genome sequence,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;small_st &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;41267.735e3L&lt;/span&gt;
small_en &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;41267.805e3L&lt;/span&gt;

&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;BSgenome.Hsapiens.UCSC.hg19&lt;span class="p"&gt;)&lt;/span&gt;
strack &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; SequenceTrack&lt;span class="p"&gt;(&lt;/span&gt;
    Hsapiens&lt;span class="p"&gt;,&lt;/span&gt;
    chromosome &lt;span class="o"&gt;=&lt;/span&gt; thechr&lt;span class="p"&gt;,&lt;/span&gt; from &lt;span class="o"&gt;=&lt;/span&gt; small_en&lt;span class="p"&gt;,&lt;/span&gt; to &lt;span class="o"&gt;=&lt;/span&gt; small_st&lt;span class="p"&gt;,&lt;/span&gt;
    cex&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0.8&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We tweak other tracks as well to make sure the figure won&amp;rsquo;t explode by too much information. Gene annotations are collapsed down to one liner. Also, aligned read&amp;rsquo;s height is increased to fit in individual letters (e.g., ATCG).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grtrack_small &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; GeneRegionTrack&lt;span class="p"&gt;(&lt;/span&gt;
   grtrack&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="kp"&gt;range&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
   chromosome &lt;span class="o"&gt;=&lt;/span&gt; thechr&lt;span class="p"&gt;,&lt;/span&gt;
   start &lt;span class="o"&gt;=&lt;/span&gt; small_st&lt;span class="p"&gt;,&lt;/span&gt; end &lt;span class="o"&gt;=&lt;/span&gt; small_en&lt;span class="p"&gt;,&lt;/span&gt;
   stacking &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;dense&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
   name &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Gene Annotation&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
altrack &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; AlignmentsTrack&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="s"&gt;&amp;quot;myseq.bam&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    isPaired &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    min.height &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; max.height &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; coverageHeight &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0.15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; size &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;50&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
plotTracks&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="kt"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;gtrack&lt;span class="p"&gt;,&lt;/span&gt; altrack&lt;span class="p"&gt;,&lt;/span&gt; grtrack_small&lt;span class="p"&gt;,&lt;/span&gt; strack&lt;span class="p"&gt;),&lt;/span&gt;
    from &lt;span class="o"&gt;=&lt;/span&gt; small_st&lt;span class="p"&gt;,&lt;/span&gt; to &lt;span class="o"&gt;=&lt;/span&gt; small_en
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
  &lt;img src="https://blog.liang2.tw/posts/2016/01/plot-seq-depth-gviz/pics/seqdepth_BAM_small_region.png"/&gt;
&lt;/div&gt;

&lt;p&gt;We found a C&amp;gt;T SNP here!&lt;/p&gt;</content><category term="en"></category><category term="r"></category><category term="bioconductor"></category><category term="gviz"></category><category term="NGS"></category></entry><entry><title>Overview of Genomic Data Processing in Bioconductor</title><link href="https://blog.liang2.tw/posts/2015/12/biocondutor-genomic-data/" rel="alternate"></link><published>2015-12-29T20:28:00-06:00</published><updated>2015-12-29T20:28:00-06:00</updated><author><name>Liang-Bo Wang</name></author><id>tag:blog.liang2.tw,2015-12-29:/posts/2015/12/biocondutor-genomic-data/</id><summary type="html">&lt;p&gt;Notes of fundamental tools and learning resources for handling genomic data in R with Bioconductor.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Sorry for the late update. In the past two months, I finished my Ph.D. applications (hope to hear good news in the next two months) and was busy preparing the PyCon Taiwan 2016. Also, a year-long website development finally came to the end.&lt;/p&gt;
&lt;p&gt;Now most things are set so I can back to writing my blog.&lt;/p&gt;
&lt;p&gt;Since September, there accumulates at least 5 drafts and I don&amp;rsquo;t know when I can finish them, so I think I have to change my writing strategy. I will first publish things as soon as information collection is done, and deeper reviews will be given in the following posts. Right now I will focus on Bioconductor (and general Bioinformatics topics) and Django.&lt;/p&gt;
&lt;div class="toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#bioconductor"&gt;Bioconductor&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#annotation-and-genome-reference"&gt;Annotation and Genome Reference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#experiment-data-storage"&gt;Experiment Data Storage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#operations-on-genome"&gt;Operations on Genome&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#genomic-data-visualization"&gt;Genomic data visualization&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#summary"&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h2 id="bioconductor"&gt;Bioconductor&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.bioconductor.org/"&gt;Bioconductor&lt;/a&gt; is indeed a rich resources for R both in terms of data and tools. And I found I have yet spent time seriously understanding the whole ecosystem, which I believe can drastically lighten the loading of daily analysis.&lt;/p&gt;
&lt;p&gt;Bioconductor&amp;rsquo;s website is informative. If you are familar with R, you should already know that in order to understand the usage of a package, one of the best way is to read its vignettes. Packages on Bioconductor generally have vignettes, which is really helpful and the website makes them accessible. On top of that, they have &lt;a href="https://www.bioconductor.org/help/course-materials/"&gt;Courses &amp;amp; Conferences&lt;/a&gt; and &lt;a href="https://www.bioconductor.org/help/workflows/"&gt;Workflows&lt;/a&gt;. The former section collects all conference materials in the past few years, which contains package hands-on, analysis tutorial, and R advanced topics. It&amp;rsquo;s a hidden gem to me since I have already found numerous materials worth reading only after a glance over it. The latter one should be well-known. It gives examples of typical analysis workflows.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m interested in the following topics in Biocondutor:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Annotation and genome reference (OrgDb, TxDb, OrganismDb, BSgenome)&lt;/li&gt;
&lt;li&gt;Experiment data storage (ExpressionSets)&lt;/li&gt;
&lt;li&gt;Operations on genome (GenomicRanges)&lt;/li&gt;
&lt;li&gt;Genomic data visualization (Gviz, ggbio)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Keywords in Biocondutors for each topic are attached in the parens, mostly being the package name. For each topic, I&amp;rsquo;ll put the related resources I collected in the following sections.&lt;/p&gt;
&lt;p&gt;Before the listing, I found &lt;a href="http://genomicsclass.github.io/book/"&gt;PH525x series&lt;/a&gt; maintained by Rafael Irizarry and Michael Love from Harvard serves as a comprehensive entry point for almost every related topic. The site is the accompanied resources for their edX classes. Both of them worth taking a look.&lt;/p&gt;
&lt;h3 id="annotation-and-genome-reference"&gt;Annotation and Genome Reference&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://genomicsclass.github.io/book/pages/annoPhen.html"&gt;Annotating phenotypes and molecular function&lt;/a&gt; from &lt;a href="http://genomicsclass.github.io/book/"&gt;PH525x series&lt;/a&gt; gives a good overview and a taste of the powerful ecosystem Bioconductor provides.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.bioconductor.org/help/course-materials/2015/BioC2015/Annotation_Resources.html"&gt;Annotation Resources&lt;/a&gt; from &lt;a href="https://www.bioconductor.org/help/course-materials/2015/BioC2015/"&gt;BioC 2015&lt;/a&gt; gives more extensive introduction about all available types of references from genome sequences to transcriptome and gene info.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, human comes with&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://bioconductor.org/packages/release/data/annotation/html/org.Hs.eg.db.html"&gt;org.Hs.eg.db&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://bioconductor.org/packages/release/data/annotation/html/TxDb.Hsapiens.UCSC.hg38.knownGene.html"&gt;TxDb.Hsapiens.UCSC.hg38.knownGene&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://bioconductor.org/packages/release/data/annotation/html/Homo.sapiens.html"&gt;Homo.sapiens&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://bioconductor.org/packages/release/data/annotation/html/BSgenome.Hsapiens.UCSC.hg38.html"&gt;BSgenome.Hsapiens.UCSC.hg38&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="experiment-data-storage"&gt;Experiment Data Storage&lt;/h3&gt;
&lt;p&gt;ExpressionSet helps store the expression experiment data, which one can combine   expression values and phenotypes of the same sample. Additionally the experiment data (like descriptions of GEO dataset) can be attached as well.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://genomicsclass.github.io/book/pages/eset.html"&gt;The ExpressionSet container&lt;/a&gt; from &lt;a href="http://genomicsclass.github.io/book/"&gt;PH525x series&lt;/a&gt; gives an intro. It should be sufficient enough to use ExpressionSet in daily work.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.bioconductor.org/packages/release/bioc/vignettes/Biobase/inst/doc/ExpressionSetIntroduction.pdf"&gt;The ExpressionSet Introduction&lt;/a&gt; from its package &lt;a href="https://www.bioconductor.org/packages/release/bioc/html/Biobase.html"&gt;Biobase&lt;/a&gt;’s vignette gives detailed explanation.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="operations-on-genome"&gt;Operations on Genome&lt;/h3&gt;
&lt;p&gt;I haven&amp;rsquo;t gone into the details, but operations about genomic ranges are often tricky and more importantly, badly optimized.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://genomicsclass.github.io/book/pages/iranges_granges.html"&gt;IRanges and GRanges&lt;/a&gt; and &lt;a href="http://genomicsclass.github.io/book/pages/operateGRanges.html"&gt;GRanges operations&lt;/a&gt; from &lt;a href="http://genomicsclass.github.io/book/"&gt;PH525x series&lt;/a&gt; give the overview of using the package &lt;a href="https://bioconductor.org/packages/release/bioc/html/GenomicRanges.html"&gt;GenomicRanges&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.bioconductor.org/packages/release/bioc/vignettes/GenomicRanges/inst/doc/GenomicRangesIntroduction.pdf"&gt;An Introduction to Genomic Ranges Classes&lt;/a&gt;, a &lt;a href="https://bioconductor.org/packages/release/bioc/html/GenomicRanges.html"&gt;GenomicRanges&lt;/a&gt; vignette, gives a detailed view.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Also, their paper, &lt;a href="http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003118"&gt;&amp;ldquo;Software for Computing and Annotating Genomic Ranges&amp;rdquo;, &lt;em&gt;PLOS One&lt;/em&gt;&lt;/a&gt; should be another overview source of the package.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://cran.r-project.org/web/packages/data.table/index.html"&gt;data.table&lt;/a&gt;&amp;lsquo;s &lt;code&gt;foverlap&lt;/code&gt; function worth the comparison, since I already use it and I know it is &lt;a href="https://github.com/Rdatatable/data.table/wiki/talks/EARL2014_OverlapRangeJoin_Arun.pdf"&gt;blazingly fast&lt;/a&gt;. &lt;code&gt;foverlap&lt;/code&gt; handles the overlapping of integer ranges so it can be applied to genomic operation. Its code is quite complex so its mechanism is still a myth to me. I&amp;rsquo;d like to see its comparison with using database like SQLite.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="genomic-data-visualization"&gt;Genomic data visualization&lt;/h3&gt;
&lt;p&gt;Basically I can find two packages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://bioconductor.org/packages/release/bioc/html/Gviz.html"&gt;Gviz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bioconductor.org/packages/release/bioc/html/ggbio.html"&gt;ggbio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Don&amp;rsquo;t know their difference yet. Both of them can produce well-done figures. But I think I have some experience with ggbio, which was a bit tricky to use. So for now I will go for Gviz.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.bioconductor.org/help/course-materials/2012/BiocEurope2012/GvizEuropeanBioc2012.pdf"&gt;Visualizing genomic features with the Gviz package&lt;/a&gt; given at Bioc Europe 2012 has a decent introduction about Gviz.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bioconductor.org/packages/release/bioc/vignettes/Gviz/inst/doc/Gviz.pdf"&gt;The Gviz User Guide&lt;/a&gt; looks very comprehensive, which also cover usage with expression and alignment results.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;
&lt;p&gt;These resources should be enough for weeks of trying. It&amp;rsquo;s excited to find so many useful tools.&lt;/p&gt;
&lt;p&gt;So, good luck to me for my Ph.D. application, PyCon Taiwan 2016, and a shorter blog posting frequency.&lt;/p&gt;</content><category term="en"></category><category term="r"></category><category term="bioconductor"></category></entry><entry><title>FASTA/Q sequence processing toolkit -- seqtk</title><link href="https://blog.liang2.tw/posts/2015/09/seqtk/" rel="alternate"></link><published>2015-09-27T14:11:00-05:00</published><updated>2015-09-27T14:11:00-05:00</updated><author><name>Liang-Bo Wang</name></author><id>tag:blog.liang2.tw,2015-09-27:/posts/2015/09/seqtk/</id><summary type="html">&lt;p&gt;This post demonstrates the FASTQ to FASTA conversion and sequence quality check using seqtk.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is the first post of the series of my common NGS processing workflows and notes.&lt;/p&gt;
&lt;p&gt;Some of the most common operation in sequence processing is FASTQ → FASTA conversion. Tons of conversion scripts using either sed or awk can be found by search. For example,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# FASTQ to FASTA&lt;/span&gt;
&lt;span class="c1"&gt;# Assume every read record takes exactly 4 line&lt;/span&gt;
&lt;span class="c1"&gt;# Ref: http://stackoverflow.com/a/10359425&lt;/span&gt;
$ sed -n &lt;span class="s1"&gt;&amp;#39;1~4s/^@/&amp;gt;/p;2~4p&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The assumption of 4 lines per read usually holds for recent NGS sequencing data, so not a big deal.&lt;/p&gt;
&lt;p&gt;In many case the sequence is gzip&amp;rsquo;d. It is still a piece of cake when combining with pipe editing,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gzcat myseq.fq.gz &lt;span class="p"&gt;|&lt;/span&gt; sed -n &lt;span class="s1"&gt;&amp;#39;1~4s/^@/&amp;gt;/p;2~4p&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; gzip &amp;gt; myseq.fa.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;However, things can get complex really fast when one wants to additionally do reverse complement, randomly sample a subset of reads, and many other types of sequence manipulation. Efficiency matters if those tasks are applied to tens of millions of reads. Even a few nanoseconds longer of computing time difference per read can make a difference at this scale of reads.&lt;/p&gt;
&lt;h3 id="seqtk"&gt;Seqtk&lt;/h3&gt;
&lt;p&gt;So &lt;a href="https://github.com/lh3/seqtk"&gt;seqtk&lt;/a&gt; comes into rescue. It is written in C and MIT licensed. &lt;a href="https://www.biostars.org/p/85929/#86082"&gt;A quick comparison&lt;/a&gt; shows it is generally faster than other UNIX-based solutions, let alone implementations based on scripting languages.&lt;/p&gt;
&lt;p&gt;Seqtk bundles many other operations, but I&amp;rsquo;ll just mention those I frequently use.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;$seqtk&lt;/span&gt;

Usage:   seqtk &amp;lt;command&amp;gt; &amp;lt;arguments&amp;gt;
Version: &lt;span class="m"&gt;1&lt;/span&gt;.0-r77-dirty

Command: seq       common transformation of FASTA/Q
         comp      get the nucleotide composition of FASTA/Q
         sample    subsample sequences
         subseq    extract subsequences from FASTA/Q
         fqchk     fastq QC &lt;span class="o"&gt;(&lt;/span&gt;base/quality summary&lt;span class="o"&gt;)&lt;/span&gt;
         mergepe   interleave two PE FASTA/Q files
         trimfq    trim FASTQ using the Phred algorithm

         hety      regional heterozygosity
         mutfa     point mutate FASTA at specified positions
         mergefa   merge two FASTA/Q files
         dropse    drop unpaired from interleaved PE FASTA/Q
         rename    rename sequence names
         randbase  choose a random base from hets
         cutN      cut sequence at long N
         listhet   extract the position of each het
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="fastq-fasta"&gt;FASTQ → FASTA&lt;/h3&gt;
&lt;p&gt;Read (gzip&amp;rsquo;d) FASTQ and write out as FASTA,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ seqtk seq -A in.fq&lt;span class="o"&gt;[&lt;/span&gt;.gz&lt;span class="o"&gt;]&lt;/span&gt; &amp;gt; out.fa
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To make the output gzip&amp;rsquo;d again, piped with gzip,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ seqtk seq -A in.fq&lt;span class="o"&gt;[&lt;/span&gt;.gz&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; gzip &amp;gt; out.fa.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="reverse-complement"&gt;Reverse complement&lt;/h3&gt;
&lt;p&gt;If one wants to debug the R2 reads of pair-end sequencing (second read on forward strand), since they contain reverse complement sequence of the insert DNA, one needs to reverse complement R2 reads again to debug directly by bare human eyes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ seqtk seq -r R2.fq &amp;gt; R2_rc.fq

$ &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;gt; Example R2 seq&lt;/span&gt;
&lt;span class="s1"&gt;  GCATTGGTGGTTCAGTGGTAGAATTCT&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; seqtk seq -r
&lt;span class="c1"&gt;# &amp;gt; Example R2 seq&lt;/span&gt;
&lt;span class="c1"&gt;# AGAATTCTACCACTGAACCACCAATGC&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="quality-check"&gt;Quality check&lt;/h3&gt;
&lt;p&gt;To be honest, &lt;a href="http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"&gt;FastQC&lt;/a&gt; is more frequently used for quality check because it generates &lt;a href="http://www.bioinformatics.babraham.ac.uk/projects/fastqc/good_sequence_short_fastqc.html"&gt;reports with beautiful figures&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But for a detail report on each read position, one should consider &lt;code&gt;seqtk fqchk&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ seqtk fqchk myseq.fq&lt;span class="o"&gt;[&lt;/span&gt;.gz&lt;span class="o"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;By default it sets &lt;code&gt;-q 20&lt;/code&gt;. This quality threshold determines the threshold of counting a base as low or high quality, shown as &lt;code&gt;%low&lt;/code&gt; and &lt;code&gt;%high&lt;/code&gt; per read position. In the default case, quality score higher than 20 will be treated as high quality bases.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;min_len: 10; max_len: 174; avg_len: 28.92; 37 distinct quality values
POS #bases    %A   %C   %G   %T   %N  avgQ errQ %low %high
ALL 236344886 17.0 22.5 31.3 29.2 0.0 39.9 37.6 0.1  99.9
1   8172342   8.9  12.4 57.0 21.7 0.0 39.6 29.0 0.5  99.5
2   8172342   7.7  62.5 16.2 13.7 0.0 39.8 37.8 0.2  99.8
3   8172342   50.3 24.1 11.9 13.6 0.0 39.8 38.2 0.1  99.9
4   8172342   10.4 22.9 15.3 51.3 0.0 39.9 38.7 0.1  99.9
5   8172342   14.3 12.9 22.3 50.5 0.0 39.8 37.0 0.2  99.8
# ... (trimmed)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The following columns, &lt;code&gt;avgQ&lt;/code&gt; and &lt;code&gt;errQ&lt;/code&gt;, need more explanation. Average quality (&lt;code&gt;avgQ&lt;/code&gt;) is computed by weighted mean of each base&amp;rsquo;s quality,&lt;/p&gt;
&lt;div class="math"&gt;$$
    \text{avgQ} = \dfrac{\sum_{q=0}^{93} q \cdot n_q}{\sum_{q = 0}^{93} n_q},
$$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(n_q\)&lt;/span&gt; is the number of bases with quality score being &lt;span class="math"&gt;\(q\)&lt;/span&gt;. The magic number 93 comes from the quality score of Sanger sequencing&lt;sup id="fnref:sanger-qual-score"&gt;&lt;a class="footnote-ref" href="#fn:sanger-qual-score" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, whose score ranges from 0 to 93.&lt;/p&gt;
&lt;p&gt;For &lt;code&gt;errQ&lt;/code&gt; we need more background knowledge about how quality score is computed. A base with quality score &lt;span class="math"&gt;\(q\)&lt;/span&gt; implies the probability of being erroneously called, &lt;span class="math"&gt;\(P_q\)&lt;/span&gt;, is &lt;/p&gt;
&lt;div class="math"&gt;$$
    P_q = 10^{\frac{-q}{10}}, \hspace{1em} q = -10\log_{10}{P_q}.
$$&lt;/div&gt;
&lt;p&gt;Therefore, given &lt;span class="math"&gt;\(q\)&lt;/span&gt; being &lt;span class="math"&gt;\(0, 1, 2, \ldots\)&lt;/span&gt;, seqtk has a conversion table &lt;code&gt;perr&lt;/code&gt; from quality score to probability,&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Q&lt;/th&gt;
&lt;th align="right"&gt;0&lt;/th&gt;
&lt;th align="right"&gt;1&lt;/th&gt;
&lt;th align="right"&gt;2&lt;/th&gt;
&lt;th align="right"&gt;3&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;strong&gt;P&lt;/strong&gt;&lt;/td&gt;
&lt;td align="right"&gt;0.5&lt;/td&gt;
&lt;td align="right"&gt;0.5&lt;/td&gt;
&lt;td align="right"&gt;0.5&lt;/td&gt;
&lt;td align="right"&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;Q&lt;/th&gt;
&lt;th align="right"&gt;4&lt;/th&gt;
&lt;th align="right"&gt;5&lt;/th&gt;
&lt;th align="center"&gt;&amp;hellip;&lt;/th&gt;
&lt;th align="right"&gt;38&lt;/th&gt;
&lt;th align="right"&gt;39&lt;/th&gt;
&lt;th align="right"&gt;40&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;&lt;strong&gt;P&lt;/strong&gt;&lt;/td&gt;
&lt;td align="right"&gt;0.398107&lt;/td&gt;
&lt;td align="right"&gt;0.316228&lt;/td&gt;
&lt;td align="center"&gt;&amp;hellip;&lt;/td&gt;
&lt;td align="right"&gt;0.000158&lt;/td&gt;
&lt;td align="right"&gt;0.000126&lt;/td&gt;
&lt;td align="right"&gt;0.000100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Based on the probability, it computes the expected number of base call errors, num_err, and the empirical probability of having a base call error at this position, errP, &lt;/p&gt;
&lt;div class="math"&gt;$$
    \text{num_err} = \sum_q P_q \cdot n_q, \hspace{1em} \text{errP} = \frac{\text{num_err}}{\sum_q n_q}.
$$&lt;/div&gt;
&lt;p&gt;Thus the &lt;code&gt;errQ&lt;/code&gt; is the equivalent quality score of errP, which better interprets the probability of base call error than &lt;code&gt;avgQ&lt;/code&gt;, &lt;/p&gt;
&lt;div class="math"&gt;$$
    \text{errQ} = -10\log_{10}{\text{errP}}.
$$&lt;/div&gt;
&lt;p&gt;By passing &lt;code&gt;-q 0&lt;/code&gt; to &lt;code&gt;seqtk fqchk&lt;/code&gt;, one can get the proportion of all distinct quality scores at each position. This information is pretty useful if the sequencing data is all a mess and one needs to figure out the cause.&lt;/p&gt;
&lt;p&gt;Though some of the &lt;code&gt;seqtk fqchk&lt;/code&gt;&amp;lsquo;s behavior is not documented, it should be straight forward enough to understand. All in all, the details can always be found in the &lt;a href="https://github.com/lh3/seqtk/blob/4feb6e81444ab6bc44139dd3a125068f81ae4ad8/seqtk.c#L1483"&gt;source code&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="summary"&gt;Summary&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/lh3/seqtk"&gt;Seqtk&lt;/a&gt; is fast to use for daily routines of FASTA/Q conversion. On top of that it provide various functionalities such as read random sampling, quality check, and many I haven&amp;rsquo;t tried or mentioned.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:sanger-qual-score"&gt;
&lt;p&gt;See multiple specifications of quality score at &lt;a href="http://scikit-bio.org/docs/latest/generated/skbio.io.format.fastq.html#quality-score-variants"&gt;sckit-bio doc&lt;/a&gt;. The score is &lt;a href="https://en.wikipedia.org/wiki/Phred_quality_score"&gt;Phred quality score&lt;/a&gt;. More other score representations can be found at &lt;a href="https://en.wikipedia.org/wiki/FASTQ_format"&gt;FASTQ wiki&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:sanger-qual-score" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Note that the probability of q less than 4 is fixed with 0.5. A quick computation can see when &lt;span class="math"&gt;\(q = 3\)&lt;/span&gt;, its actual Phred probability is &lt;span class="math"&gt;\(10 ^ {-0.3} = 0.501\)&lt;/span&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="en"></category><category term="seqtk"></category><category term="NGS"></category></entry></feed>